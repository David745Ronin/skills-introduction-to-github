{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/David745Ronin/skills-introduction-to-github/blob/main/KineticAI_PROD%20v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ztHwGkS2KPQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "043f5a2fe7a84d3f9ba17253ac42cd6a",
            "f68738d6ed8c48d4b66820185aceef99",
            "e03cc7d87a5e421189d57cefef9bb61d",
            "0e58daee331e4e12ab7a6bcad51ec901",
            "3fc1c7c07230482793640612ef673ad4",
            "27e2835f986b4a79a2bc4a954cec6b1b",
            "89d0ab4a2eb84f49a7471e78ca99aeaa",
            "44b14417b3944a4aa39d97180d8bf816",
            "deecc1373b694bf5be8d55f046295b2b",
            "dab3addc95bc4a79bf276987115c243d",
            "9c063cb2db01490a88d4ae21153fd470",
            "eeedd30a00174deabfce6e00a9cc339d",
            "40d0741456af4d1c8e20ab70d70a34dc"
          ]
        },
        "outputId": "4ea343e8-6d25-4494-ee69-686f0c5b6fec",
        "cellView": "form",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              ".widget-dropdown select {\n",
              "    font-size: 18px;\n",
              "    font-family: \"Arial\", sans-serif;\n",
              "}\n",
              ".widget-textarea textarea {\n",
              "    font-size: 18px;\n",
              "    font-family: \"Arial\", sans-serif;\n",
              "}\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GridBox(children=(Dropdown(layout=Layout(width='auto'), options=('google/gemini-2.0-flash', 'google/gemini-2.0‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "043f5a2fe7a84d3f9ba17253ac42cd6a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title AI prompt cell\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, Markdown,clear_output\n",
        "from google.colab import ai\n",
        "\n",
        "dropdown = widgets.Dropdown(\n",
        "    options=[],\n",
        "    layout={'width': 'auto'}\n",
        ")\n",
        "\n",
        "def update_model_list(new_options):\n",
        "    dropdown.options = new_options\n",
        "update_model_list(ai.list_models())\n",
        "\n",
        "text_input = widgets.Textarea(\n",
        "    placeholder='Ask me anything....',\n",
        "    layout={'width': 'auto', 'height': '100px'},\n",
        ")\n",
        "\n",
        "button = widgets.Button(\n",
        "    description='Submit Text',\n",
        "    disabled=False,\n",
        "    tooltip='Click to submit the text',\n",
        "    icon='check'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output(\n",
        "     layout={'width': 'auto', 'max_height': '300px','overflow_y': 'scroll'}\n",
        ")\n",
        "\n",
        "def on_button_clicked(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output(wait=False)\n",
        "        accumulated_content = \"\"\n",
        "        for new_chunk in ai.generate_text(prompt=text_input.value, model_name=dropdown.value, stream=True):\n",
        "            if new_chunk is None:\n",
        "                continue\n",
        "            accumulated_content += new_chunk\n",
        "            clear_output(wait=True)\n",
        "            display(Markdown(accumulated_content))\n",
        "\n",
        "button.on_click(on_button_clicked)\n",
        "vbox = widgets.GridBox([dropdown, text_input, button, output_area])\n",
        "\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        ".widget-dropdown select {\n",
        "    font-size: 18px;\n",
        "    font-family: \"Arial\", sans-serif;\n",
        "}\n",
        ".widget-textarea textarea {\n",
        "    font-size: 18px;\n",
        "    font-family: \"Arial\", sans-serif;\n",
        "}\n",
        "</style>\n",
        "\"\"\"))\n",
        "display(vbox)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhFM-XKofcle"
      },
      "source": [
        "### **Install Packages**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxsDsgUis6NN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBwn2PwbWpsS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "563d5457-e998-4422-b631-b534e3395976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.234-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.234-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.234 ultralytics-thop-2.0.18\n",
            "‚úì All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install ultralytics opencv-python-headless numpy scipy\n",
        "\n",
        "print(\"‚úì All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u0-fdlDe-UQ"
      },
      "source": [
        "### **Package Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_RXB5mtW0lA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb5050b-51d7-4642-ce01-c76c2c4478a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "‚úì Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Video, display\n",
        "\n",
        "print(\"‚úì Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEjmEIMYfqKC"
      },
      "source": [
        "### **Download YOLOv8 Pose**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHm0CsiAW5l-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de450a1-459d-4180-abb2-08f25f71b3fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m-pose.pt to 'yolov8m-pose.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50.8MB 42.4MB/s 1.2s\n",
            "‚úì YOLOv8-Pose model loaded successfully!\n",
            "Model: yolov8m-pose.pt\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained YOLOv8 pose estimation model\n",
        "model = YOLO('yolov8m-pose.pt')  # Medium model - good balance of speed/accuracy\n",
        "\n",
        "print(\"‚úì YOLOv8-Pose model loaded successfully!\")\n",
        "print(f\"Model: {model.model_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set up logger that writes to Colab output and to a log file**\n",
        "\n",
        "Example: logger.info('This is a log line.')\n",
        "\n",
        "Levels include .info(), .warning(), .error(), and others"
      ],
      "metadata": {
        "id": "CcuDYPrlleuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "def setup_logger(log_file='system_log.log'):\n",
        "    \"\"\"\n",
        "    Configures and returns a logger that writes to a console and a file.\n",
        "\n",
        "    Usage:\n",
        "    logger = setup_logger()\n",
        "    logger.info('This is a log line.')\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger('kinetic_ai_logger')\n",
        "    logger.setLevel(logging.INFO)\n",
        "\n",
        "    logger.propagate = False\n",
        "\n",
        "    if logger.hasHandlers():\n",
        "        logger.handlers.clear()\n",
        "\n",
        "    formatter = logging.Formatter(\n",
        "      '%(asctime)s - %(levelname)s - %(message)s',\n",
        "      datefmt='%Y-%m-%d %H:%M:%S'\n",
        "    )\n",
        "\n",
        "    # Console handler\n",
        "    stream_handler = logging.StreamHandler(sys.stdout)\n",
        "    stream_handler.setFormatter(formatter)\n",
        "    logger.addHandler(stream_handler)\n",
        "\n",
        "    # File handler\n",
        "    file_handler = logging.FileHandler(log_file)\n",
        "    file_handler.setFormatter(formatter)\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "logger = setup_logger()"
      ],
      "metadata": {
        "id": "b8Rts4czldg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7Rc-m_LqoZB6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "945164a2-55d7-4480-bcf9-fcbd07b37bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L6KII8xtMVi"
      },
      "source": [
        "Purpose: Connects to Google Drive and locates training videos.\n",
        "What it does:\n",
        "\n",
        "Mounts Google Drive to access files\n",
        "Searches for \"Good Form\" folder (reference videos)\n",
        "Searches for \"Bad Form\" folder (user videos to analyze)\n",
        "Tries multiple common folder path variations\n",
        "Validates that videos can be opened by OpenCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c88ZbEk76nwi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive, files\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define a temporary folder for uploaded videos\n",
        "UPLOAD_FOLDER = '/content/uploaded_videos'\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "\n",
        "def get_video_path_from_user(video_type):\n",
        "    \"\"\"\n",
        "    Prompts the user to upload a video or provide a Google Drive path.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Select {video_type} Video ---\")\n",
        "    print(\"  1. Upload a video file from your computer\")\n",
        "    print(\"  2. Provide a Google Drive path (e.g., /content/drive/MyDrive/my_video.mp4)\")\n",
        "    choice = input(\"Enter choice (1 or 2): \").strip()\n",
        "\n",
        "    video_path = None\n",
        "    if choice == '1':\n",
        "        print(f\"Please select your {video_type} video file to upload...\")\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            filename = list(uploaded.keys())[0]\n",
        "            temp_path = os.path.join(UPLOAD_FOLDER, filename)\n",
        "            shutil.move(filename, temp_path)\n",
        "            video_path = temp_path\n",
        "            print(f\"‚úì Uploaded {video_type} video: {filename}\")\n",
        "        else:\n",
        "            print(\"‚ùå No file uploaded.\")\n",
        "    elif choice == '2':\n",
        "        gdrive_path = input(f\"Enter Google Drive path for {video_type} video: \").strip()\n",
        "        if os.path.exists(gdrive_path):\n",
        "            video_path = gdrive_path\n",
        "            print(f\"‚úì {video_type} video found at: {gdrive_path}\")\n",
        "        else:\n",
        "            print(f\"‚ùå File not found at: {gdrive_path}\")\n",
        "    else:\n",
        "        print(\"‚ùå Invalid choice.\")\n",
        "    return video_path\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VIDEO SELECTION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "reference_video = get_video_path_from_user(\"Reference\")\n",
        "user_video = get_video_path_from_user(\"User\")\n",
        "\n",
        "if reference_video and user_video:\n",
        "    print(\"\\n‚úì Both videos selected!\")\n",
        "    print(f\"  Reference Video: {reference_video}\")\n",
        "    print(f\"  User Video: {user_video}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Video selection incomplete. Please ensure both videos are provided.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vojm03NF36kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuhmlZWjtWGo"
      },
      "source": [
        "Purpose: Explicitly sets the paths to reference and user videos.\n",
        "What it does:\n",
        "\n",
        "Lists all video files in Good Form and Bad Form folders\n",
        "Selects the first video from each folder\n",
        "Creates full file paths for both videos\n",
        "Verifies files exist and are accessible\n",
        "\n",
        "Output:\n",
        "\n",
        "reference_video = path to correct form example\n",
        "user_video = path to user's form to analyze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wX06of23qlV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Your folder paths\n",
        "good_form_folder = '/content/Good Form'  # or wherever your folder is\n",
        "bad_form_folder = '/content/Bad Form'\n",
        "\n",
        "# Get video files\n",
        "good_form_videos = [f for f in os.listdir(good_form_folder)\n",
        "                    if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
        "bad_form_videos = [f for f in os.listdir(bad_form_folder)\n",
        "                   if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
        "\n",
        "print(\"Videos found:\")\n",
        "print(f\"  Good Form: {good_form_videos}\")\n",
        "print(f\"  Bad Form: {bad_form_videos}\")\n",
        "\n",
        "# IMPORTANT: Set the full paths\n",
        "if good_form_videos:\n",
        "    reference_video = os.path.join(good_form_folder, good_form_videos[0])\n",
        "    print(f\"\\n‚úì Reference video set to: {reference_video}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No good form videos found!\")\n",
        "    reference_video = None\n",
        "\n",
        "if bad_form_videos:\n",
        "    user_video = os.path.join(bad_form_folder, bad_form_videos[0])\n",
        "    print(f\"‚úì User video set to: {user_video}\")\n",
        "else:\n",
        "    print(\"‚ùå No bad form videos found!\")\n",
        "    user_video = None\n",
        "\n",
        "# Verify both are set\n",
        "if reference_video and user_video:\n",
        "    print(\"\\n‚úì Both videos ready for comparison\")\n",
        "    print(f\"  Reference exists: {os.path.exists(reference_video)}\")\n",
        "    print(f\"  User exists: {os.path.exists(user_video)}\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Cannot proceed - missing video paths\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no7ChQpA3GAo"
      },
      "source": [
        "## üìä **Enhanced Progress Tracking System**\n",
        "**Purpose:** Track your progress day-by-day, week-by-week, and month-to-month.\n",
        "\n",
        "**New Features:**\n",
        "- ‚úÖ Weight tracking (bodyweight to heavy)\n",
        "- ‚úÖ Difficulty levels (light, moderate, heavy)\n",
        "- ‚úÖ Session notes\n",
        "- ‚úÖ Time-based analysis (day/week/month/all)\n",
        "- ‚úÖ Visual progress charts (8-panel dashboard)\n",
        "- ‚úÖ Comparative analysis across time periods\n",
        "- ‚úÖ Personal records tracking\n",
        "- ‚úÖ Training frequency & streak monitoring\n",
        "\n",
        "**Key Functions:**\n",
        "- `save_session_data()` - Log workouts with weight/notes\n",
        "- `analyze_progress()` - View detailed stats\n",
        "- `visualize_progress()` - Generate charts\n",
        "- `compare_time_periods()` - Compare different periods\n",
        "- `get_workout_summary()` - Interactive logging\n",
        "\n",
        "**Dependencies:** Run after basic setup, before video processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc1Vptl11n7o"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ========== ENHANCED PROGRESS TRACKING FUNCTIONS ==========\n",
        "\n",
        "def save_session_data(user_id, exercise_type, accuracy_pct, total_reps,\n",
        "                      most_common_issues, avg_difference,\n",
        "                      weight_lbs=0, difficulty_level='bodyweight',\n",
        "                      session_date=None, notes=''):\n",
        "    \"\"\"\n",
        "    Save workout session data to a JSON file for progress tracking\n",
        "\n",
        "    Args:\n",
        "        user_id: Unique identifier for the user\n",
        "        exercise_type: Type of exercise (e.g., 'squat', 'deadlift')\n",
        "        accuracy_pct: Overall form accuracy percentage\n",
        "        total_reps: Number of reps completed\n",
        "        most_common_issues: List of (joint, count) tuples\n",
        "        avg_difference: Average angle difference across all frames\n",
        "        weight_lbs: Weight used in pounds (0 for bodyweight)\n",
        "        difficulty_level: 'bodyweight', 'light', 'moderate', 'heavy', or custom\n",
        "        session_date: Optional date (defaults to now)\n",
        "        notes: Optional notes about the session\n",
        "    \"\"\"\n",
        "    if session_date is None:\n",
        "        session_date = datetime.now().isoformat()\n",
        "\n",
        "    # Create progress directory if it doesn't exist\n",
        "    progress_dir = '/content/progress_data'\n",
        "    os.makedirs(progress_dir, exist_ok=True)\n",
        "\n",
        "    # File path for user's progress data\n",
        "    progress_file = f'{progress_dir}/{user_id}_{exercise_type}_progress.json'\n",
        "\n",
        "    # Load existing data or create new\n",
        "    progress_data = {\n",
        "        'user_id': user_id,\n",
        "        'exercise_type': exercise_type,\n",
        "        'sessions': []\n",
        "    }\n",
        "\n",
        "    if os.path.exists(progress_file):\n",
        "        try:\n",
        "            with open(progress_file, 'r') as f:\n",
        "                progress_data = json.load(f)\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"‚ö†Ô∏è Warning: Progress file '{progress_file}' was corrupted. Starting new progress data.\")\n",
        "\n",
        "    # Add new session\n",
        "    session = {\n",
        "        'date': session_date,\n",
        "        'accuracy': accuracy_pct,\n",
        "        'reps': total_reps,\n",
        "        'avg_difference': avg_difference,\n",
        "        'weight_lbs': weight_lbs,\n",
        "        'difficulty_level': difficulty_level,\n",
        "        'notes': notes,\n",
        "        'issues': [{'joint': joint, 'count': count} for joint, count in most_common_issues[:5]]\n",
        "    }\n",
        "\n",
        "    progress_data['sessions'].append(session)\n",
        "\n",
        "    # Save updated data\n",
        "    with open(progress_file, 'w') as f:\n",
        "        json.dump(progress_data, f, indent=2)\n",
        "\n",
        "    print(f\"‚úì Session data saved to {progress_file}\")\n",
        "    return progress_file\n",
        "\n",
        "\n",
        "def load_progress_data(user_id, exercise_type):\n",
        "    \"\"\"Load user's progress data\"\"\"\n",
        "    progress_file = f'/content/progress_data/{user_id}_{exercise_type}_progress.json'\n",
        "\n",
        "    if not os.path.exists(progress_file):\n",
        "        print(f\"No progress data found for {user_id} - {exercise_type}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(progress_file, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"‚ö†Ô∏è Warning: Progress file '{progress_file}' is corrupted. Cannot load data.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def analyze_progress(user_id, exercise_type, time_period='all'):\n",
        "    \"\"\"\n",
        "    Analyze user's progress over specified time period\n",
        "\n",
        "    Args:\n",
        "        user_id: User identifier\n",
        "        exercise_type: Exercise type\n",
        "        time_period: 'day', 'week', 'month', '4weeks', or 'all'\n",
        "    \"\"\"\n",
        "    data = load_progress_data(user_id, exercise_type)\n",
        "\n",
        "    if not data or not data['sessions']:\n",
        "        print(\"No session data available for analysis\")\n",
        "        return None\n",
        "\n",
        "    sessions = data['sessions']\n",
        "    df = pd.DataFrame(sessions)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    # Sort by date\n",
        "    df = df.sort_values('date')\n",
        "\n",
        "    # Filter by time period\n",
        "    now = datetime.now()\n",
        "    if time_period == 'day':\n",
        "        cutoff_date = now - timedelta(days=1)\n",
        "        period_name = \"Last 24 Hours\"\n",
        "    elif time_period == 'week':\n",
        "        cutoff_date = now - timedelta(weeks=1)\n",
        "        period_name = \"Last 7 Days\"\n",
        "    elif time_period == '4weeks':\n",
        "        cutoff_date = now - timedelta(weeks=4)\n",
        "        period_name = \"Last 4 Weeks\"\n",
        "    elif time_period == 'month':\n",
        "        cutoff_date = now - timedelta(days=30)\n",
        "        period_name = \"Last 30 Days\"\n",
        "    else:  # 'all'\n",
        "        cutoff_date = df['date'].min()\n",
        "        period_name = \"All Time\"\n",
        "\n",
        "    df_filtered = df[df['date'] >= cutoff_date]\n",
        "\n",
        "    if len(df_filtered) == 0:\n",
        "        print(f\"No sessions found in {period_name.lower()}\")\n",
        "        return None\n",
        "\n",
        "    # Calculate statistics\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üìä PROGRESS REPORT - {period_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Exercise: {exercise_type.upper()}\")\n",
        "    print(f\"Total Sessions: {len(df_filtered)}\")\n",
        "    print(f\"Date Range: {df_filtered['date'].min().strftime('%Y-%m-%d')} to {df_filtered['date'].max().strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    # Form Quality Metrics\n",
        "    print(f\"\\nüéØ FORM QUALITY:\")\n",
        "    print(f\"  Current Accuracy: {df_filtered.iloc[-1]['accuracy']:.1f}%\")\n",
        "    print(f\"  Starting Accuracy: {df_filtered.iloc[0]['accuracy']:.1f}%\")\n",
        "    improvement = df_filtered.iloc[-1]['accuracy'] - df_filtered.iloc[0]['accuracy']\n",
        "    print(f\"  Improvement: {improvement:+.1f}%\")\n",
        "    print(f\"  Average Accuracy: {df_filtered['accuracy'].mean():.1f}%\")\n",
        "    print(f\"  Best Session: {df_filtered['accuracy'].max():.1f}%\")\n",
        "\n",
        "    # Volume Metrics\n",
        "    print(f\"\\nüí™ VOLUME & INTENSITY:\")\n",
        "    total_reps = df_filtered['reps'].sum()\n",
        "    print(f\"  Total Reps: {total_reps}\")\n",
        "    print(f\"  Average Reps/Session: {df_filtered['reps'].mean():.1f}\")\n",
        "    print(f\"  Max Reps (Single Session): {df_filtered['reps'].max()}\")\n",
        "\n",
        "    # Weight Progression\n",
        "    if 'weight_lbs' in df_filtered.columns:\n",
        "        max_weight = df_filtered['weight_lbs'].max()\n",
        "        current_weight = df_filtered.iloc[-1]['weight_lbs']\n",
        "        starting_weight = df_filtered.iloc[0]['weight_lbs']\n",
        "\n",
        "        print(f\"\\nüèãÔ∏è WEIGHT PROGRESSION:\")\n",
        "        print(f\"  Current Weight: {current_weight} lbs\")\n",
        "        print(f\"  Starting Weight: {starting_weight} lbs\")\n",
        "        print(f\"  Max Weight Used: {max_weight} lbs\")\n",
        "        print(f\"  Weight Increase: +{current_weight - starting_weight} lbs\")\n",
        "\n",
        "        # Total volume (reps √ó weight)\n",
        "        df_filtered['volume'] = df_filtered['reps'] * df_filtered['weight_lbs']\n",
        "        total_volume = df_filtered['volume'].sum()\n",
        "        print(f\"  Total Volume: {total_volume:,.0f} lbs\")\n",
        "\n",
        "    # Frequency Analysis\n",
        "    print(f\"\\nüìÖ TRAINING FREQUENCY:\")\n",
        "    days_span = (df_filtered['date'].max() - df_filtered['date'].min()).days + 1\n",
        "    sessions_per_week = (len(df_filtered) / days_span) * 7 if days_span > 0 else 0\n",
        "    print(f\"  Sessions per Week: {sessions_per_week:.1f}\")\n",
        "    print(f\"  Days Since Last Session: {(now - df_filtered['date'].max()).days}\")\n",
        "\n",
        "    # Streak calculation\n",
        "    df_filtered['date_only'] = df_filtered['date'].dt.date\n",
        "    unique_dates = sorted(df_filtered['date_only'].unique(), reverse=True)\n",
        "    current_streak = 0\n",
        "    for i, date in enumerate(unique_dates):\n",
        "        if i == 0:\n",
        "            days_diff = (datetime.now().date() - date).days\n",
        "            if days_diff <= 1:  # Within last day\n",
        "                current_streak = 1\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            days_diff = (unique_dates[i-1] - date).days\n",
        "            if days_diff == 1:\n",
        "                current_streak += 1\n",
        "            else:\n",
        "                break\n",
        "    print(f\"  Current Streak: {current_streak} days\")\n",
        "\n",
        "    # Trend analysis\n",
        "    if len(df_filtered) >= 3:\n",
        "        recent_avg = df_filtered.tail(3)['accuracy'].mean()\n",
        "        early_avg = df_filtered.head(3)['accuracy'].mean()\n",
        "        if recent_avg > early_avg + 2:\n",
        "            trend = \"üìà Improving\"\n",
        "        elif recent_avg < early_avg - 2:\n",
        "            trend = \"üìâ Declining\"\n",
        "        else:\n",
        "            trend = \"‚û°Ô∏è Stable\"\n",
        "        print(f\"\\nüéØ Trend: {trend}\")\n",
        "\n",
        "    # Most common issues\n",
        "    all_issues = {}\n",
        "    for session in df_filtered.to_dict('records'):\n",
        "        for issue in session['issues']:\n",
        "            joint = issue['joint']\n",
        "            all_issues[joint] = all_issues.get(joint, 0) + issue['count']\n",
        "\n",
        "    if all_issues:\n",
        "        print(f\"\\n‚ö†Ô∏è MOST COMMON FORM ISSUES:\")\n",
        "        sorted_issues = sorted(all_issues.items(), key=lambda x: x[1], reverse=True)\n",
        "        for i, (joint, count) in enumerate(sorted_issues[:3], 1):\n",
        "            print(f\"  {i}. {joint.replace('_', ' ').title()} ({count} occurrences)\")\n",
        "\n",
        "    # Personal Records\n",
        "    print(f\"\\nüèÜ PERSONAL RECORDS:\")\n",
        "    pr_accuracy = df_filtered.loc[df_filtered['accuracy'].idxmax()]\n",
        "    print(f\"  Best Accuracy: {pr_accuracy['accuracy']:.1f}% on {pr_accuracy['date'].strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    pr_reps = df_filtered.loc[df_filtered['reps'].idxmax()]\n",
        "    print(f\"  Most Reps: {pr_reps['reps']} on {pr_reps['date'].strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    if 'weight_lbs' in df_filtered.columns and df_filtered['weight_lbs'].max() > 0:\n",
        "        pr_weight = df_filtered.loc[df_filtered['weight_lbs'].idxmax()]\n",
        "        print(f\"  Heaviest Weight: {pr_weight['weight_lbs']} lbs on {pr_weight['date'].strftime('%Y-%m-%d')}\")\n",
        "\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    return df_filtered\n",
        "\n",
        "\n",
        "def visualize_progress(user_id, exercise_type, time_period='month'):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualization of user's progress\n",
        "\n",
        "    Args:\n",
        "        user_id: User identifier\n",
        "        exercise_type: Exercise type\n",
        "        time_period: 'week', 'month', '4weeks', '3months', '6months', or 'all'\n",
        "    \"\"\"\n",
        "    data = load_progress_data(user_id, exercise_type)\n",
        "\n",
        "    if not data or not data['sessions']:\n",
        "        print(\"No session data available for visualization\")\n",
        "        return None\n",
        "\n",
        "    sessions = data['sessions']\n",
        "    df = pd.DataFrame(sessions)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.sort_values('date')\n",
        "\n",
        "    # Filter by time period\n",
        "    now = datetime.now()\n",
        "    if time_period == 'week':\n",
        "        cutoff_date = now - timedelta(weeks=1)\n",
        "        period_name = \"Last 7 Days\"\n",
        "    elif time_period == '4weeks':\n",
        "        cutoff_date = now - timedelta(weeks=4)\n",
        "        period_name = \"Last 4 Weeks\"\n",
        "    elif time_period == 'month':\n",
        "        cutoff_date = now - timedelta(days=30)\n",
        "        period_name = \"Last 30 Days\"\n",
        "    elif time_period == '3months':\n",
        "        cutoff_date = now - timedelta(days=90)\n",
        "        period_name = \"Last 3 Months\"\n",
        "    elif time_period == '6months':\n",
        "        cutoff_date = now - timedelta(days=180)\n",
        "        period_name = \"Last 6 Months\"\n",
        "    else:  # 'all'\n",
        "        cutoff_date = df['date'].min()\n",
        "        period_name = \"All Time\"\n",
        "\n",
        "    df_filtered = df[df['date'] >= cutoff_date]\n",
        "\n",
        "    if len(df_filtered) == 0:\n",
        "        print(f\"No sessions found in {period_name.lower()}\")\n",
        "        return None\n",
        "\n",
        "    # Create figure with subplots\n",
        "    fig = plt.figure(figsize=(20, 12))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    fig.suptitle(f'{exercise_type.upper()} Progress - {period_name}',\n",
        "                 fontsize=20, fontweight='bold', y=0.98)\n",
        "\n",
        "    # 1. Accuracy over time (Large - top left)\n",
        "    ax1 = fig.add_subplot(gs[0, :2])\n",
        "    ax1.plot(df_filtered['date'], df_filtered['accuracy'],\n",
        "             marker='o', linewidth=2.5, markersize=8, color='#2E86AB', label='Accuracy')\n",
        "    ax1.axhline(y=85, color='g', linestyle='--', linewidth=2, label='Target (85%)')\n",
        "\n",
        "    # Add trend line\n",
        "    if len(df_filtered) > 1:\n",
        "        z = np.polyfit(range(len(df_filtered)), df_filtered['accuracy'], 1)\n",
        "        p = np.poly1d(z)\n",
        "        ax1.plot(df_filtered['date'], p(range(len(df_filtered))),\n",
        "                \"r--\", alpha=0.5, linewidth=2, label='Trend')\n",
        "\n",
        "    ax1.set_xlabel('Date', fontsize=12)\n",
        "    ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    ax1.set_title('Form Accuracy Over Time', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 2. Reps per session (top right)\n",
        "    ax2 = fig.add_subplot(gs[0, 2])\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(df_filtered)))\n",
        "    bars = ax2.bar(range(len(df_filtered)), df_filtered['reps'], color=colors)\n",
        "    ax2.set_xlabel('Session Number', fontsize=11)\n",
        "    ax2.set_ylabel('Reps', fontsize=11)\n",
        "    ax2.set_title('Reps Per Session', fontsize=13, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # 3. Weight progression (middle left)\n",
        "    ax3 = fig.add_subplot(gs[1, 0])\n",
        "    if 'weight_lbs' in df_filtered.columns:\n",
        "        ax3.plot(df_filtered['date'], df_filtered['weight_lbs'],\n",
        "                marker='s', linewidth=2.5, markersize=8, color='#A23B72')\n",
        "        ax3.fill_between(df_filtered['date'], 0, df_filtered['weight_lbs'],\n",
        "                        alpha=0.3, color='#A23B72')\n",
        "        ax3.set_xlabel('Date', fontsize=11)\n",
        "        ax3.set_ylabel('Weight (lbs)', fontsize=11)\n",
        "        ax3.set_title('Weight Progression', fontsize=13, fontweight='bold')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "        ax3.tick_params(axis='x', rotation=45)\n",
        "    else:\n",
        "        ax3.text(0.5, 0.5, 'No Weight Data', ha='center', va='center',\n",
        "                fontsize=14, transform=ax3.transAxes)\n",
        "        ax3.set_title('Weight Progression', fontsize=13, fontweight='bold')\n",
        "\n",
        "    # 4. Total Volume (middle center)\n",
        "    ax4 = fig.add_subplot(gs[1, 1])\n",
        "    if 'weight_lbs' in df_filtered.columns:\n",
        "        df_filtered['volume'] = df_filtered['reps'] * df_filtered['weight_lbs']\n",
        "        ax4.bar(df_filtered['date'], df_filtered['volume'],\n",
        "               color='#F18F01', alpha=0.7)\n",
        "        ax4.set_xlabel('Date', fontsize=11)\n",
        "        ax4.set_ylabel('Volume (lbs)', fontsize=11)\n",
        "        ax4.set_title('Training Volume (Reps √ó Weight)', fontsize=13, fontweight='bold')\n",
        "        ax4.grid(True, alpha=0.3, axis='y')\n",
        "        ax4.tick_params(axis='x', rotation=45)\n",
        "    else:\n",
        "        ax4.text(0.5, 0.5, 'No Volume Data', ha='center', va='center',\n",
        "                fontsize=14, transform=ax4.transAxes)\n",
        "        ax4.set_title('Training Volume', fontsize=13, fontweight='bold')\n",
        "\n",
        "    # 5. Average form deviation (middle right)\n",
        "    ax5 = fig.add_subplot(gs[1, 2])\n",
        "    ax5.plot(df_filtered['date'], df_filtered['avg_difference'],\n",
        "            marker='D', linewidth=2, markersize=7, color='#C73E1D')\n",
        "    ax5.set_xlabel('Date', fontsize=11)\n",
        "    ax5.set_ylabel('Avg Angle Difference (¬∞)', fontsize=11)\n",
        "    ax5.set_title('Average Form Deviation', fontsize=13, fontweight='bold')\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    ax5.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 6. Most common issues (bottom left)\n",
        "    ax6 = fig.add_subplot(gs[2, 0])\n",
        "    all_issues = {}\n",
        "    for session in df_filtered.to_dict('records'):\n",
        "        for issue in session['issues']:\n",
        "            joint = issue['joint']\n",
        "            all_issues[joint] = all_issues.get(joint, 0) + issue['count']\n",
        "\n",
        "    if all_issues:\n",
        "        sorted_issues = sorted(all_issues.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "        joints, counts = zip(*sorted_issues)\n",
        "        joints = [j.replace('_', ' ').title() for j in joints]\n",
        "        ax6.barh(joints, counts, color='#E63946')\n",
        "        ax6.set_xlabel('Frequency', fontsize=11)\n",
        "        ax6.set_title('Most Common Form Issues', fontsize=13, fontweight='bold')\n",
        "        ax6.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "    # 7. Session frequency heatmap (bottom center)\n",
        "    ax7 = fig.add_subplot(gs[2, 1])\n",
        "    df_filtered['date_only'] = df_filtered['date'].dt.date\n",
        "    session_counts = df_filtered.groupby('date_only').size()\n",
        "\n",
        "    # Create calendar view\n",
        "    dates = pd.date_range(df_filtered['date'].min(), df_filtered['date'].max(), freq='D')\n",
        "    session_matrix = [session_counts.get(d.date(), 0) for d in dates]\n",
        "\n",
        "    ax7.plot(dates, session_matrix, marker='o', linewidth=2, markersize=6, color='#06A77D')\n",
        "    ax7.fill_between(dates, 0, session_matrix, alpha=0.3, color='#06A77D')\n",
        "    ax7.set_xlabel('Date', fontsize=11)\n",
        "    ax7.set_ylabel('Sessions', fontsize=11)\n",
        "    ax7.set_title('Training Frequency', fontsize=13, fontweight='bold')\n",
        "    ax7.grid(True, alpha=0.3)\n",
        "    ax7.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # 8. Personal Records Summary (bottom right)\n",
        "    ax8 = fig.add_subplot(gs[2, 2])\n",
        "    ax8.axis('off')\n",
        "\n",
        "    pr_text = \"üèÜ PERSONAL RECORDS\\n\\n\"\n",
        "    pr_text += f\"Best Accuracy:\\n{df_filtered['accuracy'].max():.1f}%\\n\\n\"\n",
        "    pr_text += f\"Most Reps:\\n{df_filtered['reps'].max()}\\n\\n\"\n",
        "    if 'weight_lbs' in df_filtered.columns and df_filtered['weight_lbs'].max() > 0:\n",
        "        pr_text += f\"Max Weight:\\n{df_filtered['weight_lbs'].max()} lbs\\n\\n\"\n",
        "    pr_text += f\"Total Sessions:\\n{len(df_filtered)}\\n\\n\"\n",
        "    pr_text += f\"Total Reps:\\n{df_filtered['reps'].sum()}\"\n",
        "\n",
        "    ax8.text(0.1, 0.9, pr_text, fontsize=12, verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    output_path = f'/content/{user_id}_{exercise_type}_progress_{time_period}.png'\n",
        "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"‚úì Progress chart saved to {output_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def compare_time_periods(user_id, exercise_type):\n",
        "    \"\"\"\n",
        "    Compare performance across different time periods\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üìä COMPARATIVE ANALYSIS - {exercise_type.upper()}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    periods = {\n",
        "        'day': 'Last 24 Hours',\n",
        "        'week': 'Last 7 Days',\n",
        "        'month': 'Last 30 Days'\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for period_key, period_name in periods.items():\n",
        "        df = analyze_progress(user_id, exercise_type, time_period=period_key)\n",
        "        if df is not None and len(df) > 0:\n",
        "            results[period_name] = {\n",
        "                'sessions': len(df),\n",
        "                'avg_accuracy': df['accuracy'].mean(),\n",
        "                'total_reps': df['reps'].sum(),\n",
        "                'max_weight': df['weight_lbs'].max() if 'weight_lbs' in df.columns else 0\n",
        "            }\n",
        "\n",
        "    if results:\n",
        "        print(\"\\nüìà SUMMARY COMPARISON:\")\n",
        "        print(f\"{'Period':<20} {'Sessions':<12} {'Avg Accuracy':<15} {'Total Reps':<12} {'Max Weight'}\")\n",
        "        print(\"-\" * 70)\n",
        "        for period, stats in results.items():\n",
        "            print(f\"{period:<20} {stats['sessions']:<12} {stats['avg_accuracy']:<14.1f}% \"\n",
        "                  f\"{stats['total_reps']:<12} {stats['max_weight']} lbs\")\n",
        "\n",
        "\n",
        "def get_workout_summary():\n",
        "    \"\"\"\n",
        "    Interactive function to log workout details\n",
        "    Returns dictionary with workout parameters\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìù WORKOUT SESSION DETAILS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Weight\n",
        "    weight_input = input(\"\\nüèãÔ∏è Weight used (lbs) [0 for bodyweight]: \").strip()\n",
        "    weight_lbs = float(weight_input) if weight_input else 0\n",
        "\n",
        "    # Difficulty level\n",
        "    if weight_lbs == 0:\n",
        "        difficulty = 'bodyweight'\n",
        "    else:\n",
        "        print(\"\\nüí™ Difficulty Level:\")\n",
        "        print(\"  1. Light (warm-up weight)\")\n",
        "        print(\"  2. Moderate (working weight)\")\n",
        "        print(\"  3. Heavy (near max)\")\n",
        "        difficulty_choice = input(\"Choose (1-3): \").strip()\n",
        "        difficulty_map = {'1': 'light', '2': 'moderate', '3': 'heavy'}\n",
        "        difficulty = difficulty_map.get(difficulty_choice, 'moderate')\n",
        "\n",
        "    # Notes\n",
        "    notes = input(\"\\nüìù Session notes (optional): \").strip()\n",
        "\n",
        "    return {\n",
        "        'weight_lbs': weight_lbs,\n",
        "        'difficulty_level': difficulty,\n",
        "        'notes': notes\n",
        "    }\n",
        "\n",
        "\n",
        "# ========== EXAMPLE USAGE ==========\n",
        "\n",
        "def demo_enhanced_tracking():\n",
        "    \"\"\"\n",
        "    Demonstration of the enhanced tracking system\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üéØ ENHANCED PROGRESS TRACKING DEMO\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Simulate some sessions with progression\n",
        "    user_id = \"demo_user\"\n",
        "    exercise = \"squat\"\n",
        "\n",
        "    # Clear old demo data\n",
        "    demo_file = f'/content/progress_data/{user_id}_{exercise}_progress.json'\n",
        "    if os.path.exists(demo_file):\n",
        "        os.remove(demo_file)\n",
        "\n",
        "    print(\"\\nüìä Creating sample progress data...\")\n",
        "\n",
        "    # Week 1: Bodyweight\n",
        "    for day in range(3):\n",
        "        date = datetime.now() - timedelta(days=21-day)\n",
        "        save_session_data(\n",
        "            user_id, exercise,\n",
        "            accuracy_pct=70 + day*2,\n",
        "            total_reps=8 + day,\n",
        "            most_common_issues=[('left_knee', 5), ('right_hip', 3)],\n",
        "            avg_difference=18 - day,\n",
        "            weight_lbs=0,\n",
        "            difficulty_level='bodyweight',\n",
        "            session_date=date.isoformat(),\n",
        "            notes=f\"Week 1 - Day {day+1}\"\n",
        "        )\n",
        "\n",
        "    # Week 2: Light weight\n",
        "    for day in range(3):\n",
        "        date = datetime.now() - timedelta(days=14-day)\n",
        "        save_session_data(\n",
        "            user_id, exercise,\n",
        "            accuracy_pct=76 + day*2,\n",
        "            total_reps=10 + day,\n",
        "            most_common_issues=[('left_knee', 3), ('right_hip', 2)],\n",
        "            avg_difference=15 - day,\n",
        "            weight_lbs=25,\n",
        "            difficulty_level='light',\n",
        "            session_date=date.isoformat(),\n",
        "            notes=f\"Week 2 - Added weight!\"\n",
        "        )\n",
        "\n",
        "    # Week 3: Moderate weight\n",
        "    for day in range(3):\n",
        "        date = datetime.now() - timedelta(days=7-day)\n",
        "        save_session_data(\n",
        "            user_id, exercise,\n",
        "            accuracy_pct=82 + day*2,\n",
        "            total_reps=12 + day,\n",
        "            most_common_issues=[('left_knee', 2)],\n",
        "            avg_difference=12 - day,\n",
        "            weight_lbs=45,\n",
        "            difficulty_level='moderate',\n",
        "            session_date=date.isoformat(),\n",
        "            notes=f\"Week 3 - Feeling strong!\"\n",
        "        )\n",
        "\n",
        "    print(\"‚úì Sample data created!\\n\")\n",
        "\n",
        "    # Show different analyses\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"1Ô∏è‚É£ ANALYZING LAST 7 DAYS:\")\n",
        "    analyze_progress(user_id, exercise, 'week')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"2Ô∏è‚É£ ANALYZING LAST 30 DAYS:\")\n",
        "    analyze_progress(user_id, exercise, 'month')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"3Ô∏è‚É£ COMPARATIVE ANALYSIS:\")\n",
        "    compare_time_periods(user_id, exercise)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"4Ô∏è‚É£ CREATING VISUALIZATIONS:\")\n",
        "    visualize_progress(user_id, exercise, 'all')\n",
        "\n",
        "    print(\"\\n‚úÖ Demo complete! Check the generated chart above.\")\n",
        "\n",
        "\n",
        "# Uncomment to run demo:\n",
        "demo_enhanced_tracking()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbkGpeM3tqbQ"
      },
      "source": [
        "Purpose: Extracts skeletal pose data from video frames.\n",
        "\n",
        "What it does:   extract_keypoints_from_video() function:\n",
        "\n",
        "Opens video file\n",
        "Processes each frame with YOLO model\n",
        "Extracts 17 body keypoint coordinates (x, y)\n",
        "Returns array of all keypoints for all frames\n",
        "\n",
        "Troubleshooting:\n",
        "\n",
        "If encoding fails: Check that dimensions are even (handled automatically now)\n",
        "If download fails: Video file will be in /content/ folder\n",
        "If summaries look wrong: Verify Cell 1 completed successfully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RViacMj1XPbv"
      },
      "outputs": [],
      "source": [
        "def extract_keypoints_from_video(video_path):\n",
        "    \"\"\"Extract keypoints from each frame of a video\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    all_keypoints = []\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Run pose estimation\n",
        "        results = model(frame, verbose=False)\n",
        "\n",
        "        if len(results[0].keypoints) > 0:\n",
        "            # Get keypoints (17 points with x, y coordinates)\n",
        "            keypoints = results[0].keypoints.xy[0].cpu().numpy()\n",
        "            all_keypoints.append(keypoints)\n",
        "            frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(all_keypoints), frame_count\n",
        "\n",
        "print(\"‚úì Keypoint extraction function ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtS4I14zu4jF"
      },
      "source": [
        "Purpose: Calculates joint angles from body keypoints.\n",
        "\n",
        "**Key Functions:**\n",
        "\n",
        "1. **`calculate_angle(point1, point2, point3)`**\n",
        "   - Calculates angle at middle point (point2)\n",
        "   - Uses dot product formula\n",
        "   - Returns angle in degrees\n",
        "\n",
        "2. **`get_joint_angles(keypoints)`**\n",
        "   - Calculates 6 key angles:\n",
        "     - Left/right knee angles (hip-knee-ankle)\n",
        "     - Left/right hip angles (shoulder-hip-knee)\n",
        "     - Left/right elbow angles (shoulder-elbow-wrist)\n",
        "\n",
        "**Why angles matter:**\n",
        "- More meaningful than raw coordinates\n",
        "- Invariant to camera position\n",
        "- Direct measure of form quality\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qafhkb1oXakn"
      },
      "outputs": [],
      "source": [
        "def calculate_angle(point1, point2, point3):\n",
        "    \"\"\"\n",
        "    Calculate angle between three points\n",
        "    point2 is the vertex of the angle\n",
        "    \"\"\"\n",
        "    vector1 = point1 - point2\n",
        "    vector2 = point3 - point2\n",
        "\n",
        "    # Calculate angle using dot product\n",
        "    cosine_angle = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
        "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
        "\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def get_joint_angles(keypoints):\n",
        "    \"\"\"\n",
        "    Calculate key joint angles from keypoints\n",
        "    Keypoint indices (COCO format):\n",
        "    5: left_shoulder, 7: left_elbow, 9: left_wrist\n",
        "    6: right_shoulder, 8: right_elbow, 10: right_wrist\n",
        "    11: left_hip, 13: left_knee, 15: left_ankle\n",
        "    12: right_hip, 14: right_knee, 16: right_ankle\n",
        "    \"\"\"\n",
        "    angles = {}\n",
        "\n",
        "    # Left elbow angle\n",
        "    if keypoints[5].any() and keypoints[7].any() and keypoints[9].any():\n",
        "        angles['left_elbow'] = calculate_angle(\n",
        "            keypoints[5], keypoints[7], keypoints[9]\n",
        "        )\n",
        "\n",
        "    # Right elbow angle\n",
        "    if keypoints[6].any() and keypoints[8].any() and keypoints[10].any():\n",
        "        angles['right_elbow'] = calculate_angle(\n",
        "            keypoints[6], keypoints[8], keypoints[10]\n",
        "        )\n",
        "\n",
        "    # Left knee angle\n",
        "    if keypoints[11].any() and keypoints[13].any() and keypoints[15].any():\n",
        "        angles['left_knee'] = calculate_angle(\n",
        "            keypoints[11], keypoints[13], keypoints[15]\n",
        "        )\n",
        "\n",
        "    # Right knee angle\n",
        "    if keypoints[12].any() and keypoints[14].any() and keypoints[16].any():\n",
        "        angles['right_knee'] = calculate_angle(\n",
        "            keypoints[12], keypoints[14], keypoints[16]\n",
        "        )\n",
        "\n",
        "    # Left hip angle\n",
        "    # Using shoulder, hip, knee for hip angle\n",
        "    if keypoints[5].any() and keypoints[11].any() and keypoints[13].any():\n",
        "        angles['left_hip'] = calculate_angle(\n",
        "            keypoints[5], keypoints[11], keypoints[13]\n",
        "        )\n",
        "\n",
        "    # Right hip angle\n",
        "    # Using shoulder, hip, knee for hip angle\n",
        "    if keypoints[6].any() and keypoints[12].any() and keypoints[14].any():\n",
        "        angles['right_hip'] = calculate_angle(\n",
        "            keypoints[6], keypoints[12], keypoints[14]\n",
        "        )\n",
        "\n",
        "    return angles\n",
        "\n",
        "print(\"‚úì Angle calculation functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B0zgyI8vlKi"
      },
      "source": [
        "Purpose: Defines movement patterns for different exercise types.\n",
        "\n",
        "What it does:\n",
        "\n",
        "1. **`get_exercise_key_points()`**\n",
        "   - Returns tracking config for each exercise\n",
        "   - Defines: primary joints, movement direction, reference points\n",
        "   - Supports: squat, pushup, plank, lunge, deadlift, curls, presses\n",
        "\n",
        "2. **`calculate_movement_phase()`**\n",
        "   - Determines position in exercise movement\n",
        "   - Tracks: vertical, horizontal, or angular motion\n",
        "   - Returns: normalized phase value (0-1)\n",
        "\n",
        "3. **`normalize_phases()`**\n",
        "   - Scales phase values to 0-1 range\n",
        "   - Enables comparison across different videos\n",
        "\n",
        "4. **`detect_reps()`**\n",
        "   - Finds peaks and valleys in movement\n",
        "   - Identifies complete repetitions\n",
        "   - Returns: start, peak, end frame indices per rep\n",
        "\n",
        "5. **`find_matching_frame_by_phase()`**\n",
        "   - Matches user frame to reference frame\n",
        "   - Based on movement phase (not time)\n",
        "   - Enables accurate form comparison\n",
        "\n",
        "6. **`match_reps()`**\n",
        "   - Pairs corresponding reps between videos\n",
        "   - Returns: matched rep data for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqKUZCHnEXIw"
      },
      "outputs": [],
      "source": [
        "def get_exercise_key_points(exercise_type):\n",
        "    \"\"\"\n",
        "    Return the key body points to track for each exercise type\n",
        "    \"\"\"\n",
        "    exercise_tracking = {\n",
        "        'squat': {\n",
        "            'primary_joint': 'hip',  # Main joint to track movement\n",
        "            'keypoint_indices': [11, 12],  # Hip keypoints\n",
        "            'direction': 'vertical',  # Movement direction\n",
        "            'reference_point': 'shoulder',  # Point to measure relative to\n",
        "            'reference_indices': [5, 6]\n",
        "        },\n",
        "        'pushup': {\n",
        "            'primary_joint': 'shoulder',\n",
        "            'keypoint_indices': [5, 6],\n",
        "            'direction': 'vertical',\n",
        "            'reference_point': 'hip',\n",
        "            'reference_indices': [11, 12]\n",
        "        },\n",
        "        'plank': {\n",
        "            'primary_joint': 'hip',\n",
        "            'keypoint_indices': [11, 12],\n",
        "            'direction': 'vertical',\n",
        "            'reference_point': 'shoulder',\n",
        "            'reference_indices': [5, 6]\n",
        "        },\n",
        "        'lunge': {\n",
        "            'primary_joint': 'knee',\n",
        "            'keypoint_indices': [13, 14],\n",
        "            'direction': 'vertical',\n",
        "            'reference_point': 'hip',\n",
        "            'reference_indices': [11, 12]\n",
        "        },\n",
        "        'deadlift': {\n",
        "            'primary_joint': 'hip',\n",
        "            'keypoint_indices': [11, 12],\n",
        "            'direction': 'vertical',\n",
        "            'reference_point': 'ankle',\n",
        "            'reference_indices': [15, 16]\n",
        "        },\n",
        "        'bicep_curl': {\n",
        "            'primary_joint': 'elbow',\n",
        "            'keypoint_indices': [7, 8],\n",
        "            'direction': 'angular',\n",
        "            'reference_point': 'shoulder',\n",
        "            'reference_indices': [5, 6]\n",
        "        },\n",
        "        'shoulder_press': {\n",
        "            'primary_joint': 'elbow',\n",
        "            'keypoint_indices': [7, 8],\n",
        "            'direction': 'vertical',\n",
        "            'reference_point': 'shoulder',\n",
        "            'reference_indices': [5, 6]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return exercise_tracking.get(exercise_type, {\n",
        "        'primary_joint': 'hip',\n",
        "        'keypoint_indices': [11, 12],\n",
        "        'direction': 'vertical',\n",
        "        'reference_point': 'shoulder',\n",
        "        'reference_indices': [5, 6]\n",
        "    })\n",
        "\n",
        "\n",
        "def calculate_movement_phase(keypoints, exercise_type):\n",
        "    \"\"\"\n",
        "    Calculate movement phase for any exercise type\n",
        "    Returns: phase value that represents position in movement\n",
        "    \"\"\"\n",
        "    tracking_config = get_exercise_key_points(exercise_type)\n",
        "\n",
        "    # Get primary joint position\n",
        "    primary_indices = tracking_config['keypoint_indices']\n",
        "    primary_pos = []\n",
        "\n",
        "    for idx in primary_indices:\n",
        "        if idx < len(keypoints) and keypoints[idx].any():\n",
        "            primary_pos.append(keypoints[idx])\n",
        "\n",
        "    if not primary_pos:\n",
        "        return None\n",
        "\n",
        "    # Average position of primary joints\n",
        "    primary_avg = np.mean(primary_pos, axis=0)\n",
        "\n",
        "    # Get reference point position\n",
        "    reference_indices = tracking_config['reference_indices']\n",
        "    reference_pos = []\n",
        "\n",
        "    for idx in reference_indices:\n",
        "        if idx < len(keypoints) and keypoints[idx].any():\n",
        "            reference_pos.append(keypoints[idx])\n",
        "\n",
        "    if not reference_pos:\n",
        "        return None\n",
        "\n",
        "    reference_avg = np.mean(reference_pos, axis=0)\n",
        "\n",
        "    # Calculate phase based on direction\n",
        "    direction = tracking_config['direction']\n",
        "\n",
        "    if direction == 'vertical':\n",
        "        # Vertical movement (up/down)\n",
        "        phase = primary_avg[1] - reference_avg[1]  # Y-axis difference\n",
        "    elif direction == 'horizontal':\n",
        "        # Horizontal movement (left/right)\n",
        "        phase = primary_avg[0] - reference_avg[0]  # X-axis difference\n",
        "    elif direction == 'angular':\n",
        "        # Angular movement (like bicep curl)\n",
        "        # Calculate angle between joints\n",
        "        if len(keypoints) > max(primary_indices + reference_indices):\n",
        "            # Use calculate_angle function you already have\n",
        "            phase = calculate_angle(reference_avg, primary_avg,\n",
        "                                   keypoints[primary_indices[0] + 2] if primary_indices[0] + 2 < len(keypoints) else primary_avg)\n",
        "        else:\n",
        "            phase = primary_avg[1]\n",
        "    else:\n",
        "        # Default to vertical\n",
        "        phase = primary_avg[1]\n",
        "\n",
        "    return phase\n",
        "\n",
        "\n",
        "def normalize_phases(phases):\n",
        "    \"\"\"\n",
        "    Normalize phase values to 0-1 range\n",
        "    \"\"\"\n",
        "    if not phases or len(phases) == 0:\n",
        "        return []\n",
        "\n",
        "    valid_phases = [p for p in phases if p is not None]\n",
        "\n",
        "    if not valid_phases:\n",
        "        return []\n",
        "\n",
        "    min_phase = min(valid_phases)\n",
        "    max_phase = max(valid_phases)\n",
        "    phase_range = max_phase - min_phase\n",
        "\n",
        "    if phase_range == 0:\n",
        "        return [0.5] * len(phases)\n",
        "\n",
        "    normalized = []\n",
        "    for phase in phases:\n",
        "        if phase is not None:\n",
        "            norm_phase = (phase - min_phase) / phase_range\n",
        "            normalized.append(norm_phase)\n",
        "        else:\n",
        "            normalized.append(None)\n",
        "\n",
        "    return normalized\n",
        "\n",
        "\n",
        "def detect_reps(phases, exercise_type):\n",
        "    \"\"\"\n",
        "    Detect complete repetitions for any exercise\n",
        "    Returns: list of (start_idx, peak_idx, end_idx) tuples for each rep\n",
        "    \"\"\"\n",
        "    if not phases or len(phases) < 3:\n",
        "        return []\n",
        "\n",
        "    tracking_config = get_exercise_key_points(exercise_type)\n",
        "\n",
        "    # Detect peaks and valleys\n",
        "    peaks = []  # Maximum extension/top position\n",
        "    valleys = []  # Minimum position/bottom\n",
        "\n",
        "    # Find local maxima and minima\n",
        "    for i in range(1, len(phases) - 1):\n",
        "        if phases[i] is None:\n",
        "            continue\n",
        "\n",
        "        prev_phase = phases[i-1] if phases[i-1] is not None else phases[i]\n",
        "        next_phase = phases[i+1] if phases[i+1] is not None else phases[i]\n",
        "\n",
        "        # Peak detection (local maximum)\n",
        "        if phases[i] >= prev_phase and phases[i] >= next_phase:\n",
        "            if not peaks or i - peaks[-1] > 5:  # Minimum 5 frames between peaks\n",
        "                peaks.append(i)\n",
        "\n",
        "        # Valley detection (local minimum)\n",
        "        if phases[i] <= prev_phase and phases[i] <= next_phase:\n",
        "            if not valleys or i - valleys[-1] > 5:  # Minimum 5 frames between valleys\n",
        "                valleys.append(i)\n",
        "\n",
        "    # Determine rep structure based on exercise\n",
        "    # For most exercises: valley (start) -> peak (mid) -> valley (end)\n",
        "    reps = []\n",
        "\n",
        "    if len(valleys) >= 2:\n",
        "        for i in range(len(valleys) - 1):\n",
        "            start = valleys[i]\n",
        "            end = valleys[i + 1]\n",
        "\n",
        "            # Find peak between valleys\n",
        "            peaks_between = [p for p in peaks if start < p < end]\n",
        "            peak = peaks_between[0] if peaks_between else (start + end) // 2\n",
        "\n",
        "            reps.append({\n",
        "                'start': start,\n",
        "                'peak': peak,\n",
        "                'end': end,\n",
        "                'phase_range': abs(phases[peak] - phases[start]) if phases[peak] and phases[start] else 0\n",
        "            })\n",
        "\n",
        "    return reps\n",
        "\n",
        "\n",
        "def find_matching_frame_by_phase(ref_phases, user_phase_value, search_window=None):\n",
        "    \"\"\"\n",
        "    Find the reference frame that best matches a given phase value\n",
        "\n",
        "    Args:\n",
        "        ref_phases: List of normalized phase values from reference video\n",
        "        user_phase_value: Current phase value to match\n",
        "        search_window: Optional tuple (start, end) to limit search range\n",
        "    \"\"\"\n",
        "    if user_phase_value is None or not ref_phases:\n",
        "        return None\n",
        "\n",
        "    # Set search range\n",
        "    if search_window:\n",
        "        start_idx, end_idx = search_window\n",
        "        search_phases = ref_phases[start_idx:end_idx]\n",
        "        offset = start_idx\n",
        "    else:\n",
        "        search_phases = ref_phases\n",
        "        offset = 0\n",
        "\n",
        "    # Find closest match\n",
        "    best_match = None\n",
        "    best_diff = float('inf')\n",
        "\n",
        "    for idx, ref_phase in enumerate(search_phases):\n",
        "        if ref_phase is None:\n",
        "            continue\n",
        "\n",
        "        diff = abs(ref_phase - user_phase_value)\n",
        "        if diff < best_diff:\n",
        "            best_diff = diff\n",
        "            best_match = idx + offset\n",
        "\n",
        "    return best_match\n",
        "\n",
        "\n",
        "def match_reps(ref_reps, user_reps, ref_phases, user_phases):\n",
        "    \"\"\"\n",
        "    Match corresponding reps between reference and user videos\n",
        "    Returns list of matched rep pairs with their key frames\n",
        "    \"\"\"\n",
        "    matched_reps = []\n",
        "\n",
        "    num_matched = min(len(ref_reps), len(user_reps))\n",
        "\n",
        "    for i in range(num_matched):\n",
        "        ref_rep = ref_reps[i]\n",
        "        user_rep = user_reps[i]\n",
        "\n",
        "        matched_reps.append({\n",
        "            'rep_number': i + 1,\n",
        "            'ref_start': ref_rep['start'],\n",
        "            'ref_peak': ref_rep['peak'],\n",
        "            'ref_end': ref_rep['end'],\n",
        "            'user_start': user_rep['start'],\n",
        "            'user_peak': user_rep['peak'],\n",
        "            'user_end': user_rep['end'],\n",
        "            'ref_phase_range': ref_rep['phase_range'],\n",
        "            'user_phase_range': user_rep['phase_range']\n",
        "        })\n",
        "\n",
        "    return matched_reps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tTKU121v88h"
      },
      "source": [
        "Purpose: Compares user's form against reference with exercise-specific feedback.\n",
        "\n",
        "What it does:\n",
        "\n",
        "- `compare_form_exercise_specific()` function:\n",
        "  - Compares joint angles between reference and user\n",
        "  - Uses stricter thresholds for critical joints\n",
        "  - Generates specific, actionable feedback\n",
        "  - Categorizes issues by severity (CRITICAL/MODERATE)\n",
        "\n",
        "**Example feedback:**\n",
        "- \"‚ö†Ô∏è Left Knee: Squat deeper - aim for 90¬∞ (currently 110¬∞)\"\n",
        "- \"‚ö†Ô∏è Right Hip: Push hips back - improve hip hinge\"\n",
        "\n",
        "**Thresholds:**\n",
        "- Primary joints: ¬±15¬∞ tolerance\n",
        "- Secondary joints: ¬±20¬∞ tolerance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpPhCvQVBzTe"
      },
      "outputs": [],
      "source": [
        "def compare_form_exercise_specific(reference_angles, user_angles, exercise_type='squat', threshold=15):\n",
        "    \"\"\"\n",
        "    Compare user's form against reference with exercise-specific focus\n",
        "    \"\"\"\n",
        "    feedback = []\n",
        "    issues = {}\n",
        "\n",
        "    # Get critical joints for this exercise\n",
        "    critical_joints_info = get_exercise_critical_joints(exercise_type)\n",
        "    primary_joints = critical_joints_info['primary']\n",
        "\n",
        "    for joint, ref_angle in reference_angles.items():\n",
        "        if joint in user_angles:\n",
        "            user_angle = user_angles[joint]\n",
        "            difference = abs(ref_angle - user_angle)\n",
        "\n",
        "            # Use stricter threshold for primary joints\n",
        "            joint_threshold = threshold if joint in primary_joints else threshold + 5\n",
        "\n",
        "            if difference > joint_threshold:\n",
        "                # Mark severity\n",
        "                severity = 'CRITICAL' if joint in primary_joints else 'MODERATE'\n",
        "\n",
        "                issues[joint] = {\n",
        "                    'reference': ref_angle,\n",
        "                    'user': user_angle,\n",
        "                    'difference': difference,\n",
        "                    'severity': severity\n",
        "                }\n",
        "\n",
        "                # Generate exercise-specific feedback\n",
        "                joint_name = joint.replace('_', ' ').title()\n",
        "\n",
        "                if exercise_type == 'squat':\n",
        "                    if 'knee' in joint:\n",
        "                        if user_angle < ref_angle:\n",
        "                            feedback.append(f\"‚ö†Ô∏è {joint_name}: Squat deeper - aim for 90¬∞ (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "                        else:\n",
        "                            feedback.append(f\"‚ö†Ô∏è {joint_name}: Control depth - don't over-extend (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "                    elif 'hip' in joint:\n",
        "                        if user_angle < ref_angle:\n",
        "                            feedback.append(f\"‚ö†Ô∏è {joint_name}: Push hips back - improve hip hinge (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "                        else:\n",
        "                            feedback.append(f\"‚ö†Ô∏è {joint_name}: Maintain upright torso (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "                    else:\n",
        "                        feedback.append(f\"‚ö†Ô∏è {joint_name}: Adjust form (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "\n",
        "                else:\n",
        "                    # Generic feedback for other exercises\n",
        "                    if 'elbow' in joint:\n",
        "                        if user_angle < ref_angle:\n",
        "                            feedback.append(f\"‚ö†Ô∏è {joint_name}: Bend arm more (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "                        else:\n",
        "                            feedback.append(f\"‚ö†Ô∏è {joint_name}: Straighten arm more (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "                    elif 'knee' in joint:\n",
        "                        if user_angle < ref_angle:\n",
        "                            feedback.append(f\"‚ö†Ô∏è {joint_name}: Squat deeper (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "                        else:\n",
        "                            feedback.append(f\"‚ö†Ô∏è {joint_name}: Don't bend as much (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "                    elif 'hip' in joint:\n",
        "                        feedback.append(f\"‚ö†Ô∏è {joint_name}: Adjust hip angle (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "                    else:\n",
        "                        feedback.append(f\"‚ö†Ô∏è {joint_name}: Adjust form (currently {user_angle:.1f}¬∞, target {ref_angle:.1f}¬∞)\")\n",
        "\n",
        "    return feedback, issues"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kYJaUkpwFpJ"
      },
      "source": [
        "Purpose: Extracts pose data from both reference and user videos.\n",
        "\n",
        "What it does:\n",
        "\n",
        "- Runs `extract_keypoints_from_video()` on both videos\n",
        "- Processes all frames\n",
        "- Shows progress for each video\n",
        "- Stores keypoint arrays for later comparison\n",
        "\n",
        "Processing time:\n",
        "- ~10 seconds for 30-second video\n",
        "- Depends on video length and GPU speed\n",
        "\n",
        "Output:\n",
        "- `reference_keypoints` - pose data from correct form video\n",
        "- `user_keypoints` - pose data from user's video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldU5t-9MXm4v"
      },
      "outputs": [],
      "source": [
        "# Extract keypoints from both videos\n",
        "print(\"Processing reference video (correct form)...\")\n",
        "reference_keypoints, ref_frames = extract_keypoints_from_video(reference_video)\n",
        "print(f\"‚úì Processed {ref_frames} frames from reference video\")\n",
        "\n",
        "print(\"\\nProcessing user video...\")\n",
        "user_keypoints, user_frames = extract_keypoints_from_video(user_video)\n",
        "print(f\"‚úì Processed {user_frames} frames from user video\")\n",
        "\n",
        "print(f\"\\n‚úì Total frames to compare: {min(ref_frames, user_frames)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgts-zu_wRcD"
      },
      "source": [
        "Purpose: Automatically identifies which exercise is being performed.\n",
        "\n",
        "Key Functions:\n",
        "\n",
        "1. **`detect_exercise_type()`**\n",
        "   - Analyzes first 30 frames\n",
        "   - Measures: hip movement, knee angles, shoulder movement\n",
        "   - Returns: 'squat', 'pushup', 'plank', 'lunge', 'deadlift', or 'unknown'\n",
        "\n",
        "**Detection criteria:**\n",
        "- **Squat:** Large hip movement + knee flexion (>40¬∞) + low knee angle\n",
        "- **Pushup:** Significant shoulder movement, horizontal body\n",
        "- **Plank:** Minimal movement, horizontal body\n",
        "- **Lunge:** Moderate knee flexion (30-60¬∞)\n",
        "- **Deadlift:** Hip hinge pattern, minimal knee bend\n",
        "\n",
        "2. **`get_reference_video_path()`**\n",
        "   - Finds appropriate reference video for detected exercise\n",
        "   - Searches Good Form folder\n",
        "\n",
        "\n",
        "3. **`get_exercise_critical_joints()`**\n",
        "   - Returns most important joints for each exercise\n",
        "   - Defines focus areas for analysis\n",
        "\n",
        "**Why automatic detection?**\n",
        "- User doesn't need to specify exercise type\n",
        "- Simplifies workflow\n",
        "- Enables multi-exercise analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn1BBynq-leh"
      },
      "outputs": [],
      "source": [
        "def detect_exercise_type(keypoints_sequence, num_frames=30):\n",
        "    \"\"\"\n",
        "    Detect exercise type based on keypoint movement patterns\n",
        "    Analyzes first 30 frames to determine exercise\n",
        "\n",
        "    Returns: 'squat', 'pushup', 'plank', 'lunge', or 'unknown'\n",
        "    \"\"\"\n",
        "    if len(keypoints_sequence) < num_frames:\n",
        "        num_frames = len(keypoints_sequence)\n",
        "\n",
        "    # Analyze sample frames\n",
        "    vertical_movement = []\n",
        "    horizontal_movement = []\n",
        "    hip_heights = []\n",
        "    shoulder_heights = []\n",
        "    knee_angles = []\n",
        "\n",
        "    for i in range(num_frames):\n",
        "        kp = keypoints_sequence[i]\n",
        "\n",
        "        # Check if keypoints are valid\n",
        "        if len(kp) < 17:\n",
        "            continue\n",
        "\n",
        "        # Calculate key measurements\n",
        "        # Hip position (average of left and right hip)\n",
        "        if kp[11].any() and kp[12].any():\n",
        "            hip_y = (kp[11][1] + kp[12][1]) / 2\n",
        "            hip_heights.append(hip_y)\n",
        "\n",
        "        # Shoulder position\n",
        "        if kp[5].any() and kp[6].any():\n",
        "            shoulder_y = (kp[5][1] + kp[6][1]) / 2\n",
        "            shoulder_heights.append(shoulder_y)\n",
        "\n",
        "        # Knee angle (for squat detection)\n",
        "        if kp[11].any() and kp[13].any() and kp[15].any():\n",
        "            knee_angle = calculate_angle(kp[11], kp[13], kp[15])\n",
        "            knee_angles.append(knee_angle)\n",
        "\n",
        "    # Calculate movement statistics\n",
        "    if len(hip_heights) > 1:\n",
        "        hip_range = max(hip_heights) - min(hip_heights)\n",
        "        hip_variance = np.var(hip_heights)\n",
        "    else:\n",
        "        hip_range = 0\n",
        "        hip_variance = 0\n",
        "\n",
        "    if len(knee_angles) > 1:\n",
        "        knee_range = max(knee_angles) - min(knee_angles)\n",
        "        avg_knee_angle = np.mean(knee_angles)\n",
        "    else:\n",
        "        knee_range = 0\n",
        "        avg_knee_angle = 180\n",
        "\n",
        "    # Decision tree for exercise classification\n",
        "    print(f\"\\nExercise Detection Analysis:\")\n",
        "    print(f\"  Hip movement range: {hip_range:.1f}\")\n",
        "    print(f\"  Knee angle range: {knee_range:.1f}¬∞\")\n",
        "    print(f\"  Average knee angle: {avg_knee_angle:.1f}¬∞\")\n",
        "\n",
        "    # SQUAT: Large vertical hip movement + significant knee flexion\n",
        "    if hip_range > 50 and knee_range > 40 and avg_knee_angle < 140:\n",
        "        return 'squat'\n",
        "\n",
        "    # PUSHUP: Shoulders move significantly, body horizontal\n",
        "    elif len(shoulder_heights) > 1 and np.var(shoulder_heights) > 30:\n",
        "        return 'pushup'\n",
        "\n",
        "    # PLANK: Minimal movement, body horizontal\n",
        "    elif hip_variance < 10 and len(shoulder_heights) > 1 and np.var(shoulder_heights) < 10:\n",
        "        return 'plank'\n",
        "\n",
        "    # LUNGE: Moderate knee flexion, alternating pattern\n",
        "    elif knee_range > 30 and knee_range < 60:\n",
        "        return 'lunge'\n",
        "\n",
        "    # DEADLIFT: Hip hinge pattern\n",
        "    elif hip_range > 40 and knee_range < 30:\n",
        "        return 'deadlift'\n",
        "\n",
        "    else:\n",
        "        return 'unknown'\n",
        "\n",
        "\n",
        "def get_reference_video_path(exercise_type):\n",
        "    \"\"\"\n",
        "    Get the appropriate reference video path based on detected exercise\n",
        "    \"\"\"\n",
        "    reference_folder = '/content/Good Form'\n",
        "\n",
        "    # Try to find a video file in the folder that matches the exercise\n",
        "    if os.path.exists(reference_folder):\n",
        "        video_files = [f for f in os.listdir(reference_folder)\n",
        "                      if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
        "\n",
        "        if video_files:\n",
        "            # Return first video found\n",
        "            return os.path.join(reference_folder, video_files[0])\n",
        "\n",
        "    # Fallback to specific paths\n",
        "    reference_videos = {\n",
        "        'squat': '/content/Good Form/8837221-uhd_2160_4096_25fps.mp4',\n",
        "        'pushup': '/content/Good Form/pushup.mp4',\n",
        "        'plank': '/content/Good Form/plank.mp4',\n",
        "        'lunge': '/content/Good Form/lunge.mp4',\n",
        "        'deadlift': '/content/Good Form/deadlift.mp4'\n",
        "    }\n",
        "\n",
        "    return reference_videos.get(exercise_type, None)\n",
        "\n",
        "\n",
        "def get_exercise_critical_joints(exercise_type):\n",
        "    \"\"\"\n",
        "    Return the most important joints to analyze for each exercise type\n",
        "    \"\"\"\n",
        "    exercise_joints = {\n",
        "        'squat': {\n",
        "            'primary': ['left_knee', 'right_knee', 'left_hip', 'right_hip'],\n",
        "            'secondary': ['left_ankle', 'right_ankle'],\n",
        "            'focus': 'Lower body alignment and depth'\n",
        "        },\n",
        "        'pushup': {\n",
        "            'primary': ['left_elbow', 'right_elbow', 'left_shoulder', 'right_shoulder'],\n",
        "            'secondary': ['left_hip', 'right_hip'],\n",
        "            'focus': 'Upper body and core stability'\n",
        "        },\n",
        "        'plank': {\n",
        "            'primary': ['left_hip', 'right_hip', 'left_shoulder', 'right_shoulder'],\n",
        "            'secondary': ['left_elbow', 'right_elbow'],\n",
        "            'focus': 'Core stability and body alignment'\n",
        "        },\n",
        "        'lunge': {\n",
        "            'primary': ['left_knee', 'right_knee', 'left_hip', 'right_hip'],\n",
        "            'secondary': ['left_ankle', 'right_ankle'],\n",
        "            'focus': 'Balance and knee alignment'\n",
        "        },\n",
        "        'deadlift': {\n",
        "            'primary': ['left_hip', 'right_hip', 'left_knee', 'right_knee'],\n",
        "            'secondary': ['left_shoulder', 'right_shoulder'],\n",
        "            'focus': 'Hip hinge and back position'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return exercise_joints.get(exercise_type, {\n",
        "        'primary': ['left_knee', 'right_knee', 'left_hip', 'right_hip',\n",
        "                   'left_elbow', 'right_elbow'],\n",
        "        'secondary': [],\n",
        "        'focus': 'Overall form'\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR62Ffq_wsw0"
      },
      "source": [
        "**Purpose:** Detects exercise type and selects appropriate reference video.\n",
        "\n",
        "**What it does:**\n",
        "1. Analyzes user video keypoints\n",
        "2. Determines exercise type (squat, pushup, etc.)\n",
        "3. Finds matching reference video\n",
        "4. Loads exercise-specific critical joints\n",
        "5. Prepares for form comparison\n",
        "\n",
        "**Output displayed:**\n",
        "- Detected exercise type\n",
        "- Reference video being used\n",
        "- Primary joints to focus on\n",
        "- Analysis focus description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEp7WvTs-NL8"
      },
      "outputs": [],
      "source": [
        "# ========== AUTOMATIC EXERCISE DETECTION ==========\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: DETECTING EXERCISE TYPE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Extract keypoints from user video for detection\n",
        "print(\"\\nAnalyzing user video...\")\n",
        "user_keypoints_sample, _ = extract_keypoints_from_video(user_video)\n",
        "\n",
        "# Detect exercise type\n",
        "detected_exercise = detect_exercise_type(user_keypoints_sample, num_frames=50)\n",
        "\n",
        "print(f\"\\n‚úì Detected Exercise: {detected_exercise.upper()}\")\n",
        "\n",
        "# Get appropriate reference video\n",
        "if detected_exercise != 'unknown':\n",
        "    auto_reference_video = get_reference_video_path(detected_exercise)\n",
        "\n",
        "    if auto_reference_video and os.path.exists(auto_reference_video):\n",
        "        reference_video = auto_reference_video\n",
        "        print(f\"‚úì Using reference video: {reference_video}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Reference video for {detected_exercise} not found!\")\n",
        "        print(f\"  Please add: {auto_reference_video}\")\n",
        "        print(f\"  Falling back to manual selection...\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Could not detect exercise type\")\n",
        "    print(\"  Using manually specified reference video...\")\n",
        "\n",
        "# Get exercise-specific joints to focus on\n",
        "critical_joints = get_exercise_critical_joints(detected_exercise)\n",
        "print(f\"\\n‚úì Focus areas for {detected_exercise}:\")\n",
        "print(f\"  Primary joints: {', '.join(critical_joints['primary'])}\")\n",
        "print(f\"  Analysis focus: {critical_joints['focus']}\")\n",
        "\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQnMhgm9w7pa"
      },
      "source": [
        "**Purpose:** Processes videos frame-by-frame and creates comparison frames.\n",
        "\n",
        "**What this massive function does:**\n",
        "\n",
        "### Phase 1: Setup & Analysis\n",
        "1. Extracts keypoints from both videos\n",
        "2. Analyzes movement phases for synchronization\n",
        "3. Detects repetitions in both videos\n",
        "4. Matches corresponding reps\n",
        "\n",
        "### Phase 2: Frame Processing\n",
        "5. For each matched rep:\n",
        "   - Reads user frame\n",
        "   - Finds matching reference frame by movement phase\n",
        "   - Compares joint angles\n",
        "   - Detects form issues\n",
        "   - Tracks worst frame\n",
        "\n",
        "### Phase 3: Visualization\n",
        "6. Runs YOLO visualization on both frames\n",
        "7. Resizes frames to consistent dimensions (720p height)\n",
        "8. **Ensures dimensions are even for FFmpeg compatibility**\n",
        "9. Adds feedback text and rep counter\n",
        "10. Combines frames side-by-side\n",
        "11. Saves combined frame as JPEG\n",
        "\n",
        "### Phase 4: Statistics\n",
        "12. Calculates accuracy percentage\n",
        "13. Identifies most common issues\n",
        "14. Tracks worst frame details\n",
        "\n",
        "**‚ö†Ô∏è Critical fixes:**\n",
        "- All dimensions forced to be even numbers (FFmpeg requirement)\n",
        "- Consistent 720p height for all frames\n",
        "- Proper aspect ratio preservation\n",
        "\n",
        "**Output:** Dictionary containing:\n",
        "- All frame files in `temp_frames/` folder\n",
        "- Statistics (accuracy, issue counts)\n",
        "- Frame dimensions\n",
        "- Worst frame data\n",
        "- Ready for Cell 2 to create summaries\n",
        "\n",
        "**Processing time:** ~30-60 seconds for a 30-second video\n",
        "\n",
        "---\n",
        "\n",
        "## üìä **Helper Functions: Summary Screen Creators**\n",
        "**Purpose:** Functions to generate the 3 summary screens shown at end of video.\n",
        "\n",
        "\n",
        "\n",
        "**Functions defined:**\n",
        "\n",
        "1. **`create_summary_screen_1()`** - Statistics Summary\n",
        "   - Shows: total frames, accuracy %, most common issues\n",
        "   - Duration: 3 seconds\n",
        "   - Black background with white/yellow text\n",
        "\n",
        "2. **`create_summary_screen_2()`** - Worst Frame Analysis\n",
        "   - Shows: side-by-side of worst frame\n",
        "   - Highlights: biggest form deviations\n",
        "   - Duration: 5 seconds\n",
        "\n",
        "3. **`create_summary_screen_3()`** - Recommendations\n",
        "   - Shows: overall assessment, top 3 focus areas\n",
        "   - Color-coded: green (excellent), orange (good), red (needs practice)\n",
        "   - Duration: 4 seconds\n",
        "\n",
        "**Design:** All summaries use consistent dimensions and centered text.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ñ∂Ô∏è **Cell 1 Execution: Run Main Processing**\n",
        "**Purpose:** Executes the main video comparison function.\n",
        "\n",
        "**What happens when you run this:**\n",
        "1. Calls `create_complete_comparison_video()` with your videos\n",
        "2. Processes all frames and creates comparison images\n",
        "3. Calculates statistics\n",
        "4. Returns `video_data` dictionary\n",
        "5. **Does NOT create final video yet** - that's Cell 2's job\n",
        "\n",
        "**Parameters:**\n",
        "- `threshold=15` - Form tolerance in degrees\n",
        "- `progression_threshold=85` - Accuracy % needed to advance\n",
        "\n",
        "**Success indicators:**\n",
        "- \"‚úÖ CELL 1 COMPLETE!\"\n",
        "- Shows frame count and accuracy\n",
        "- Confirms temp frames are saved\n",
        "\n",
        "**Next step:** Run Cell 2 to create summary screens and encode final video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYM4mKzA2H9G"
      },
      "outputs": [],
      "source": [
        "# ========== CELL 1: Main Video Processing Function ==========\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "from collections import Counter\n",
        "\n",
        "def create_complete_comparison_video(reference_video, user_video, exercise_type='squat',\n",
        "                                    output_path='comparison_video.mp4', threshold=15,\n",
        "                                    progression_threshold=85, user_id='default_user'):\n",
        "    \"\"\"\n",
        "    Fixed version with proper error handling and frame dimension management\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract keypoints from both videos\n",
        "        print(f\"Processing reference video: {reference_video}...\")\n",
        "        reference_keypoints, ref_frames = extract_keypoints_from_video(reference_video)\n",
        "        print(f\"‚úì Processed {ref_frames} frames from reference video\")\n",
        "\n",
        "        print(f\"\\nProcessing user video: {user_video}...\")\n",
        "        user_keypoints, user_frames = extract_keypoints_from_video(user_video)\n",
        "        print(f\"‚úì Processed {user_frames} frames from user video\")\n",
        "\n",
        "        # Determine video properties\n",
        "        cap_user = cv2.VideoCapture(user_video)\n",
        "        cap_ref = cv2.VideoCapture(reference_video)\n",
        "\n",
        "        if not cap_user.isOpened() or not cap_ref.isOpened():\n",
        "            raise ValueError(\"Failed to open video files\")\n",
        "\n",
        "        user_orig_width = int(cap_user.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        user_orig_height = int(cap_user.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = int(cap_user.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        # CRITICAL: Define consistent dimensions for ALL frames\n",
        "        target_display_height = 720  # Fixed height for consistency\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"CREATING COMPLETE COMPARISON VIDEO\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Exercise: {exercise_type.upper()}\")\n",
        "        print(f\"Original video: {user_orig_width}x{user_orig_height} @ {fps} fps\")\n",
        "        print(f\"Target height: {target_display_height}px\")\n",
        "        print(f\"Angle threshold: {threshold}¬∞\")\n",
        "\n",
        "        # Movement phase analysis\n",
        "        print(\"\\nüìä Analyzing movement phases...\")\n",
        "\n",
        "        ref_phases = [calculate_movement_phase(kp, exercise_type) for kp in reference_keypoints]\n",
        "        ref_normalized_phases = normalize_phases(ref_phases)\n",
        "        print(f\"  ‚úì Reference: {len(ref_phases)} frames analyzed\")\n",
        "\n",
        "        user_phases = [calculate_movement_phase(kp, exercise_type) for kp in user_keypoints]\n",
        "        user_normalized_phases = normalize_phases(user_phases)\n",
        "        print(f\"  ‚úì User: {len(user_phases)} frames analyzed\")\n",
        "\n",
        "        # Detect reps\n",
        "        ref_reps = detect_reps(ref_normalized_phases, exercise_type)\n",
        "        user_reps = detect_reps(user_normalized_phases, exercise_type)\n",
        "        matched_reps = match_reps(ref_reps, user_reps, ref_normalized_phases, user_normalized_phases)\n",
        "\n",
        "        print(f\"\\n  üìà Detected repetitions:\")\n",
        "        print(f\"    Reference: {len(ref_reps)} reps\")\n",
        "        print(f\"    User: {len(user_reps)} reps\")\n",
        "        print(f\"    Matched: {len(matched_reps)} reps\")\n",
        "\n",
        "        # Create temporary directory\n",
        "        frames_dir = 'temp_frames'\n",
        "        if os.path.exists(frames_dir):\n",
        "            shutil.rmtree(frames_dir)\n",
        "        os.makedirs(frames_dir, exist_ok=True)\n",
        "\n",
        "        # Initialize tracking variables\n",
        "        frame_num = 0\n",
        "        total_diff_sum = 0\n",
        "        total_frames_with_issues = 0\n",
        "        issue_counts = Counter()\n",
        "        worst_frame_diff = -1\n",
        "        worst_frame_data = None\n",
        "\n",
        "        # Variables for consistent output dimensions\n",
        "        final_combined_width = None\n",
        "        final_output_height = target_display_height\n",
        "\n",
        "        print(\"\\nüé¨ Processing frames with phase matching...\")\n",
        "\n",
        "        # Process each matched rep\n",
        "        for rep_idx, rep_match in enumerate(matched_reps):\n",
        "            for frame_in_rep_idx in range(max(rep_match['user_start'], 0),\n",
        "                                         min(rep_match['user_end'], len(user_keypoints))):\n",
        "\n",
        "                # Read user frame\n",
        "                cap_user.set(cv2.CAP_PROP_POS_FRAMES, frame_in_rep_idx)\n",
        "                ret_user, user_frame_original = cap_user.read()\n",
        "                if not ret_user:\n",
        "                    break\n",
        "\n",
        "                # Get user keypoints and angles\n",
        "                user_kp_current = user_keypoints[frame_in_rep_idx]\n",
        "                user_angles_current = get_joint_angles(user_kp_current)\n",
        "\n",
        "                # Find matching reference frame\n",
        "                user_phase_value = user_normalized_phases[frame_in_rep_idx]\n",
        "                search_start_ref = max(0, rep_match['ref_start'] - 20)\n",
        "                search_end_ref = min(len(ref_normalized_phases), rep_match['ref_end'] + 20)\n",
        "\n",
        "                matching_ref_frame_idx = find_matching_frame_by_phase(\n",
        "                    ref_normalized_phases, user_phase_value,\n",
        "                    search_window=(search_start_ref, search_end_ref)\n",
        "                )\n",
        "\n",
        "                if matching_ref_frame_idx is None:\n",
        "                    matching_ref_frame_idx = int(ref_frames * (frame_in_rep_idx / user_frames))\n",
        "\n",
        "                # Read reference frame\n",
        "                cap_ref.set(cv2.CAP_PROP_POS_FRAMES, matching_ref_frame_idx)\n",
        "                ret_ref, ref_frame_original = cap_ref.read()\n",
        "                if not ret_ref:\n",
        "                    continue\n",
        "\n",
        "                # Get reference angles\n",
        "                ref_kp_current = reference_keypoints[matching_ref_frame_idx]\n",
        "                ref_angles_current = get_joint_angles(ref_kp_current)\n",
        "\n",
        "                # Compare form\n",
        "                feedback, issues = compare_form_exercise_specific(\n",
        "                    ref_angles_current, user_angles_current, exercise_type, threshold\n",
        "                )\n",
        "\n",
        "                # Calculate frame statistics\n",
        "                if issues:\n",
        "                    frame_diff_sum = sum(issue_data['difference'] for issue_data in issues.values())\n",
        "                    avg_frame_diff = frame_diff_sum / len(issues)\n",
        "                    total_diff_sum += avg_frame_diff\n",
        "\n",
        "                    # Track worst frame\n",
        "                    if avg_frame_diff > worst_frame_diff:\n",
        "                        worst_frame_diff = avg_frame_diff\n",
        "                        worst_frame_data = {\n",
        "                            'frame_num': frame_in_rep_idx,\n",
        "                            'frame_ref': ref_frame_original.copy(),\n",
        "                            'frame_user': user_frame_original.copy(),\n",
        "                            'user_kp': user_kp_current,\n",
        "                            'issues': issues,\n",
        "                            'feedback': feedback\n",
        "                        }\n",
        "                else:\n",
        "                    avg_frame_diff = 0\n",
        "\n",
        "                if feedback:\n",
        "                    total_frames_with_issues += 1\n",
        "                    for issue_joint in issues.keys():\n",
        "                        issue_counts[issue_joint] += 1\n",
        "\n",
        "                # Process frames with YOLO pose visualization\n",
        "                ref_results = model(ref_frame_original, verbose=False)\n",
        "                user_results = model(user_frame_original, verbose=False)\n",
        "\n",
        "                # Plot keypoints\n",
        "                ref_frame_plotted = ref_frame_original.copy()\n",
        "                if ref_results and len(ref_results) > 0:\n",
        "                    ref_frame_plotted = ref_results[0].plot(\n",
        "                        boxes=False, masks=False, probs=False, conf=False,\n",
        "                        kpt_line=True, labels=False\n",
        "                    )\n",
        "\n",
        "                user_frame_plotted = user_frame_original.copy()\n",
        "                if user_results and len(user_results) > 0:\n",
        "                    user_frame_plotted = user_results[0].plot(\n",
        "                        boxes=False, masks=False, probs=False, conf=False,\n",
        "                        kpt_line=True, labels=False\n",
        "                    )\n",
        "\n",
        "                # CRITICAL: Resize both frames to exact same height\n",
        "                ref_aspect_ratio = ref_frame_plotted.shape[1] / ref_frame_plotted.shape[0]\n",
        "                ref_width_resized = int(target_display_height * ref_aspect_ratio)\n",
        "                # Make width even for FFmpeg compatibility\n",
        "                if ref_width_resized % 2 != 0:\n",
        "                    ref_width_resized += 1\n",
        "                ref_frame_final = cv2.resize(ref_frame_plotted, (ref_width_resized, target_display_height))\n",
        "\n",
        "                user_aspect_ratio = user_frame_plotted.shape[1] / user_frame_plotted.shape[0]\n",
        "                user_width_resized = int(target_display_height * user_aspect_ratio)\n",
        "                # Make width even for FFmpeg compatibility\n",
        "                if user_width_resized % 2 != 0:\n",
        "                    user_width_resized += 1\n",
        "                user_frame_final = cv2.resize(user_frame_plotted, (user_width_resized, target_display_height))\n",
        "\n",
        "                # Set combined width on first frame (ensure it's even)\n",
        "                if final_combined_width is None:\n",
        "                    final_combined_width = ref_width_resized + user_width_resized\n",
        "                    # Ensure final width is also even\n",
        "                    if final_combined_width % 2 != 0:\n",
        "                        final_combined_width += 1\n",
        "                    print(f\"  Output dimensions: {final_combined_width}x{target_display_height}\")\n",
        "\n",
        "                # Add feedback text\n",
        "                for i, text_line in enumerate(feedback[:5]):  # Limit to 5 lines\n",
        "                    cv2.putText(user_frame_final, text_line, (10, 30 + i * 30),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "\n",
        "                # Add rep counter\n",
        "                cv2.putText(user_frame_final, f\"Rep: {rep_idx + 1}\",\n",
        "                           (user_width_resized - 150, 30),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
        "\n",
        "                # Combine frames horizontally\n",
        "                combined_frame = np.hstack((ref_frame_final, user_frame_final))\n",
        "\n",
        "                # Verify dimensions\n",
        "                if combined_frame.shape[0] != target_display_height or combined_frame.shape[1] != final_combined_width:\n",
        "                    print(f\"‚ö†Ô∏è Frame dimension mismatch at frame {frame_num}\")\n",
        "                    combined_frame = cv2.resize(combined_frame, (final_combined_width, target_display_height))\n",
        "\n",
        "                # Save frame\n",
        "                frame_path = os.path.join(frames_dir, f'frame_{frame_num:06d}.jpg')\n",
        "                cv2.imwrite(frame_path, combined_frame)\n",
        "                frame_num += 1\n",
        "\n",
        "                if frame_num % 30 == 0:\n",
        "                    print(f\"  Processed {frame_num} frames...\")\n",
        "\n",
        "        cap_ref.release()\n",
        "        cap_user.release()\n",
        "\n",
        "        total_video_frames = frame_num\n",
        "\n",
        "        if total_video_frames == 0:\n",
        "            raise ValueError(\"No frames were processed!\")\n",
        "\n",
        "        # Calculate statistics\n",
        "        accuracy_pct = (1 - (total_frames_with_issues / total_video_frames)) * 100 if total_video_frames > 0 else 0\n",
        "        avg_difference = total_diff_sum / total_frames_with_issues if total_frames_with_issues > 0 else 0\n",
        "        most_common_issues = issue_counts.most_common()\n",
        "\n",
        "        print(f\"\\n‚úì Processed {total_video_frames} video frames\")\n",
        "        print(f\"  Frames with issues: {total_frames_with_issues}\")\n",
        "        print(f\"  Form accuracy: {accuracy_pct:.1f}%\")\n",
        "\n",
        "        # Return data for Cell 2 to create summary screens\n",
        "        return {\n",
        "            'frames_dir': frames_dir,\n",
        "            'frame_num': frame_num,\n",
        "            'fps': fps,\n",
        "            'final_combined_width': final_combined_width,\n",
        "            'target_display_height': target_display_height,\n",
        "            'total_video_frames': total_video_frames,\n",
        "            'total_frames_with_issues': total_frames_with_issues,\n",
        "            'accuracy_pct': accuracy_pct,\n",
        "            'most_common_issues': most_common_issues,\n",
        "            'worst_frame_data': worst_frame_data,\n",
        "            'exercise_type': exercise_type,\n",
        "            'progression_threshold': progression_threshold,\n",
        "            'output_path': output_path,\n",
        "            'user_id': user_id,\n",
        "            'matched_reps': matched_reps,\n",
        "            'avg_difference': avg_difference\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERROR: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "\n",
        "# ========== HELPER FUNCTIONS FOR CELL 2 ==========\n",
        "\n",
        "def create_summary_screen_1(width, height, total_frames, frames_with_issues, accuracy, issues):\n",
        "    \"\"\"Create statistics summary screen\"\"\"\n",
        "    summary = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "    center_x = width // 2\n",
        "    y = 100\n",
        "\n",
        "    # Title\n",
        "    title = \"FORM ANALYSIS SUMMARY\"\n",
        "    text_size = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, 2.0, 4)[0]\n",
        "    cv2.putText(summary, title, (center_x - text_size[0]//2, y),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), 4)\n",
        "    y += 100\n",
        "\n",
        "    # Stats\n",
        "    stats = [\n",
        "        f\"Total Frames: {total_frames}\",\n",
        "        f\"Frames with Issues: {frames_with_issues}\",\n",
        "        f\"Form Accuracy: {accuracy:.1f}%\"\n",
        "    ]\n",
        "\n",
        "    for stat in stats:\n",
        "        text_size = cv2.getTextSize(stat, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]\n",
        "        cv2.putText(summary, stat, (center_x - text_size[0]//2, y),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
        "        y += 70\n",
        "\n",
        "    # Issues\n",
        "    if issues:\n",
        "        y += 30\n",
        "        title = \"MOST COMMON ISSUES\"\n",
        "        text_size = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, 1.3, 3)[0]\n",
        "        cv2.putText(summary, title, (center_x - text_size[0]//2, y),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1.3, (255, 255, 0), 3)\n",
        "        y += 60\n",
        "\n",
        "        for i, (joint, count) in enumerate(issues[:5]):\n",
        "            text = f\"{i+1}. {joint.replace('_', ' ').title()}: {count} times\"\n",
        "            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)[0]\n",
        "            cv2.putText(summary, text, (center_x - text_size[0]//2, y),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
        "            y += 50\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def create_summary_screen_2(worst_data, height, width, exercise_type):\n",
        "    \"\"\"Create worst frame summary screen\"\"\"\n",
        "    # Process worst frames\n",
        "    ref_frame = worst_data['frame_ref']\n",
        "    user_frame = worst_data['frame_user']\n",
        "\n",
        "    # Resize maintaining aspect ratio\n",
        "    ref_aspect = ref_frame.shape[1] / ref_frame.shape[0]\n",
        "    ref_w = int(height * ref_aspect)\n",
        "    ref_resized = cv2.resize(ref_frame, (ref_w, height))\n",
        "\n",
        "    user_aspect = user_frame.shape[1] / user_frame.shape[0]\n",
        "    user_w = int(height * user_aspect)\n",
        "    user_resized = cv2.resize(user_frame, (user_w, height))\n",
        "\n",
        "    # Combine\n",
        "    combined = np.hstack([ref_resized, user_resized])\n",
        "\n",
        "    # Resize to exact output dimensions\n",
        "    summary = cv2.resize(combined, (width, height))\n",
        "\n",
        "    # Add title overlay\n",
        "    cv2.rectangle(summary, (0, 0), (width, 70), (0, 0, 0), -1)\n",
        "    cv2.putText(summary, f\"FRAME NEEDING MOST IMPROVEMENT\",\n",
        "               (50, 45), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 3)\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def create_summary_screen_3(width, height, accuracy, threshold, issues, exercise):\n",
        "    \"\"\"Create recommendations summary screen\"\"\"\n",
        "    summary = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "    center_x = width // 2\n",
        "    y = 100\n",
        "\n",
        "    # Title\n",
        "    title = \"RECOMMENDATIONS\"\n",
        "    text_size = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, 2.0, 4)[0]\n",
        "    cv2.putText(summary, title, (center_x - text_size[0]//2, y),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 2.0, (255, 255, 255), 4)\n",
        "    y += 100\n",
        "\n",
        "    # Assessment\n",
        "    if accuracy >= threshold:\n",
        "        msg = \"EXCELLENT FORM! Ready to progress!\"\n",
        "        color = (0, 255, 0)\n",
        "    elif accuracy >= threshold - 15:\n",
        "        msg = \"GOOD FORM! Keep practicing!\"\n",
        "        color = (0, 165, 255)\n",
        "    else:\n",
        "        msg = \"KEEP PRACTICING!\"\n",
        "        color = (0, 0, 255)\n",
        "\n",
        "    text_size = cv2.getTextSize(msg, cv2.FONT_HERSHEY_SIMPLEX, 1.3, 3)[0]\n",
        "    cv2.putText(summary, msg, (center_x - text_size[0]//2, y),\n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 1.3, color, 3)\n",
        "    y += 100\n",
        "\n",
        "    # Top issues\n",
        "    if issues:\n",
        "        title = \"TOP FOCUS AREAS\"\n",
        "        text_size = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 2)[0]\n",
        "        cv2.putText(summary, title, (center_x - text_size[0]//2, y),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 0), 2)\n",
        "        y += 60\n",
        "\n",
        "        for i, (joint, _) in enumerate(issues[:3]):\n",
        "            text = f\"{i+1}. {joint.replace('_', ' ').title()}\"\n",
        "            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 1.0, 2)[0]\n",
        "            cv2.putText(summary, text, (center_x - text_size[0]//2, y),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)\n",
        "            y += 50\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "# ========== RUN CELL 1 ==========\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING VIDEO COMPARISON ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "video_data = create_complete_comparison_video(\n",
        "    reference_video,\n",
        "    user_video,\n",
        "    exercise_type=detected_exercise,\n",
        "    output_path='comparison_final.mp4',\n",
        "    threshold=15,\n",
        "    progression_threshold=85\n",
        ")\n",
        "\n",
        "if video_data:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ CELL 1 COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"‚úì Processed {video_data['total_video_frames']} frames\")\n",
        "    print(f\"‚úì Form accuracy: {video_data['accuracy_pct']:.1f}%\")\n",
        "    print(f\"‚úì Temporary frames saved in: {video_data['frames_dir']}\")\n",
        "    print(\"\\nüé¨ Now run CELL 2 to create summary screens and finalize video!\")\n",
        "    print(\"=\"*60)\n",
        "else:\n",
        "    print(\"\\n‚ùå Video processing failed. Check errors above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U87x_qDH2scd"
      },
      "source": [
        "## üé¨ **CELL 2: Video Finalization + Workout Logging**\n",
        "**Purpose:** Creates summary screens, encodes video, AND logs your workout.\n",
        "\n",
        "**New Workflow:**\n",
        "1. Creates 3 summary screens\n",
        "2. Encodes final video with FFmpeg\n",
        "3. **NEW:** Prompts for workout details (weight, difficulty, notes)\n",
        "4. **NEW:** Saves enhanced session data\n",
        "5. **NEW:** Option to view progress immediately\n",
        "6. Downloads completed video\n",
        "\n",
        "**What you'll be asked:**\n",
        "- Weight used (0 for bodyweight)\n",
        "- Difficulty level (light/moderate/heavy)\n",
        "- Optional session notes\n",
        "\n",
        "**After logging:**\n",
        "- Choose to view daily/weekly/monthly progress\n",
        "- Or skip and check later with Progress Viewer cell\n",
        "\n",
        "**Run after:** Cell 1 completes successfully"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qhwiOMV2Rui"
      },
      "outputs": [],
      "source": [
        "# ========== CELL 2: Summary Screens and Video Finalization ==========\n",
        "# Run this cell AFTER Cell 1 has completed successfully\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "from google.colab import files\n",
        "\n",
        "# Check if video_data exists from Cell 1\n",
        "if 'video_data' not in globals() or video_data is None:\n",
        "    print(\"‚ùå ERROR: video_data not found!\")\n",
        "    print(\"Please run Cell 1 first to process the video frames.\")\n",
        "else:\n",
        "    try:\n",
        "        # Extract data from Cell 1\n",
        "        frames_dir = video_data['frames_dir']\n",
        "        frame_num = video_data['frame_num']\n",
        "        fps = video_data['fps']\n",
        "        final_combined_width = video_data['final_combined_width']\n",
        "        target_display_height = video_data['target_display_height']\n",
        "\n",
        "        # Ensure dimensions are even for FFmpeg (H.264 requirement)\n",
        "        if final_combined_width % 2 != 0:\n",
        "            final_combined_width += 1\n",
        "        if target_display_height % 2 != 0:\n",
        "            target_display_height += 1\n",
        "\n",
        "        print(f\"Video dimensions (verified even): {final_combined_width}x{target_display_height}\")\n",
        "\n",
        "        total_video_frames = video_data['total_video_frames']\n",
        "        total_frames_with_issues = video_data['total_frames_with_issues']\n",
        "        accuracy_pct = video_data['accuracy_pct']\n",
        "        most_common_issues = video_data['most_common_issues']\n",
        "        worst_frame_data = video_data['worst_frame_data']\n",
        "        exercise_type = video_data['exercise_type']\n",
        "        progression_threshold = video_data['progression_threshold']\n",
        "        output_path = video_data['output_path']\n",
        "        user_id = video_data['user_id']\n",
        "        matched_reps = video_data['matched_reps']\n",
        "        avg_difference = video_data['avg_difference']\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"CREATING SUMMARY SCREENS\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Processing data from {total_video_frames} frames...\")\n",
        "\n",
        "        # Summary 1: Statistics (3 seconds)\n",
        "        print(\"\\n1Ô∏è‚É£ Creating Statistics Summary...\")\n",
        "        summary1 = create_summary_screen_1(\n",
        "            final_combined_width, target_display_height,\n",
        "            total_video_frames, total_frames_with_issues,\n",
        "            accuracy_pct, most_common_issues\n",
        "        )\n",
        "        # Verify dimensions are correct\n",
        "        if summary1.shape[1] != final_combined_width or summary1.shape[0] != target_display_height:\n",
        "            summary1 = cv2.resize(summary1, (final_combined_width, target_display_height))\n",
        "\n",
        "        for i in range(int(3 * fps)):\n",
        "            frame_path = os.path.join(frames_dir, f'frame_{frame_num:06d}.jpg')\n",
        "            cv2.imwrite(frame_path, summary1)\n",
        "            frame_num += 1\n",
        "        print(f\"   ‚úì Added {int(3 * fps)} frames (3 seconds)\")\n",
        "\n",
        "        # Summary 2: Worst Frame (5 seconds)\n",
        "        if worst_frame_data:\n",
        "            print(\"\\n2Ô∏è‚É£ Creating Worst Frame Analysis...\")\n",
        "            summary2 = create_summary_screen_2(\n",
        "                worst_frame_data, target_display_height,\n",
        "                final_combined_width, exercise_type\n",
        "            )\n",
        "            # Verify dimensions are correct\n",
        "            if summary2.shape[1] != final_combined_width or summary2.shape[0] != target_display_height:\n",
        "                summary2 = cv2.resize(summary2, (final_combined_width, target_display_height))\n",
        "\n",
        "            for i in range(int(5 * fps)):\n",
        "                frame_path = os.path.join(frames_dir, f'frame_{frame_num:06d}.jpg')\n",
        "                cv2.imwrite(frame_path, summary2)\n",
        "                frame_num += 1\n",
        "            print(f\"   ‚úì Added {int(5 * fps)} frames (5 seconds)\")\n",
        "        else:\n",
        "            print(\"\\n2Ô∏è‚É£ Skipping Worst Frame (no issues detected)\")\n",
        "\n",
        "        # Summary 3: Recommendations (4 seconds)\n",
        "        print(\"\\n3Ô∏è‚É£ Creating Recommendations...\")\n",
        "        summary3 = create_summary_screen_3(\n",
        "            final_combined_width, target_display_height,\n",
        "            accuracy_pct, progression_threshold,\n",
        "            most_common_issues, exercise_type\n",
        "        )\n",
        "        # Verify dimensions are correct\n",
        "        if summary3.shape[1] != final_combined_width or summary3.shape[0] != target_display_height:\n",
        "            summary3 = cv2.resize(summary3, (final_combined_width, target_display_height))\n",
        "\n",
        "        for i in range(int(4 * fps)):\n",
        "            frame_path = os.path.join(frames_dir, f'frame_{frame_num:06d}.jpg')\n",
        "            cv2.imwrite(frame_path, summary3)\n",
        "            frame_num += 1\n",
        "        print(f\"   ‚úì Added {int(4 * fps)} frames (4 seconds)\")\n",
        "\n",
        "        print(f\"\\n‚úì Total frames created: {frame_num}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Encode video with FFmpeg\n",
        "        print(\"\\nüé¨ Encoding video with FFmpeg...\")\n",
        "        print(\"This may take a minute...\")\n",
        "\n",
        "        result = subprocess.run([\n",
        "            'ffmpeg', '-framerate', str(fps),\n",
        "            '-i', f'{frames_dir}/frame_%06d.jpg',\n",
        "            '-c:v', 'libx264',\n",
        "            '-preset', 'medium',\n",
        "            '-crf', '23',\n",
        "            '-pix_fmt', 'yuv420p',\n",
        "            '-y', output_path\n",
        "        ], capture_output=True, text=True)\n",
        "\n",
        "        # Clean up temporary frames\n",
        "        print(\"üßπ Cleaning up temporary files...\")\n",
        "        shutil.rmtree(frames_dir)\n",
        "\n",
        "        # Check encoding result\n",
        "        if result.returncode != 0:\n",
        "            print(f\"\\n‚ùå FFmpeg encoding failed!\")\n",
        "            print(f\"Error: {result.stderr}\")\n",
        "            output_video = None\n",
        "        elif not os.path.exists(output_path):\n",
        "            print(\"\\n‚ùå Video file was not created\")\n",
        "            output_video = None\n",
        "        else:\n",
        "            # Success!\n",
        "            file_size = os.path.getsize(output_path) / (1024*1024)\n",
        "            duration = frame_num / fps\n",
        "\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(\"‚úÖ VIDEO CREATED SUCCESSFULLY!\")\n",
        "            print(f\"{'='*60}\")\n",
        "            print(f\"üìÅ File: {output_path}\")\n",
        "            print(f\"üíæ Size: {file_size:.2f} MB\")\n",
        "            print(f\"‚è±Ô∏è  Duration: ~{duration:.1f} seconds\")\n",
        "            print(f\"üéûÔ∏è  Total frames: {frame_num}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            # Print progression analysis\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(\"üìä PROGRESSION ANALYSIS\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            if accuracy_pct >= progression_threshold:\n",
        "                print(f\"üéâ EXCELLENT! Form Accuracy: {accuracy_pct:.1f}%\")\n",
        "                print(f\"\\n‚úì You're ready to progress to more challenging exercises!\")\n",
        "                print(f\"\\nüí° Suggested next steps:\")\n",
        "                print(f\"   ‚Ä¢ Add weight/resistance\")\n",
        "                print(f\"   ‚Ä¢ Increase reps or sets\")\n",
        "                print(f\"   ‚Ä¢ Try advanced variations\")\n",
        "            elif accuracy_pct >= progression_threshold - 15:\n",
        "                print(f\"üëç GOOD! Form Accuracy: {accuracy_pct:.1f}%\")\n",
        "                print(f\"\\n‚ö° You're close! Gap: {progression_threshold - accuracy_pct:.1f}%\")\n",
        "                print(f\"\\nüí° Keep practicing:\")\n",
        "                if most_common_issues:\n",
        "                    print(f\"   Focus on: {most_common_issues[0][0].replace('_', ' ').title()}\")\n",
        "                print(f\"   Estimated: 2-3 more sessions to reach {progression_threshold}%\")\n",
        "            else:\n",
        "                print(f\"üìö LEARNING! Form Accuracy: {accuracy_pct:.1f}%\")\n",
        "                print(f\"\\nüéØ Keep practicing fundamentals\")\n",
        "                print(f\"\\nüí° Focus areas:\")\n",
        "                if most_common_issues:\n",
        "                    for i, (joint, count) in enumerate(most_common_issues[:3], 1):\n",
        "                        pct = (count / total_video_frames * 100)\n",
        "                        print(f\"   {i}. {joint.replace('_', ' ').title()} - {pct:.0f}% of frames\")\n",
        "\n",
        "            print(f\"{'='*60}\\n\")\n",
        "\n",
        "            # ========== NEW EXERCISE LEVEL SELECTION ========== #\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"üéØ SELECT NEW EXERCISE LEVEL FOR PATIENT\")\n",
        "            print(\"=\"*60)\n",
        "            print(\"  1. Beginner (Focus on fundamental movements)\")\n",
        "            print(\"  2. Intermediate (Progressive overload, complex movements)\")\n",
        "            print(\"  3. Advanced (High intensity, specialized training)\")\n",
        "            print(\"  4. Rehabilitation (Gentle movements, recovery focus)\")\n",
        "\n",
        "            level_choice = input(\"\\nEnter new exercise level (1-4): \").strip()\n",
        "            level_map = {\n",
        "                '1': 'Beginner',\n",
        "                '2': 'Intermediate',\n",
        "                '3': 'Advanced',\n",
        "                '4': 'Rehabilitation'\n",
        "            }\n",
        "            selected_level = level_map.get(level_choice, 'Not specified')\n",
        "            print(f\"‚úì Selected new exercise level: {selected_level}\")\n",
        "            print(f\"{'='*60}\\n\")\n",
        "            # ================================================== #\n",
        "\n",
        "            # ========== ENHANCED SESSION LOGGING ========== #\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"üìù LOG THIS WORKOUT SESSION\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            # Get workout details from user\n",
        "            workout_details = get_workout_summary()\n",
        "\n",
        "            # Save session data with enhanced tracking\n",
        "            print(\"\\nüíæ Saving session data...\")\n",
        "            save_session_data(\n",
        "                user_id=user_id,\n",
        "                exercise_type=exercise_type,\n",
        "                accuracy_pct=float(accuracy_pct),\n",
        "                total_reps=len(matched_reps),\n",
        "                most_common_issues=most_common_issues,\n",
        "                avg_difference=float(avg_difference),\n",
        "                weight_lbs=workout_details['weight_lbs'],\n",
        "                difficulty_level=workout_details['difficulty_level'],\n",
        "                notes=workout_details['notes']\n",
        "            )\n",
        "            print(\"‚úì Session data saved for progress tracking\\n\")\n",
        "            # =============================================== #\n",
        "\n",
        "            # ========== SHOW PROGRESS ANALYSIS ========== #\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"üìä WOULD YOU LIKE TO VIEW YOUR PROGRESS?\")\n",
        "            print(\"=\"*60)\n",
        "            print(\"  1. View daily progress (last 24 hours)\")\n",
        "            print(\"  2. View weekly progress (last 7 days)\")\n",
        "            print(\"  3. View monthly progress (last 30 days)\")\n",
        "            print(\"  4. View 4-week progress (last 28 days)\")\n",
        "            print(\"  5. View all-time progress\")\n",
        "            print(\"  6. Compare all periods\")\n",
        "            print(\"  7. View progress charts\")\n",
        "\n",
        "            choice = input(\"\\nChoose option (1-7): \").strip()\n",
        "\n",
        "            if choice == '1':\n",
        "                analyze_progress(user_id, exercise_type, 'day')\n",
        "                visualize_progress(user_id, exercise_type, 'week')\n",
        "            elif choice == '2':\n",
        "                analyze_progress(user_id, exercise_type, 'week')\n",
        "                visualize_progress(user_id, exercise_type, 'week')\n",
        "            elif choice == '3':\n",
        "                analyze_progress(user_id, exercise_type, 'month')\n",
        "                visualize_progress(user_id, exercise_type, 'month')\n",
        "            elif choice == '4':\n",
        "                analyze_progress(user_id, exercise_type, '4weeks')\n",
        "                visualize_progress(user_id, exercise_type, '4weeks')\n",
        "            elif choice == '5':\n",
        "                analyze_progress(user_id, exercise_type, 'all')\n",
        "                visualize_progress(user_id, exercise_type, 'all')\n",
        "            else:\n",
        "                print(\"\\n‚úì Skipping progress view. You can view it anytime by running analyze_progress()!\")\n",
        "\n",
        "            # Download the video\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"üì• Downloading video...\")\n",
        "            files.download(output_path)\n",
        "            print(\"‚úì Download complete! Check your Downloads folder.\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            output_video = output_path\n",
        "            # ============================================ #\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERROR: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        print(\"\\nüí° Tip: Make sure Cell 1 completed successfully before running this cell.\")\n",
        "        output_video = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH3MzVRE2Zhp"
      },
      "source": [
        "## üìà **Progress Viewer - Run Anytime**\n",
        "**Purpose:** Check your progress history without processing videos.\n",
        "\n",
        "**Use Cases:**\n",
        "- Review yesterday's workout\n",
        "- Check weekly consistency  \n",
        "- Monitor monthly improvement\n",
        "- Generate new progress charts\n",
        "- Compare time periods\n",
        "\n",
        "**Quick Setup:**\n",
        "1. Set `USER_ID` to your username\n",
        "2. Set `EXERCISE` to exercise type\n",
        "3. Run cell and choose analysis type\n",
        "\n",
        "**Options:**\n",
        "1. Last 24 hours\n",
        "2. Last 7 days\n",
        "3. Last 30 days  \n",
        "4. All time history\n",
        "5. Compare all periods\n",
        "6. View progress charts\n",
        "\n",
        "**No video processing needed!** Fast and lightweight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs_-exdT2YAj"
      },
      "outputs": [],
      "source": [
        "# ========== PROGRESS VIEWER CELL ==========\n",
        "# Run this cell anytime to view your progress history\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"üìä WORKOUT PROGRESS TRACKER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Configuration\n",
        "USER_ID = \"demo_user\"  # Change this to your username\n",
        "EXERCISE = \"squat\"        # Change to: squat, pushup, plank, lunge, deadlift\n",
        "\n",
        "print(f\"\\nüë§ User: {USER_ID}\")\n",
        "print(f\"üèãÔ∏è  Exercise: {EXERCISE.upper()}\")\n",
        "\n",
        "print(\"\\nüìÖ SELECT TIME PERIOD:\")\n",
        "print(\"  1. Last 24 hours\")\n",
        "print(\"  2. Last 7 days\")\n",
        "print(\"  3. Last 30 days\")\n",
        "print(\"  4. Last 4 weeks\")\n",
        "print(\"  5. All time\")\n",
        "print(\"  6. Compare all periods\")\n",
        "print(\"  7. View progress charts\")\n",
        "\n",
        "choice = input(\"\\nEnter choice (1-7): \").strip()\n",
        "\n",
        "if choice == '1':\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä LAST 24 HOURS ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    analyze_progress(USER_ID, EXERCISE, 'day')\n",
        "\n",
        "elif choice == '2':\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä LAST 7 DAYS ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    analyze_progress(USER_ID, EXERCISE, 'week')\n",
        "\n",
        "elif choice == '3':\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä LAST 30 DAYS ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    analyze_progress(USER_ID, EXERCISE, 'month')\n",
        "\n",
        "elif choice == '4':\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä LAST 4 WEEKS ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    analyze_progress(USER_ID, EXERCISE, '4weeks')\n",
        "\n",
        "elif choice == '5':\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä ALL-TIME ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    analyze_progress(USER_ID, EXERCISE, 'all')\n",
        "\n",
        "elif choice == '6':\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä COMPARATIVE ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "    compare_time_periods(USER_ID, EXERCISE)\n",
        "\n",
        "elif choice == '7':\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìä PROGRESS VISUALIZATION\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nSelect time period for chart:\")\n",
        "    print(\"  1. Last 7 days\")\n",
        "    print(\"  2. Last 30 days\")\n",
        "    print(\"  3. Last 3 months\")\n",
        "    print(\"  4. Last 6 months\")\n",
        "    print(\"  5. All time\")\n",
        "    print(\"  6. Last 4 weeks\")\n",
        "\n",
        "    chart_choice = input(\"\\nEnter choice (1-6): \").strip()\n",
        "    period_map = {'1': 'week', '2': 'month', '3': '3months', '4': '6months', '5': 'all', '6': '4weeks'}\n",
        "    period = period_map.get(chart_choice, 'month')\n",
        "\n",
        "    visualize_progress(USER_ID, EXERCISE, period)\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå Invalid choice\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ PROGRESS ANALYSIS COMPLETE\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOpesBzVcspK"
      },
      "source": [
        "## **Nik's Code**\n",
        "## **Extracting skeletal data from video into CSV data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XualQOTQcu3e"
      },
      "outputs": [],
      "source": [
        "# ========== SKELETAL DATA EXTRACTION AND CSV EXPORT ==========\n",
        "# Extracts all 17 YOLO keypoints from video and exports to CSV\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "INPUT_FOLDER = \"/content/input_videos\"\n",
        "OUTPUT_FOLDER = \"/content/output_csvs\"\n",
        "os.makedirs(INPUT_FOLDER, exist_ok=True)\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "def calculate_angle(a, b, c):\n",
        "    \"\"\"\n",
        "    Calculate angle at point b given three points a, b, c.\n",
        "    Returns angle in degrees.\n",
        "    \"\"\"\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "    c = np.array(c)\n",
        "\n",
        "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
        "    angle = np.abs(radians*180.0/np.pi)\n",
        "\n",
        "    if angle > 180.0:\n",
        "        angle = 360-angle\n",
        "\n",
        "    return angle\n",
        "\n",
        "def extract_keypoints_from_video(video_path, model):\n",
        "    \"\"\"\n",
        "    Extract all 17 keypoints and calculate joint angles from video.\n",
        "    Returns list of frame data dictionaries, fps, and total frame count.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Could not open video: {video_path}\")\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    all_frame_data = []\n",
        "    frame_idx = 0\n",
        "\n",
        "    pbar = tqdm(total=total_frames, desc=\"üîç Processing frames\")\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        results = model(frame, verbose=False)\n",
        "        timestamp = frame_idx / fps\n",
        "\n",
        "        # Initialize frame data with defaults\n",
        "        frame_data = {\n",
        "            'frame_number': frame_idx,\n",
        "            'timestamp': round(timestamp, 3),\n",
        "            'overall_confidence': 0.0,\n",
        "        }\n",
        "\n",
        "        # Check if person detected\n",
        "        if results[0].keypoints is not None and len(results[0].keypoints.data) > 0:\n",
        "            keypoints = results[0].keypoints.data[0].cpu().numpy()\n",
        "\n",
        "            # Calculate overall confidence\n",
        "            confidences = keypoints[:, 2]\n",
        "            frame_data['overall_confidence'] = round(float(np.mean(confidences)), 3)\n",
        "\n",
        "            # Extract all 17 keypoints\n",
        "            # YOLO keypoint indices:\n",
        "            # 0: nose, 1: left_eye, 2: right_eye, 3: left_ear, 4: right_ear\n",
        "            # 5: left_shoulder, 6: right_shoulder\n",
        "            # 7: left_elbow, 8: right_elbow\n",
        "            # 9: left_wrist, 10: right_wrist\n",
        "            # 11: left_hip, 12: right_hip\n",
        "            # 13: left_knee, 14: right_knee\n",
        "            # 15: left_ankle, 16: right_ankle\n",
        "\n",
        "            keypoint_names = [\n",
        "                'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',\n",
        "                'left_shoulder', 'right_shoulder',\n",
        "                'left_elbow', 'right_elbow',\n",
        "                'left_wrist', 'right_wrist',\n",
        "                'left_hip', 'right_hip',\n",
        "                'left_knee', 'right_knee',\n",
        "                'left_ankle', 'right_ankle'\n",
        "            ]\n",
        "\n",
        "            try:\n",
        "                # Store all keypoint coordinates\n",
        "                for idx, name in enumerate(keypoint_names):\n",
        "                    frame_data[f'{name}_x'] = round(float(keypoints[idx][0]), 2)\n",
        "                    frame_data[f'{name}_y'] = round(float(keypoints[idx][1]), 2)\n",
        "                    frame_data[f'{name}_confidence'] = round(float(keypoints[idx][2]), 3)\n",
        "\n",
        "                # Calculate joint angles\n",
        "\n",
        "                # Left knee angle (hip-knee-ankle)\n",
        "                left_hip = [keypoints[11][0], keypoints[11][1]]\n",
        "                left_knee = [keypoints[13][0], keypoints[13][1]]\n",
        "                left_ankle = [keypoints[15][0], keypoints[15][1]]\n",
        "                frame_data['left_knee_angle'] = round(\n",
        "                    calculate_angle(left_hip, left_knee, left_ankle), 1\n",
        "                )\n",
        "\n",
        "                # Right knee angle\n",
        "                right_hip = [keypoints[12][0], keypoints[12][1]]\n",
        "                right_knee = [keypoints[14][0], keypoints[14][1]]\n",
        "                right_ankle = [keypoints[16][0], keypoints[16][1]]\n",
        "                frame_data['right_knee_angle'] = round(\n",
        "                    calculate_angle(right_hip, right_knee, right_ankle), 1\n",
        "                )\n",
        "\n",
        "                # Left hip angle (shoulder-hip-knee)\n",
        "                left_shoulder = [keypoints[5][0], keypoints[5][1]]\n",
        "                frame_data['left_hip_angle'] = round(\n",
        "                    calculate_angle(left_shoulder, left_hip, left_knee), 1\n",
        "                )\n",
        "\n",
        "                # Right hip angle\n",
        "                right_shoulder = [keypoints[6][0], keypoints[6][1]]\n",
        "                frame_data['right_hip_angle'] = round(\n",
        "                    calculate_angle(right_shoulder, right_hip, right_knee), 1\n",
        "                )\n",
        "\n",
        "                # Left elbow angle (shoulder-elbow-wrist)\n",
        "                left_elbow = [keypoints[7][0], keypoints[7][1]]\n",
        "                left_wrist = [keypoints[9][0], keypoints[9][1]]\n",
        "                frame_data['left_elbow_angle'] = round(\n",
        "                    calculate_angle(left_shoulder, left_elbow, left_wrist), 1\n",
        "                )\n",
        "\n",
        "                # Right elbow angle\n",
        "                right_elbow = [keypoints[8][0], keypoints[8][1]]\n",
        "                right_wrist = [keypoints[10][0], keypoints[10][1]]\n",
        "                frame_data['right_elbow_angle'] = round(\n",
        "                    calculate_angle(right_shoulder, right_elbow, right_wrist), 1\n",
        "                )\n",
        "\n",
        "            except (IndexError, ValueError) as e:\n",
        "                # If any keypoint is missing, angles will be NaN\n",
        "                pass\n",
        "\n",
        "        all_frame_data.append(frame_data)\n",
        "        frame_idx += 1\n",
        "        pbar.update(1)\n",
        "\n",
        "    pbar.close()\n",
        "    cap.release()\n",
        "\n",
        "    return all_frame_data, fps, total_frames\n",
        "\n",
        "# ========== MAIN WORKFLOW ==========\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üìπ SKELETAL DATA EXTRACTION AND CSV EXPORT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Video upload options\n",
        "print(\"\\nüé¨ VIDEO UPLOAD OPTIONS:\")\n",
        "print(\"  Option 1: Upload a file from your computer\")\n",
        "print(\"  Option 2: Specify a Google Drive path\")\n",
        "print()\n",
        "\n",
        "upload_method = input(\"Choose method (1 or 2): \").strip()\n",
        "\n",
        "if upload_method == \"1\":\n",
        "    print(\"\\nüì§ Please select your video file...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"‚ùå No file uploaded. Exiting.\")\n",
        "    else:\n",
        "        video_filename = list(uploaded.keys())[0]\n",
        "        destination_path = os.path.join(INPUT_FOLDER, video_filename)\n",
        "        shutil.move(video_filename, destination_path)\n",
        "        video_path = destination_path\n",
        "        print(f\"‚úì Uploaded: {video_filename}\")\n",
        "\n",
        "elif upload_method == \"2\":\n",
        "    video_path = input(\"\\nüìÅ Enter Google Drive path (e.g., /content/drive/MyDrive/video.mp4): \").strip()\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"‚ùå File not found: {video_path}\")\n",
        "        video_path = None\n",
        "    else:\n",
        "        print(f\"‚úì Found: {video_path}\")\n",
        "else:\n",
        "    print(\"‚ùå Invalid choice. Exiting.\")\n",
        "    video_path = None\n",
        "\n",
        "# Process video if valid path exists\n",
        "if video_path:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìπ Loading video...\")\n",
        "\n",
        "    # Get video info\n",
        "    cap_check = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap_check.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap_check.get(cv2.CAP_PROP_FPS)\n",
        "    duration = total_frames / fps if fps > 0 else 0\n",
        "    cap_check.release()\n",
        "\n",
        "    print(f\"   ‚úì Video loaded: {total_frames} frames, {fps:.1f} FPS, {duration:.1f} seconds\")\n",
        "\n",
        "    # Extract skeletal data\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    frame_data_list, fps, total_frames = extract_keypoints_from_video(video_path, model)\n",
        "\n",
        "    # Create DataFrame\n",
        "    print(\"\\nüìä Creating structured dataset...\")\n",
        "    df = pd.DataFrame(frame_data_list)\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    # Calculate statistics\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìä DETECTION SUMMARY:\")\n",
        "\n",
        "    frames_with_person = (df['overall_confidence'] > 0).sum()\n",
        "    detection_rate = (frames_with_person / total_frames) * 100\n",
        "    avg_confidence = df[df['overall_confidence'] > 0]['overall_confidence'].mean()\n",
        "    low_confidence_frames = (df['overall_confidence'] < 0.7).sum()\n",
        "\n",
        "    print(f\"   ‚Ä¢ Person detected: {frames_with_person}/{total_frames} frames ({detection_rate:.1f}%)\")\n",
        "    print(f\"   ‚Ä¢ Average confidence: {avg_confidence:.2f}\")\n",
        "    print(f\"   ‚Ä¢ Low confidence frames: {low_confidence_frames}\")\n",
        "\n",
        "    # Export to CSV\n",
        "    print(\"\\nüíæ Exporting to CSV...\")\n",
        "\n",
        "    base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "    csv_filename = os.path.join(OUTPUT_FOLDER, f\"{base_name}_skeletal_data.csv\")\n",
        "\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "\n",
        "    file_size_mb = os.path.getsize(csv_filename) / (1024 * 1024)\n",
        "\n",
        "    print(f\"   ‚úì File created: {csv_filename}\")\n",
        "    print(f\"   ‚Ä¢ Rows: {len(df)}\")\n",
        "    print(f\"   ‚Ä¢ Columns: {len(df.columns)}\")\n",
        "    print(f\"   ‚Ä¢ Size: {file_size_mb:.2f} MB\")\n",
        "\n",
        "    # Auto-download\n",
        "    print(\"\\nüì• Downloading CSV file to computer...\")\n",
        "    files.download(csv_filename)\n",
        "    print(\"   ‚úì Download complete!\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"‚úÖ DONE! Skeletal data extracted and exported.\")\n",
        "    print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2233e51"
      },
      "source": [
        "# Task\n",
        "Create an interactive dashboard that allows users to input a `USER_ID` and `EXERCISE` type, select analysis periods (e.g., 'Last 7 Days', 'Last 30 Days', 'All Time'), and choose to view either a detailed progress report or a visual chart. The dashboard should integrate with the existing `analyze_progress` and `visualize_progress` functions to dynamically display the requested data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8655928d"
      },
      "source": [
        "## Design Dashboard Layout\n",
        "\n",
        "### Subtask:\n",
        "Outline the structure and key interactive components of the dashboard, including input fields for user ID and exercise type, and buttons/dropdowns for selecting analysis periods (e.g., last 7 days, last 30 days, all time) and chart types.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1c70e65"
      },
      "source": [
        "### Dashboard Layout Outline\n",
        "\n",
        "To create an interactive dashboard for progress tracking, the following components will be designed:\n",
        "\n",
        "#### 1. Input Fields:\n",
        "*   **User ID:** A text input field (`widgets.Text`) to allow the user to specify their unique identifier (e.g., `USER_ID`).\n",
        "*   **Exercise Type:** A text input field (`widgets.Text`) to define the exercise being tracked (e.g., `EXERCISE`).\n",
        "\n",
        "#### 2. Selection Mechanisms for Analysis Periods:\n",
        "*   **Time Period Dropdown:** A dropdown menu (`widgets.Dropdown`) will be used to select the desired analysis period. Options will include:\n",
        "    *   'Last 24 Hours'\n",
        "    *   'Last 7 Days'\n",
        "    *   'Last 30 Days'\n",
        "    *   'Last 4 Weeks'\n",
        "    *   'All Time'\n",
        "    *   'Compare all periods'\n",
        "\n",
        "#### 3. UI Elements for Output Format Selection:\n",
        "*   **Output Type Radio Buttons:** A set of radio buttons (`widgets.RadioButtons` or similar) will allow users to choose the desired output format:\n",
        "    *   'Detailed Progress Report' (for text-based analysis)\n",
        "    *   'Visual Chart' (for graphical representation)\n",
        "\n",
        "#### 4. Submission Button:\n",
        "*   **Analyze Button:** A button (`widgets.Button`) labeled 'Analyze Progress' that, when clicked, will trigger the execution of the selected analysis based on the input fields and selection mechanisms.\n",
        "\n",
        "#### 5. Output Area:\n",
        "*   **Results Display:** A dedicated output area (`widgets.Output`) where the generated text reports (from 'Detailed Progress Report') or visual charts (from 'Visual Chart') will be displayed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c188473"
      },
      "source": [
        "## Implement Dashboard Widgets\n",
        "\n",
        "### Subtask:\n",
        "Use `ipywidgets` to create the interactive elements for the dashboard, such as text input fields for `USER_ID` and `EXERCISE`, and dropdowns or buttons for selecting time periods and triggering analysis functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a311fc37"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to import the `ipywidgets` library, which is necessary for creating interactive elements in the dashboard.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34443c5a"
      },
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "print(\"‚úì ipywidgets imported successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "579ebf69"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that `ipywidgets` is imported, I will create and display the interactive elements of the dashboard as per the instructions, including text inputs for USER_ID and EXERCISE, a dropdown for analysis periods, radio buttons for output type, a button to trigger analysis, and an output area.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef45e152"
      },
      "source": [
        "user_id_input = widgets.Text(\n",
        "    value='demo_user',\n",
        "    placeholder='Enter User ID',\n",
        "    description='User ID:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "exercise_input = widgets.Text(\n",
        "    value='squat',\n",
        "    placeholder='Enter Exercise Type (e.g., squat, pushup)',\n",
        "    description='Exercise:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "time_period_dropdown = widgets.Dropdown(\n",
        "    options=[\n",
        "        ('Last 24 Hours', 'day'),\n",
        "        ('Last 7 Days', 'week'),\n",
        "        ('Last 30 Days', 'month'),\n",
        "        ('Last 4 Weeks', '4weeks'),\n",
        "        ('All Time', 'all'),\n",
        "        ('Compare all periods', 'compare')\n",
        "    ],\n",
        "    value='month',\n",
        "    description='Time Period:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "output_type_radio = widgets.RadioButtons(\n",
        "    options=['Detailed Progress Report', 'Visual Chart'],\n",
        "    value='Detailed Progress Report',\n",
        "    description='Output Type:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "analyze_button = widgets.Button(\n",
        "    description='Analyze Progress',\n",
        "    disabled=False,\n",
        "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click to analyze progress',\n",
        "    icon='chart-line'\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "\n",
        "print(\"‚úì Dashboard widgets created successfully!\")\n",
        "\n",
        "# Display the widgets\n",
        "display(user_id_input, exercise_input, time_period_dropdown, output_type_radio, analyze_button, output_area)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e37f2d0"
      },
      "source": [
        "## Integrate Progress Functions\n",
        "\n",
        "### Subtask:\n",
        "Connect the dashboard widgets to the existing `analyze_progress` and `visualize_progress` functions, allowing the user to dynamically generate reports and charts based on their selections.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2db74e9b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the `on_analyze_button_clicked` function to handle the button click event, incorporating the logic for retrieving widget values, clearing the output, and conditionally calling `analyze_progress`, `visualize_progress`, or `compare_time_periods` based on user selections. Then, I will attach this function to the `analyze_button`'s `on_click` event.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9069151"
      },
      "source": [
        "def on_analyze_button_clicked(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output(wait=True)\n",
        "\n",
        "        user_id = user_id_input.value\n",
        "        exercise_type = exercise_input.value\n",
        "        time_period = time_period_dropdown.value\n",
        "        output_type = output_type_radio.value\n",
        "\n",
        "        print(f\"Analyzing for User ID: {user_id}, Exercise: {exercise_type}, Period: {time_period}, Output: {output_type}\")\n",
        "\n",
        "        if output_type == 'Detailed Progress Report':\n",
        "            if time_period == 'compare':\n",
        "                compare_time_periods(user_id, exercise_type)\n",
        "            else:\n",
        "                analyze_progress(user_id, exercise_type, time_period)\n",
        "        elif output_type == 'Visual Chart':\n",
        "            # Map time periods for visualization if necessary\n",
        "            chart_time_period_map = {\n",
        "                'day': 'week',\n",
        "                'week': 'week',\n",
        "                'month': 'month',\n",
        "                '4weeks': '4weeks',\n",
        "                'all': 'all',\n",
        "                'compare': 'all' # Default to all if compare is selected for chart\n",
        "            }\n",
        "            chart_period = chart_time_period_map.get(time_period, 'month')\n",
        "\n",
        "            if time_period == 'compare':\n",
        "                print(\"Chart comparison is not directly supported. Displaying 'All Time' chart instead.\")\n",
        "            visualize_progress(user_id, exercise_type, chart_period)\n",
        "\n",
        "# Attach the function to the button's on_click event\n",
        "analyze_button.on_click(on_analyze_button_clicked)\n",
        "\n",
        "print(\"‚úì Dashboard logic connected to analysis functions.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c33f53d2"
      },
      "source": [
        "## Display Dashboard\n",
        "\n",
        "### Subtask:\n",
        "Render the interactive dashboard in a new cell, ensuring all components are properly displayed and functional.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7689a1cc"
      },
      "source": [
        "**Reasoning**:\n",
        "To properly display all the dashboard components together in a structured layout, I need to use `VBox` from `ipywidgets` and then display the `VBox`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8bc96a3"
      },
      "source": [
        "from ipywidgets import VBox\n",
        "\n",
        "# Group the widgets into a VBox for display\n",
        "dashboard_layout = VBox([\n",
        "    user_id_input,\n",
        "    exercise_input,\n",
        "    time_period_dropdown,\n",
        "    output_type_radio,\n",
        "    analyze_button,\n",
        "    output_area\n",
        "])\n",
        "\n",
        "# Display the dashboard\n",
        "display(dashboard_layout)\n",
        "\n",
        "print(\"‚úì Interactive dashboard displayed successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6c625c3"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the created interactive dashboard and explain how to use it to view progress data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97cf5034"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The interactive dashboard allows users to view progress data by following these steps:\n",
        "1.  **Input User ID**: Enter a specific user's ID in the \"User ID\" text field.\n",
        "2.  **Input Exercise Type**: Specify the exercise (e.g., 'squat', 'pushup') in the \"Exercise\" text field.\n",
        "3.  **Select Time Period**: Choose an analysis period from the \"Time Period\" dropdown menu (e.g., 'Last 7 Days', 'All Time', 'Compare all periods').\n",
        "4.  **Select Output Type**: Choose whether to view a 'Detailed Progress Report' (text-based summary) or a 'Visual Chart' (graphical representation) using the radio buttons.\n",
        "5.  **Analyze Progress**: Click the 'Analyze Progress' button to generate and display the selected data in the output area.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Dashboard Structure**: The dashboard was designed with input fields for `USER_ID` and `EXERCISE`, dropdowns for time period selection (including 'Last 24 Hours', 'Last 7 Days', 'Last 30 Days', 'Last 4 Weeks', 'All Time', and 'Compare all periods'), radio buttons for output type ('Detailed Progress Report' or 'Visual Chart'), an 'Analyze Progress' button, and a dedicated output area.\n",
        "*   **Widget Implementation**: All interactive components were successfully created using `ipywidgets`. This includes `widgets.Text` for inputs (defaulting to 'demo_user' and 'squat'), `widgets.Dropdown` for time periods, `widgets.RadioButtons` for output type (defaulting to 'Detailed Progress Report'), `widgets.Button` for triggering analysis, and `widgets.Output` for results.\n",
        "*   **Function Integration**: An event handler `on_analyze_button_clicked` was implemented to connect the dashboard widgets to the backend analysis functions. It retrieves user selections and conditionally calls `analyze_progress()`, `visualize_progress()`, or `compare_time_periods()`.\n",
        "*   **Conditional Logic**: The integration correctly handles different output types and time periods:\n",
        "    *   For 'Detailed Progress Report', it distinguishes between specific time periods and the 'compare' option to call `analyze_progress()` or `compare_time_periods()` respectively.\n",
        "    *   For 'Visual Chart', it maps selected time periods to appropriate values for `visualize_progress()` and provides a fallback to 'All Time' for charts if 'Compare all periods' is selected, printing a notification about chart comparison not being directly supported.\n",
        "*   **Dashboard Display**: The final dashboard was successfully rendered by grouping all widgets into an `ipywidgets.VBox` and displaying it, making it interactive and ready for user input.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   **Enhanced Comparison for Visualizations**: Currently, 'Compare all periods' for visual charts defaults to 'All Time'. A valuable next step would be to implement a specialized visualization function that can display comparative charts for different time periods simultaneously, offering a richer analytical experience.\n",
        "*   **Input Validation and Error Handling**: Implement input validation for `USER_ID` and `EXERCISE` to ensure valid data is entered, and add more robust error handling within `on_analyze_button_clicked` to gracefully manage cases where `analyze_progress` or `visualize_progress` might fail (e.g., user not found, no data for exercise).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b3255f6"
      },
      "source": [
        "# Task\n",
        "Create an HTML-based interactive dashboard for fitness progress tracking, including input fields for `USER_ID` and `EXERCISE`, selection for analysis periods, and a display area for dynamically generated progress reports and visual charts from existing Python functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fde819de"
      },
      "source": [
        "## Generate Basic HTML Structure\n",
        "\n",
        "### Subtask:\n",
        "Create a Python code cell that outputs a basic HTML template for a dashboard layout. This template will include sections for user input, analysis period selection, and a display area for results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0d539cf"
      },
      "source": [
        "**Reasoning**:\n",
        "To generate the basic HTML structure for the dashboard as specified, I need to create a Python code cell that defines the HTML content as a multi-line string and then uses `IPython.display.HTML` to render it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f72b8073"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "html_template = \"\"\"\n",
        "<div style=\"font-family: Arial, sans-serif; padding: 20px; border: 1px solid #ccc; border-radius: 8px;\">\n",
        "    <h2 style=\"color: #333;\">Progress Tracking Dashboard</h2>\n",
        "\n",
        "    <div style=\"margin-bottom: 15px;\">\n",
        "        <label for=\"user_id\" style=\"font-weight: bold;\">User ID:</label>\n",
        "        <input type=\"text\" id=\"user_id\" value=\"demo_user\" style=\"width: 200px; padding: 8px; margin-left: 10px; border: 1px solid #ddd; border-radius: 4px;\">\n",
        "    </div>\n",
        "\n",
        "    <div style=\"margin-bottom: 15px;\">\n",
        "        <label for=\"exercise_type\" style=\"font-weight: bold;\">Exercise Type:</label>\n",
        "        <input type=\"text\" id=\"exercise_type\" value=\"squat\" style=\"width: 200px; padding: 8px; margin-left: 10px; border: 1px solid #ddd; border-radius: 4px;\">\n",
        "    </div>\n",
        "\n",
        "    <div style=\"margin-bottom: 15px;\">\n",
        "        <label for=\"time_period\" style=\"font-weight: bold;\">Analysis Period:</label>\n",
        "        <select id=\"time_period\" style=\"padding: 8px; margin-left: 10px; border: 1px solid #ddd; border-radius: 4px;\">\n",
        "            <option value=\"day\">Last 24 Hours</option>\n",
        "            <option value=\"week\">Last 7 Days</option>\n",
        "            <option value=\"month\" selected>Last 30 Days</option>\n",
        "            <option value=\"4weeks\">Last 4 Weeks</option>\n",
        "            <option value=\"all\">All Time</option>\n",
        "            <option value=\"compare\">Compare all periods</option>\n",
        "        </select>\n",
        "    </div>\n",
        "\n",
        "    <div style=\"margin-bottom: 20px;\">\n",
        "        <label style=\"font-weight: bold;\">Output Type:</label>\n",
        "        <input type=\"radio\" id=\"report_type\" name=\"output_type\" value=\"report\" checked>\n",
        "        <label for=\"report_type\">Detailed Progress Report</label>\n",
        "        <input type=\"radio\" id=\"chart_type\" name=\"output_type\" value=\"chart\" style=\"margin-left: 15px;\">\n",
        "        <label for=\"chart_type\">Visual Chart</label>\n",
        "    </div>\n",
        "\n",
        "    <button id=\"analyze_button\" style=\"padding: 10px 20px; background-color: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer;\">Analyze Progress</button>\n",
        "\n",
        "    <div id=\"results_display_area\" style=\"margin-top: 20px; padding: 15px; border: 1px dashed #aaa; background-color: #f9f9f9; min-height: 150px;\">\n",
        "        <p>Results will be displayed here...</p>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_template))\n",
        "print(\"‚úì Basic HTML dashboard template displayed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91b9e68f"
      },
      "source": [
        "## Add Styles to HTML Dashboard\n",
        "\n",
        "### Subtask:\n",
        "Enhance the generated HTML with basic CSS to improve its visual appeal, layout, and responsiveness.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97c623f9"
      },
      "source": [
        "**Reasoning**:\n",
        "To enhance the visual appeal, layout, and responsiveness of the HTML dashboard, I will modify the existing `html_template` to include basic CSS styling within a `<style>` tag. This will involve setting styles for the main container, input fields, labels, buttons, and the results display area.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c4f1da2"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "html_template = \"\"\"\n",
        "<div class=\"dashboard-container\">\n",
        "    <style>\n",
        "        .dashboard-container {\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            padding: 25px;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            border-radius: 10px;\n",
        "            background-color: #fcfcfc;\n",
        "            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);\n",
        "            max-width: 800px;\n",
        "            margin: 20px auto;\n",
        "        }\n",
        "        h2 {\n",
        "            color: #2c3e50;\n",
        "            text-align: center;\n",
        "            margin-bottom: 30px;\n",
        "            font-size: 2em;\n",
        "        }\n",
        "        .form-group {\n",
        "            margin-bottom: 20px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            padding: 5px 0;\n",
        "        }\n",
        "        label {\n",
        "            font-weight: bold;\n",
        "            color: #34495e;\n",
        "            min-width: 120px;\n",
        "            font-size: 1.1em;\n",
        "        }\n",
        "        input[type=\"text\"], select {\n",
        "            flex-grow: 1;\n",
        "            padding: 10px 12px;\n",
        "            margin-left: 15px;\n",
        "            border: 1px solid #bdc3c7;\n",
        "            border-radius: 6px;\n",
        "            font-size: 1em;\n",
        "            box-sizing: border-box;\n",
        "            transition: border-color 0.2s, box-shadow 0.2s;\n",
        "        }\n",
        "        input[type=\"text\"]:focus, select:focus {\n",
        "            border-color: #3498db;\n",
        "            box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.2);\n",
        "            outline: none;\n",
        "        }\n",
        "        .radio-group {\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            margin-bottom: 25px;\n",
        "        }\n",
        "        .radio-group label:first-of-type {\n",
        "            min-width: 120px;\n",
        "            margin-right: 15px;\n",
        "        }\n",
        "        .radio-group input[type=\"radio\"] {\n",
        "            margin-left: 10px;\n",
        "            margin-right: 5px;\n",
        "            transform: scale(1.1);\n",
        "        }\n",
        "        button#analyze_button {\n",
        "            display: block;\n",
        "            width: 100%;\n",
        "            padding: 12px 20px;\n",
        "            background-color: #2ecc71;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 6px;\n",
        "            cursor: pointer;\n",
        "            font-size: 1.2em;\n",
        "            font-weight: bold;\n",
        "            transition: background-color 0.3s ease, transform 0.1s ease;\n",
        "            box-shadow: 0 4px 8px rgba(46, 204, 113, 0.3);\n",
        "        }\n",
        "        button#analyze_button:hover {\n",
        "            background-color: #27ae60;\n",
        "            transform: translateY(-2px);\n",
        "        }\n",
        "        #results_display_area {\n",
        "            margin-top: 30px;\n",
        "            padding: 20px;\n",
        "            border: 1px dashed #95a5a6;\n",
        "            background-color: #ecf0f1;\n",
        "            min-height: 200px;\n",
        "            border-radius: 8px;\n",
        "            font-size: 1em;\n",
        "            color: #34495e;\n",
        "            overflow-y: auto;\n",
        "        }\n",
        "        #results_display_area p {\n",
        "            margin: 0;\n",
        "            color: #7f8c8d;\n",
        "        }\n",
        "    </style>\n",
        "\n",
        "    <h2>Progress Tracking Dashboard</h2>\n",
        "\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"user_id\">User ID:</label>\n",
        "        <input type=\"text\" id=\"user_id\" value=\"demo_user\">\n",
        "    </div>\n",
        "\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"exercise_type\">Exercise Type:</label>\n",
        "        <input type=\"text\" id=\"exercise_type\" value=\"squat\">\n",
        "    </div>\n",
        "\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"time_period\">Analysis Period:</label>\n",
        "        <select id=\"time_period\">\n",
        "            <option value=\"day\">Last 24 Hours</option>\n",
        "            <option value=\"week\">Last 7 Days</option>\n",
        "            <option value=\"month\" selected>Last 30 Days</option>\n",
        "            <option value=\"4weeks\">Last 4 Weeks</option>\n",
        "            <option value=\"all\">All Time</option>\n",
        "            <option value=\"compare\">Compare all periods</option>\n",
        "        </select>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"radio-group\">\n",
        "        <label>Output Type:</label>\n",
        "        <input type=\"radio\" id=\"report_type\" name=\"output_type\" value=\"report\" checked>\n",
        "        <label for=\"report_type\">Detailed Progress Report</label>\n",
        "        <input type=\"radio\" id=\"chart_type\" name=\"output_type\" value=\"chart\">\n",
        "        <label for=\"chart_type\">Visual Chart</label>\n",
        "    </div>\n",
        "\n",
        "    <button id=\"analyze_button\">Analyze Progress</button>\n",
        "\n",
        "    <div id=\"results_display_area\">\n",
        "        <p>Results will be displayed here...</p>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_template))\n",
        "print(\"‚úì HTML dashboard template with enhanced styling displayed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "923f3112"
      },
      "source": [
        "import json\n",
        "\n",
        "# Assuming example_json_output contains the JSON string from analyze_progress\n",
        "# Parse the JSON string into a Python dictionary\n",
        "parsed_data = json.loads(example_json_output)\n",
        "\n",
        "print(\"‚úì JSON data successfully parsed into a Python dictionary.\")\n",
        "print(\"\\n--- Key Metrics from Parsed Data ---\")\n",
        "print(f\"Exercise Type: {parsed_data.get('exercise')}\")\n",
        "print(f\"Analysis Period: {parsed_data.get('period_name')}\")\n",
        "print(f\"Total Sessions: {parsed_data.get('total_sessions')}\")\n",
        "print(f\"Average Accuracy: {parsed_data.get('form_quality', {}).get('average_accuracy')}%\")\n",
        "print(f\"Most Reps: {parsed_data.get('personal_records', {}).get('most_reps', {}).get('value')}\")\n",
        "\n",
        "print(\"\\n--- Full Parsed Data (for inspection) ---\")\n",
        "# Display the entire parsed dictionary for a complete view\n",
        "print(json.dumps(parsed_data, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a8f19e3"
      },
      "source": [
        "First, let's make sure our `analyze_progress` function is registered as a Colab callback so JavaScript can call it. We'll use `analyze_progress_js` as the callback name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7486ce3f"
      },
      "source": [
        "from google.colab import output\n",
        "# Ensure analyze_progress is defined (it should be from cell 0f32b13f)\n",
        "# Register the function that returns JSON\n",
        "output.register_callback('analyze_progress_js', analyze_progress)\n",
        "print(\"‚úì `analyze_progress` registered as 'analyze_progress_js' callback.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06ba2b36"
      },
      "source": [
        "Now, here's a JavaScript code snippet that would be embedded in your HTML. This script demonstrates how to fetch the JSON data from the Python backend and display it. This is a simplified example focusing on displaying the JSON in a readable format within the `results_display_area`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2bf4c2e"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "javascript_integration_html = \"\"\"\n",
        "<div class=\"dashboard-container\">\n",
        "    <style>\n",
        "        .dashboard-container {\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            padding: 25px;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            border-radius: 10px;\n",
        "            background-color: #fcfcfc;\n",
        "            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);\n",
        "            max-width: 800px;\n",
        "            margin: 20px auto;\n",
        "        }\n",
        "        h2 {\n",
        "            color: #2c3e50;\n",
        "            text-align: center;\n",
        "            margin-bottom: 30px;\n",
        "            font-size: 2em;\n",
        "        }\n",
        "        .form-group {\n",
        "            margin-bottom: 20px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            padding: 5px 0;\n",
        "        }\n",
        "        label {\n",
        "            font-weight: bold;\n",
        "            color: #34495e;\n",
        "            min-width: 120px;\n",
        "            font-size: 1.1em;\n",
        "        }\n",
        "        input[type=\"text\"], select {\n",
        "            flex-grow: 1;\n",
        "            padding: 10px 12px;\n",
        "            margin-left: 15px;\n",
        "            border: 1px solid #bdc3c7;\n",
        "            border-radius: 6px;\n",
        "            font-size: 1em;\n",
        "            box-sizing: border-box;\n",
        "            transition: border-color 0.2s, box-shadow 0.2s;\n",
        "        }\n",
        "        input[type=\"text\"]:focus, select:focus {\n",
        "            border-color: #3498db;\n",
        "            box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.2);\n",
        "            outline: none;\n",
        "        }\n",
        "        .radio-group {\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            margin-bottom: 25px;\n",
        "        }\n",
        "        .radio-group label:first-of-type {\n",
        "            min-width: 120px;\n",
        "            margin-right: 15px;\n",
        "        }\n",
        "        .radio-group input[type=\"radio\"] {\n",
        "            margin-left: 10px;\n",
        "            margin-right: 5px;\n",
        "            transform: scale(1.1);\n",
        "        }\n",
        "        button#analyze_button {\n",
        "            display: block;\n",
        "            width: 100%;\n",
        "            padding: 12px 20px;\n",
        "            background-color: #2ecc71;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 6px;\n",
        "            cursor: pointer;\n",
        "            font-size: 1.2em;\n",
        "            font-weight: bold;\n",
        "            transition: background-color 0.3s ease, transform 0.1s ease;\n",
        "            box-shadow: 0 4px 8px rgba(46, 204, 113, 0.3);\n",
        "        }\n",
        "        button#analyze_button:hover {\n",
        "            background-color: #27ae60;\n",
        "            transform: translateY(-2px);\n",
        "        }\n",
        "        #results_display_area {\n",
        "            margin-top: 30px;\n",
        "            padding: 20px;\n",
        "            border: 1px dashed #95a5a6;\n",
        "            background-color: #ecf0f1;\n",
        "            min-height: 200px;\n",
        "            border-radius: 8px;\n",
        "            font-size: 1em;\n",
        "            color: #34495e;\n",
        "            overflow-y: auto;\n",
        "        }\n",
        "        #results_display_area p {\n",
        "            margin: 0;\n",
        "            color: #7f8c8d;\n",
        "        }\n",
        "    </style>\n",
        "\n",
        "    <h2>Progress Tracking Dashboard</h2>\n",
        "\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"user_id\">User ID:</label>\n",
        "        <input type=\"text\" id=\"user_id\" value=\"demo_user\">\n",
        "    </div>\n",
        "\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"exercise_type\">Exercise Type:</label>\n",
        "        <input type=\"text\" id=\"exercise_type\" value=\"squat\">\n",
        "    </div>\n",
        "\n",
        "    <div class=\"form-group\">\n",
        "        <label for=\"time_period\">Analysis Period:</label>\n",
        "        <select id=\"time_period\">\n",
        "            <option value=\"day\">Last 24 Hours</option>\n",
        "            <option value=\"week\">Last 7 Days</option>\n",
        "            <option value=\"month\" selected>Last 30 Days</option>\n",
        "            <option value=\"4weeks\">Last 4 Weeks</option>\n",
        "            <option value=\"all\">All Time</option>\n",
        "            <option value=\"compare\">Compare all periods</option>\n",
        "        </select>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"radio-group\">\n",
        "        <label>Output Type:</label>\n",
        "        <input type=\"radio\" id=\"report_type\" name=\"output_type\" value=\"report\" checked>\n",
        "        <label for=\"report_type\">Detailed Progress Report</label>\n",
        "        <input type=\"radio\" id=\"chart_type\" name=\"output_type\" value=\"chart\">\n",
        "        <label for=\"chart_type\">Visual Chart</label>\n",
        "    </div>\n",
        "\n",
        "    <button id=\"analyze_button\">Analyze Progress</button>\n",
        "\n",
        "    <div id=\"results_display_area\">\n",
        "        <p>Results will be displayed here...</p>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        const analyzeButton = document.getElementById('analyze_button');\n",
        "        const resultsDisplayArea = document.getElementById('results_display_area');\n",
        "\n",
        "        analyzeButton.addEventListener('click', async () => {\n",
        "            const userId = document.getElementById('user_id').value;\n",
        "            const exerciseType = document.getElementById('exercise_type').value;\n",
        "            const timePeriod = document.getElementById('time_period').value;\n",
        "            const outputTypeReport = document.getElementById('report_type').checked;\n",
        "\n",
        "            resultsDisplayArea.innerHTML = '<p>Loading analysis...</p>';\n",
        "\n",
        "            try {\n",
        "                if (outputTypeReport) {\n",
        "                    // Call the Python callback for JSON analysis\n",
        "                    const jsonString = await google.colab.output.getData({\n",
        "                        name: 'analyze_progress_js',\n",
        "                        args: [userId, exerciseType, timePeriod]\n",
        "                    });\n",
        "                    const data = JSON.parse(jsonString.data); // jsonString.data contains the JSON string from Python\n",
        "\n",
        "                    if (data.status === \"success\") {\n",
        "                        let htmlOutput = `<h3>üìä PROGRESS REPORT - ${data.period_name}</h3>`;\n",
        "                        htmlOutput += `<p><b>Exercise:</b> ${data.exercise}</p>`;\n",
        "                        htmlOutput += `<p><b>Total Sessions:</b> ${data.total_sessions}</p>`;\n",
        "                        htmlOutput += `<p><b>Date Range:</b> ${data.date_range_start} to ${data.date_range_end}</p>`;\n",
        "\n",
        "                        htmlOutput += `<h4>üéØ FORM QUALITY:</h4>`;\n",
        "                        htmlOutput += `<ul>`;\n",
        "                        htmlOutput += `<li><b>Current Accuracy:</b> ${data.form_quality.current_accuracy}%</li>`;\n",
        "                        htmlOutput += `<li><b>Starting Accuracy:</b> ${data.form_quality.starting_accuracy}%</li>`;\n",
        "                        htmlOutput += `<li><b>Improvement:</b> ${data.form_quality.improvement}%</li>`;\n",
        "                        htmlOutput += `<li><b>Average Accuracy:</b> ${data.form_quality.average_accuracy}%</li>`;\n",
        "                        htmlOutput += `<li><b>Best Session:</b> ${data.form_quality.best_session_accuracy}%</li>`;\n",
        "                        htmlOutput += `</ul>`;\n",
        "\n",
        "                        htmlOutput += `<h4>üí™ VOLUME & INTENSITY:</h4>`;\n",
        "                        htmlOutput += `<ul>`;\n",
        "                        htmlOutput += `<li><b>Total Reps:</b> ${data.volume_intensity.total_reps}</li>`;\n",
        "                        htmlOutput += `<li><b>Average Reps/Session:</b> ${data.volume_intensity.average_reps_per_session}</li>`;\n",
        "                        htmlOutput += `<li><b>Max Reps (Single Session):</b> ${data.volume_intensity.max_reps_single_session}</li>`;\n",
        "                        htmlOutput += `</ul>`;\n",
        "\n",
        "                        if (data.weight_progression) {\n",
        "                            htmlOutput += `<h4>üèãÔ∏è WEIGHT PROGRESSION:</h4>`;\n",
        "                            htmlOutput += `<ul>`;\n",
        "                            htmlOutput += `<li><b>Current Weight:</b> ${data.weight_progression.current_weight_lbs} lbs</li>`;\n",
        "                            htmlOutput += `<li><b>Starting Weight:</b> ${data.weight_progression.starting_weight_lbs} lbs</li>`;\n",
        "                            htmlOutput += `<li><b>Max Weight Used:</b> ${data.weight_progression.max_weight_used_lbs} lbs</li>`;\n",
        "                            htmlOutput += `<li><b>Weight Increase:</b> ${data.weight_progression.weight_increase_lbs} lbs</li>`;\n",
        "                            htmlOutput += `<li><b>Total Volume:</b> ${data.weight_progression.total_volume_lbs} lbs</li>`;\n",
        "                            htmlOutput += `</ul>`;\n",
        "                        }\n",
        "\n",
        "                        htmlOutput += `<h4>üìÖ TRAINING FREQUENCY:</h4>`;\n",
        "                        htmlOutput += `<ul>`;\n",
        "                        htmlOutput += `<li><b>Sessions per Week:</b> ${data.training_frequency.sessions_per_week}</li>`;\n",
        "                        htmlOutput += `<li><b>Days Since Last Session:</b> ${data.training_frequency.days_since_last_session}</li>`;\n",
        "                        htmlOutput += `<li><b>Current Streak:</b> ${data.training_frequency.current_streak_days} days</li>`;\n",
        "                        htmlOutput += `</ul>`;\n",
        "\n",
        "                        if (data.trend) {\n",
        "                            htmlOutput += `<p><b>üéØ Trend:</b> ${data.trend}</p>`;\n",
        "                        }\n",
        "\n",
        "                        if (data.most_common_issues && data.most_common_issues.length > 0) {\n",
        "                            htmlOutput += `<h4>‚ö†Ô∏è MOST COMMON FORM ISSUES:</h4>`;\n",
        "                            htmlOutput += `<ul>`;\n",
        "                            data.most_common_issues.forEach((issue, index) => {\n",
        "                                htmlOutput += `<li>${index + 1}. ${issue.joint} (${issue.occurrences} occurrences)</li>`;\n",
        "                            });\n",
        "                            htmlOutput += `</ul>`;\n",
        "                        }\n",
        "\n",
        "                        if (data.personal_records) {\n",
        "                            htmlOutput += `<h4>üèÜ PERSONAL RECORDS:</h4>`;\n",
        "                            htmlOutput += `<ul>`;\n",
        "                            if (data.personal_records.best_accuracy) {\n",
        "                                htmlOutput += `<li><b>Best Accuracy:</b> ${data.personal_records.best_accuracy.value}% on ${data.personal_records.best_accuracy.date}</li>`;\n",
        "                            }\n",
        "                            if (data.personal_records.most_reps) {\n",
        "                                htmlOutput += `<li><b>Most Reps:</b> ${data.personal_records.most_reps.value} on ${data.personal_records.most_reps.date}</li>`;\n",
        "                            }\n",
        "                            if (data.personal_records.heaviest_weight) {\n",
        "                                htmlOutput += `<li><b>Heaviest Weight:</b> ${data.personal_records.heaviest_weight.value} lbs on ${data.personal_records.heaviest_weight.date}</li>`;\n",
        "                            }\n",
        "                            htmlOutput += `</ul>`;\n",
        "                        }\n",
        "\n",
        "                        resultsDisplayArea.innerHTML = htmlOutput;\n",
        "\n",
        "                    } else {\n",
        "                        resultsDisplayArea.innerHTML = `<p style=\"color: red;\">${data.message}</p>`;\n",
        "                    }\n",
        "                } else {\n",
        "                    resultsDisplayArea.innerHTML = '<p>Visual Chart display not yet implemented in this JavaScript example.</p>';\n",
        "                }\n",
        "            } catch (error) {\n",
        "                resultsDisplayArea.innerHTML = `<p style=\"color: red;\">Error fetching or parsing data: ${error}</p>`;\n",
        "                console.error('Error:', error);\n",
        "            }\n",
        "        });\n",
        "    </script>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(javascript_integration_html))\n",
        "print(\"‚úì HTML dashboard with JavaScript for JSON integration displayed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "981ffd97"
      },
      "source": [
        "import json\n",
        "\n",
        "# Call analyze_progress with demo data to get JSON output\n",
        "example_json_output = analyze_progress('demo_user', 'squat', 'month')\n",
        "\n",
        "# Parse and print the JSON for readability\n",
        "parsed_json = json.loads(example_json_output)\n",
        "print(json.dumps(parsed_json, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe38b372"
      },
      "source": [
        "print(example_html_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38b41b2f"
      },
      "source": [
        "print(example_html_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "552dfbe6"
      },
      "source": [
        "display(HTML(example_html_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83bf642b"
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "# The content of cell 0f32b13f (which defines analyze_progress and other functions)\n",
        "# is explicitly included here to ensure it's in scope.\n",
        "\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Redefining helper functions needed by the main functions, as they are not globally available in this execution context.\n",
        "# Ideally, these would be in a separate utility file or defined earlier in the notebook.\n",
        "\n",
        "def load_progress_data(user_id, exercise_type):\n",
        "    \"\"\"\n",
        "    Load user's progress data\n",
        "    \"\"\"\n",
        "    progress_file = f'/content/progress_data/{user_id}_{exercise_type}_progress.json'\n",
        "\n",
        "    if not os.path.exists(progress_file):\n",
        "        # print(f\"No progress data found for {user_id} - {exercise_type}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(progress_file, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except json.JSONDecodeError:\n",
        "        # print(f\"‚ö†Ô∏è Warning: Progress file '{progress_file}' is corrupted. Cannot load data.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def analyze_progress(user_id, exercise_type, time_period='all'):\n",
        "    \"\"\"\n",
        "    Analyze user's progress over specified time period and return an HTML string.\n",
        "    \"\"\"\n",
        "    html_output = []\n",
        "\n",
        "    data = load_progress_data(user_id, exercise_type)\n",
        "\n",
        "    if not data or not data['sessions']:\n",
        "        html_output.append(\"<p>No session data available for analysis.</p>\")\n",
        "        return \"\".join(html_output)\n",
        "\n",
        "    sessions = data['sessions']\n",
        "    df = pd.DataFrame(sessions)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    df = df.sort_values('date')\n",
        "\n",
        "    now = datetime.now()\n",
        "    if time_period == 'day':\n",
        "        cutoff_date = now - timedelta(days=1)\n",
        "        period_name = \"Last 24 Hours\"\n",
        "    elif time_period == 'week':\n",
        "        cutoff_date = now - timedelta(weeks=1)\n",
        "        period_name = \"Last 7 Days\"\n",
        "    elif time_period == '4weeks':\n",
        "        cutoff_date = now - timedelta(weeks=4)\n",
        "        period_name = \"Last 4 Weeks\"\n",
        "    elif time_period == 'month':\n",
        "        cutoff_date = now - timedelta(days=30)\n",
        "        period_name = \"Last 30 Days\"\n",
        "    else:\n",
        "        cutoff_date = df['date'].min()\n",
        "        period_name = \"All Time\"\n",
        "\n",
        "    df_filtered = df[df['date'] >= cutoff_date]\n",
        "\n",
        "    if len(df_filtered) == 0:\n",
        "        html_output.append(f\"<p>No sessions found in {period_name.lower()}.</p>\")\n",
        "        return \"\".join(html_output)\n",
        "\n",
        "    html_output.append(f\"<h3>üìä PROGRESS REPORT - {period_name}</h3>\")\n",
        "    html_output.append(f\"<p><b>Exercise:</b> {exercise_type.upper()}</p>\")\n",
        "    html_output.append(f\"<p><b>Total Sessions:</b> {len(df_filtered)}</p>\")\n",
        "    html_output.append(f\"<p><b>Date Range:</b> {df_filtered['date'].min().strftime('%Y-%m-%d')} to {df_filtered['date'].max().strftime('%Y-%m-%d')}</p>\")\n",
        "\n",
        "    html_output.append(f\"<h4>üéØ FORM QUALITY:</h4>\")\n",
        "    html_output.append(f\"<ul>\")\n",
        "    html_output.append(f\"<li><b>Current Accuracy:</b> {df_filtered.iloc[-1]['accuracy']:.1f}%</li>\")\n",
        "    html_output.append(f\"<li><b>Starting Accuracy:</b> {df_filtered.iloc[0]['accuracy']:.1f}%</li>\")\n",
        "    improvement = df_filtered.iloc[-1]['accuracy'] - df_filtered.iloc[0]['accuracy']\n",
        "    html_output.append(f\"<li><b>Improvement:</b> {improvement:+.1f}%</li>\")\n",
        "    html_output.append(f\"<li><b>Average Accuracy:</b> {df_filtered['accuracy'].mean():.1f}%</li>\")\n",
        "    html_output.append(f\"<li><b>Best Session:</b> {df_filtered['accuracy'].max():.1f}%</li>\")\n",
        "    html_output.append(f\"</ul>\")\n",
        "\n",
        "    html_output.append(f\"<h4>üí™ VOLUME & INTENSITY:</h4>\")\n",
        "    html_output.append(f\"<ul>\")\n",
        "    total_reps = df_filtered['reps'].sum()\n",
        "    html_output.append(f\"<li><b>Total Reps:</b> {total_reps}</li>\")\n",
        "    html_output.append(f\"<li><b>Average Reps/Session:</b> {df_filtered['reps'].mean():.1f}</li>\")\n",
        "    html_output.append(f\"<li><b>Max Reps (Single Session):</b> {df_filtered['reps'].max()}</li>\")\n",
        "    html_output.append(f\"</ul>\")\n",
        "\n",
        "    if 'weight_lbs' in df_filtered.columns:\n",
        "        max_weight = df_filtered['weight_lbs'].max()\n",
        "        current_weight = df_filtered.iloc[-1]['weight_lbs']\n",
        "        starting_weight = df_filtered.iloc[0]['weight_lbs']\n",
        "\n",
        "        html_output.append(f\"<h4>üèãÔ∏è WEIGHT PROGRESSION:</h4>\")\n",
        "        html_output.append(f\"<ul>\")\n",
        "        html_output.append(f\"<li><b>Current Weight:</b> {current_weight} lbs</li>\")\n",
        "        html_output.append(f\"<li><b>Starting Weight:</b> {starting_weight} lbs</li>\")\n",
        "        html_output.append(f\"<li><b>Max Weight Used:</b> {max_weight} lbs</li>\")\n",
        "        html_output.append(f\"<li><b>Weight Increase:</b> +{current_weight - starting_weight} lbs</li>\")\n",
        "\n",
        "        df_filtered['volume'] = df_filtered['reps'] * df_filtered['weight_lbs']\n",
        "        total_volume = df_filtered['volume'].sum()\n",
        "        html_output.append(f\"<li><b>Total Volume:</b> {total_volume:,.0f} lbs</li>\")\n",
        "        html_output.append(f\"</ul>\")\n",
        "\n",
        "    html_output.append(f\"<h4>üìÖ TRAINING FREQUENCY:</h4>\")\n",
        "    html_output.append(f\"<ul>\")\n",
        "    days_span = (df_filtered['date'].max() - df_filtered['date'].min()).days + 1\n",
        "    sessions_per_week = (len(df_filtered) / days_span) * 7 if days_span > 0 else 0\n",
        "    html_output.append(f\"<li><b>Sessions per Week:</b> {sessions_per_week:.1f}</li>\")\n",
        "    html_output.append(f\"<li><b>Days Since Last Session:</b> {(now - df_filtered['date'].max()).days}</li>\")\n",
        "\n",
        "    df_filtered['date_only'] = df_filtered['date'].dt.date\n",
        "    unique_dates = sorted(df_filtered['date_only'].unique(), reverse=True)\n",
        "    current_streak = 0\n",
        "    if unique_dates:\n",
        "        for i, date in enumerate(unique_dates):\n",
        "            if i == 0:\n",
        "                days_diff = (datetime.now().date() - date).days\n",
        "                if days_diff <= 1:\n",
        "                    current_streak = 1\n",
        "                else:\n",
        "                    break\n",
        "            else:\n",
        "                days_diff = (unique_dates[i-1] - date).days\n",
        "                if days_diff == 1:\n",
        "                    current_streak += 1\n",
        "                else:\n",
        "                    break\n",
        "    html_output.append(f\"<li><b>Current Streak:</b> {current_streak} days</li>\")\n",
        "    html_output.append(f\"</ul>\")\n",
        "\n",
        "    if len(df_filtered) >= 3:\n",
        "        recent_avg = df_filtered.tail(3)['accuracy'].mean()\n",
        "        early_avg = df_filtered.head(3)['accuracy'].mean()\n",
        "        if recent_avg > early_avg + 2:\n",
        "            trend = \"üìà Improving\"\n",
        "        elif recent_avg < early_avg - 2:\n",
        "            trend = \"üìâ Declining\"\n",
        "        else:\n",
        "            trend = \"‚û°Ô∏è Stable\"\n",
        "        html_output.append(f\"<p><b>üéØ Trend:</b> {trend}</p>\")\n",
        "\n",
        "    all_issues = {}\n",
        "    for session in df_filtered.to_dict('records'):\n",
        "        if 'issues' in session and isinstance(session['issues'], list):\n",
        "            for issue in session['issues']:\n",
        "                joint = issue['joint']\n",
        "                all_issues[joint] = all_issues.get(joint, 0) + issue['count']\n",
        "\n",
        "    if all_issues:\n",
        "        html_output.append(f\"<h4>‚ö†Ô∏è MOST COMMON FORM ISSUES:</h4>\")\n",
        "        html_output.append(f\"<ul>\")\n",
        "        sorted_issues = sorted(all_issues.items(), key=lambda x: x[1], reverse=True)\n",
        "        for i, (joint, count) in enumerate(sorted_issues[:3], 1):\n",
        "            html_output.append(f\"<li>{i}. {joint.replace('_', ' ').title()} ({count} occurrences)</li>\")\n",
        "        html_output.append(f\"</ul>\")\n",
        "\n",
        "    html_output.append(f\"<h4>üèÜ PERSONAL RECORDS:</h4>\")\n",
        "    html_output.append(f\"<ul>\")\n",
        "    pr_accuracy = df_filtered.loc[df_filtered['accuracy'].idxmax()]\n",
        "    html_output.append(f\"<li><b>Best Accuracy:</b> {pr_accuracy['accuracy']:.1f}% on {pr_accuracy['date'].strftime('%Y-%m-%d')}</li>\")\n",
        "\n",
        "    pr_reps = df_filtered.loc[df_filtered['reps'].idxmax()]\n",
        "    html_output.append(f\"<li><b>Most Reps:</b> {pr_reps['reps']} on {pr_reps['date'].strftime('%Y-%m-%d')}</li>\")\n",
        "\n",
        "    if 'weight_lbs' in df_filtered.columns and df_filtered['weight_lbs'].max() > 0:\n",
        "        pr_weight = df_filtered.loc[df_filtered['weight_lbs'].idxmax()]\n",
        "        html_output.append(f\"<li><b>Heaviest Weight:</b> {pr_weight['weight_lbs']} lbs on {pr_weight['date'].strftime('%Y-%m-%d')}</li>\")\n",
        "    html_output.append(f\"</ul>\")\n",
        "\n",
        "    return \"\".join(html_output)\n",
        "\n",
        "def visualize_progress(user_id, exercise_type, time_period='month'):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualization of user's progress and return an HTML string with base64 image.\n",
        "    \"\"\"\n",
        "    data = load_progress_data(user_id, exercise_type)\n",
        "\n",
        "    if not data or not data['sessions']:\n",
        "        return \"<p>No session data available for visualization.</p>\"\n",
        "\n",
        "    sessions = data['sessions']\n",
        "    df = pd.DataFrame(sessions)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.sort_values('date')\n",
        "\n",
        "    now = datetime.now()\n",
        "    if time_period == 'week':\n",
        "        cutoff_date = now - timedelta(weeks=1)\n",
        "        period_name = \"Last 7 Days\"\n",
        "    elif time_period == '4weeks':\n",
        "        cutoff_date = now - timedelta(weeks=4)\n",
        "        period_name = \"Last 4 Weeks\"\n",
        "    elif time_period == 'month':\n",
        "        cutoff_date = now - timedelta(days=30)\n",
        "        period_name = \"Last 30 Days\"\n",
        "    elif time_period == '3months':\n",
        "        cutoff_date = now - timedelta(days=90)\n",
        "        period_name = \"Last 3 Months\"\n",
        "    elif time_period == '6months':\n",
        "        cutoff_date = now - timedelta(days=180)\n",
        "        period_name = \"Last 6 Months\"\n",
        "    else:\n",
        "        cutoff_date = df['date'].min()\n",
        "        period_name = \"All Time\"\n",
        "\n",
        "    df_filtered = df[df['date'] >= cutoff_date]\n",
        "\n",
        "    if len(df_filtered) == 0:\n",
        "        return f\"<p>No sessions found in {period_name.lower()}.</p>\"\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 12))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    fig.suptitle(f'{exercise_type.upper()} Progress - {period_name}',\n",
        "                 fontsize=20, fontweight='bold', y=0.98)\n",
        "\n",
        "    ax1 = fig.add_subplot(gs[0, :2])\n",
        "    ax1.plot(df_filtered['date'], df_filtered['accuracy'],\n",
        "             marker='o', linewidth=2.5, markersize=8, color='#2E86AB', label='Accuracy')\n",
        "    ax1.axhline(y=85, color='g', linestyle='--', linewidth=2, label='Target (85%)')\n",
        "\n",
        "    if len(df_filtered) > 1:\n",
        "        z = np.polyfit(range(len(df_filtered)), df_filtered['accuracy'], 1)\n",
        "        p = np.poly1d(z)\n",
        "        ax1.plot(df_filtered['date'], p(range(len(df_filtered))),\n",
        "                \"r--\", alpha=0.5, linewidth=2, label='Trend')\n",
        "\n",
        "    ax1.set_xlabel('Date', fontsize=12)\n",
        "    ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    ax1.set_title('Form Accuracy Over Time', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    ax2 = fig.add_subplot(gs[0, 2])\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(df_filtered)))\n",
        "    bars = ax2.bar(range(len(df_filtered)), df_filtered['reps'], color=colors)\n",
        "    ax2.set_xlabel('Session Number', fontsize=11)\n",
        "    ax2.set_ylabel('Reps', fontsize=11)\n",
        "    ax2.set_title('Reps Per Session', fontsize=13, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    ax3 = fig.add_subplot(gs[1, 0])\n",
        "    if 'weight_lbs' in df_filtered.columns:\n",
        "        ax3.plot(df_filtered['date'], df_filtered['weight_lbs'],\n",
        "                marker='s', linewidth=2.5, markersize=8, color='#A23B72')\n",
        "        ax3.fill_between(df_filtered['date'], 0, df_filtered['weight_lbs'],\n",
        "                        alpha=0.3, color='#A23B72')\n",
        "        ax3.set_xlabel('Date', fontsize=11)\n",
        "        ax3.set_ylabel('Weight (lbs)', fontsize=11)\n",
        "        ax3.set_title('Weight Progression', fontsize=13, fontweight='bold')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "        ax3.tick_params(axis='x', rotation=45)\n",
        "    else:\n",
        "        ax3.text(0.5, 0.5, 'No Weight Data', ha='center', va='center',\n",
        "                fontsize=14, transform=ax3.transAxes)\n",
        "        ax3.set_title('Weight Progression', fontsize=13, fontweight='bold')\n",
        "\n",
        "    ax4 = fig.add_subplot(gs[1, 1])\n",
        "    if 'weight_lbs' in df_filtered.columns:\n",
        "        df_filtered['volume'] = df_filtered['reps'] * df_filtered['weight_lbs']\n",
        "        ax4.bar(df_filtered['date'], df_filtered['volume'],\n",
        "               color='#F18F01', alpha=0.7)\n",
        "        ax4.set_xlabel('Date', fontsize=11)\n",
        "        ax4.set_ylabel('Volume (lbs)', fontsize=11)\n",
        "        ax4.set_title('Training Volume (Reps √ó Weight)', fontsize=13, fontweight='bold')\n",
        "        ax4.grid(True, alpha=0.3, axis='y')\n",
        "        ax4.tick_params(axis='x', rotation=45)\n",
        "    else:\n",
        "        ax4.text(0.5, 0.5, 'No Volume Data', ha='center', va='center',\n",
        "                fontsize=14, transform=ax4.transAxes)\n",
        "        ax4.set_title('Training Volume', fontsize=13, fontweight='bold')\n",
        "\n",
        "    ax5 = fig.add_subplot(gs[1, 2])\n",
        "    ax5.plot(df_filtered['date'], df_filtered['avg_difference'],\n",
        "            marker='D', linewidth=2, markersize=7, color='#C73E1D')\n",
        "    ax5.set_xlabel('Date', fontsize=11)\n",
        "    ax5.set_ylabel('Avg Angle Difference (¬∞)', fontsize=11)\n",
        "    ax5.set_title('Average Form Deviation', fontsize=13, fontweight='bold')\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    ax5.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    ax6 = fig.add_subplot(gs[2, 0])\n",
        "    all_issues = {}\n",
        "    for session in df_filtered.to_dict('records'):\n",
        "        if 'issues' in session and isinstance(session['issues'], list):\n",
        "            for issue in session['issues']:\n",
        "                joint = issue['joint']\n",
        "                all_issues[joint] = all_issues.get(joint, 0) + issue['count']\n",
        "\n",
        "    if all_issues:\n",
        "        sorted_issues = sorted(all_issues.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "        joints, counts = zip(*sorted_issues)\n",
        "        joints = [j.replace('_', ' ').title() for j in joints]\n",
        "        ax6.barh(joints, counts, color='#E63946')\n",
        "        ax6.set_xlabel('Frequency', fontsize=11)\n",
        "        ax6.set_title('Most Common Form Issues', fontsize=13, fontweight='bold')\n",
        "        ax6.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "    ax7 = fig.add_subplot(gs[2, 1])\n",
        "    df_filtered['date_only'] = df_filtered['date'].dt.date\n",
        "    session_counts = df_filtered.groupby('date_only').size()\n",
        "\n",
        "    dates = pd.date_range(df_filtered['date'].min(), df_filtered['date'].max(), freq='D')\n",
        "    session_matrix = [session_counts.get(d.date(), 0) for d in dates]\n",
        "\n",
        "    ax7.plot(dates, session_matrix, marker='o', linewidth=2, markersize=6, color='#06A77D')\n",
        "    ax7.fill_between(dates, 0, session_matrix, alpha=0.3, color='#06A77D')\n",
        "    ax7.set_xlabel('Date', fontsize=11)\n",
        "    ax7.set_ylabel('Sessions', fontsize=11)\n",
        "    ax7.set_title('Training Frequency', fontsize=13, fontweight='bold')\n",
        "    ax7.grid(True, alpha=0.3)\n",
        "    ax7.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    ax8 = fig.add_subplot(gs[2, 2])\n",
        "    ax8.axis('off')\n",
        "\n",
        "    pr_text = \"üèÜ PERSONAL RECORDS\\n\\n\"\n",
        "    pr_text += f\"Best Accuracy:\\n{df_filtered['accuracy'].max():.1f}%\\n\\n\"\n",
        "    pr_text += f\"Most Reps:\\n{df_filtered['reps'].max()}\\n\\n\"\n",
        "    if 'weight_lbs' in df_filtered.columns and df_filtered['weight_lbs'].max() > 0:\n",
        "        pr_text += f\"Max Weight:\\n{df_filtered['weight_lbs'].max()} lbs\\n\\n\"\n",
        "    pr_text += f\"Total Sessions:\\n{len(df_filtered)}\\n\\n\"\n",
        "    pr_text += f\"Total Reps:\\n{df_filtered['reps'].sum()}\"\n",
        "\n",
        "    ax8.text(0.1, 0.9, pr_text, fontsize=12, verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    buffer = io.BytesIO()\n",
        "    plt.savefig(buffer, format='png', bbox_inches='tight')\n",
        "    buffer.seek(0)\n",
        "    image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
        "    plt.close(fig)\n",
        "\n",
        "    return f\"<img src='data:image/png;base64,{image_base64}' style='max-width:100%; height:auto;'/>\"\n",
        "\n",
        "\n",
        "def compare_time_periods(user_id, exercise_type):\n",
        "    \"\"\"\n",
        "    Compare performance across different time periods and return an HTML string.\n",
        "    \"\"\"\n",
        "    html_output = []\n",
        "    html_output.append(f\"<h3>üìä COMPARATIVE ANALYSIS - {exercise_type.upper()}</h3>\")\n",
        "\n",
        "    periods = {\n",
        "        'day': 'Last 24 Hours',\n",
        "        'week': 'Last 7 Days',\n",
        "        'month': 'Last 30 Days',\n",
        "        '4weeks': 'Last 4 Weeks'\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for period_key, period_name in periods.items():\n",
        "        df = load_progress_data(user_id, exercise_type)\n",
        "        if not df or not df['sessions']:\n",
        "            html_output.append(f\"<p>No session data available for {period_name}.</p>\")\n",
        "            continue\n",
        "\n",
        "        sessions = df['sessions']\n",
        "        df_all = pd.DataFrame(sessions)\n",
        "        df_all['date'] = pd.to_datetime(df_all['date'])\n",
        "\n",
        "        now = datetime.now()\n",
        "        if period_key == 'day':\n",
        "            cutoff_date = now - timedelta(days=1)\n",
        "        elif period_key == 'week':\n",
        "            cutoff_date = now - timedelta(weeks=1)\n",
        "        elif period_key == '4weeks':\n",
        "            cutoff_date = now - timedelta(weeks=4)\n",
        "        elif period_key == 'month':\n",
        "            cutoff_date = now - timedelta(days=30)\n",
        "        else:\n",
        "            cutoff_date = df_all['date'].min()\n",
        "\n",
        "        df_filtered = df_all[df_all['date'] >= cutoff_date]\n",
        "\n",
        "        if len(df_filtered) > 0:\n",
        "            results[period_name] = {\n",
        "                'sessions': len(df_filtered),\n",
        "                'avg_accuracy': df_filtered['accuracy'].mean(),\n",
        "                'total_reps': df_filtered['reps'].sum(),\n",
        "                'max_weight': df_filtered['weight_lbs'].max() if 'weight_lbs' in df_filtered.columns else 0\n",
        "            }\n",
        "        else:\n",
        "            html_output.append(f\"<p>No sessions found for {period_name}.</p>\")\n",
        "\n",
        "    if results:\n",
        "        html_output.append(\"<h4>üìà SUMMARY COMPARISON:</h4>\")\n",
        "        html_output.append(\"<table border='1' style='width:100%; border-collapse: collapse;'>\")\n",
        "        html_output.append(\"<thead><tr><th>Period</th><th>Sessions</th><th>Avg Accuracy</th><th>Total Reps</th><th>Max Weight</th></tr></thead>\")\n",
        "        html_output.append(\"<tbody>\")\n",
        "        for period, stats in results.items():\n",
        "            html_output.append(f\"<tr>\"\n",
        "                               f\"<td>{period}</td>\"\n",
        "                               f\"<td>{stats['sessions']}</td>\"\n",
        "                               f\"<td>{stats['avg_accuracy']:.1f}%</td>\"\n",
        "                               f\"<td>{stats['total_reps']}</td>\"\n",
        "                               f\"<td>{stats['max_weight']} lbs</td>\"\n",
        "                               f\"</tr>\")\n",
        "        html_output.append(\"</tbody></table>\")\n",
        "    else:\n",
        "        html_output.append(\"<p>No comparative data available.</p>\")\n",
        "\n",
        "    return \"\".join(html_output)\n",
        "\n",
        "\n",
        "# We'll use the demo_user and squat exercise for 'month' (Last 30 Days)\n",
        "example_html_output = analyze_progress('demo_user', 'squat', 'month')\n",
        "display(HTML(example_html_output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6a611b8"
      },
      "source": [
        "## Explain How to Display Python Output in HTML\n",
        "\n",
        "### Subtask:\n",
        "Describe how to modify the existing Python analysis functions (`analyze_progress`, `visualize_progress`, `compare_time_periods`) to produce HTML-friendly output (e.g., formatted strings, base64-encoded plot images) that can be dynamically inserted into the HTML dashboard's display area.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "612527cc"
      },
      "source": [
        "### Instructions to Modify Python Analysis Functions for HTML Output\n",
        "\n",
        "To integrate the Python analysis functions into an HTML dashboard, we need to adapt their output format. Instead of printing directly to the console or displaying plots, they will return HTML strings that can be dynamically inserted into the dashboard's display area.\n",
        "\n",
        "#### 1. Modify `analyze_progress` and `compare_time_periods`\n",
        "\n",
        "These functions currently print their reports directly. We need to refactor them to build and return a single HTML string containing the report. Use appropriate HTML tags for structure and styling.\n",
        "\n",
        "**Key Changes:**\n",
        "- Initialize an empty list or string variable (e.g., `html_output = []` or `html_output = \"\"`).\n",
        "- Replace each `print()` statement with an append operation that adds HTML-formatted text to `html_output`.\n",
        "  - Titles should be `<h3>` or `<h4>`.\n",
        "  - Paragraphs should be `<p>`.\n",
        "  - Lists (e.g., most common issues, personal records) should be `<ul>` and `<li>`.\n",
        "  - Use `<br>` for line breaks where needed.\n",
        "- Ensure all dynamic values (e.g., accuracy percentages, joint names) are correctly embedded within the HTML string.\n",
        "- The function should return the concatenated `html_output` string.\n",
        "\n",
        "**Example Transformation (Conceptual):**\n",
        "\n",
        "```python\n",
        "# Before (simplified)\n",
        "print(f\"Average Accuracy: {df_filtered['accuracy'].mean():.1f}%\")\n",
        "\n",
        "# After (conceptual)\n",
        "html_output.append(f\"<p><b>Average Accuracy:</b> {df_filtered['accuracy'].mean():.1f}%</p>\")\n",
        "```\n",
        "\n",
        "#### 2. Modify `visualize_progress`\n",
        "\n",
        "This function generates a Matplotlib plot and saves it as a file or calls `plt.show()`. For HTML integration, we need to capture the plot directly into memory, encode it as a base64 string, and embed it within an `<img>` tag.\n",
        "\n",
        "**Key Changes:**\n",
        "- **Import necessary libraries**: Add `import io` and `import base64` at the top of the file (or where `visualize_progress` is defined).\n",
        "- **Remove plot display/save calls**: Delete `plt.show()` and `plt.savefig()` from the function.\n",
        "- **Capture plot to buffer**: After `plt.tight_layout()` and before `plt.show()` (if it were present), insert code to save the figure to an in-memory buffer:\n",
        "  ```python\n",
        "  buffer = io.BytesIO()\n",
        "  plt.savefig(buffer, format='png', bbox_inches='tight')\n",
        "  buffer.seek(0)\n",
        "  ```\n",
        "- **Encode to Base64**: Encode the content of the buffer to a base64 string:\n",
        "  ```python\n",
        "  image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
        "  ```\n",
        "- **Clear the plot**: Add `plt.close(fig)` or `plt.clf()` to prevent plots from displaying multiple times if the function is called repeatedly in a non-interactive context.\n",
        "- **Return HTML string**: Construct an HTML `<img>` tag with the base64 string and return it:\n",
        "  ```python\n",
        "  return f\"<img src='data:image/png;base64,{image_base64}' style='max-width:100%; height:auto;'/>\"\n",
        "  ```\n",
        "\n",
        "By implementing these changes, the Python analysis functions will produce HTML-compatible output, making them ready for dynamic insertion into the HTML dashboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "373d93d2"
      },
      "source": [
        "**Reasoning**:\n",
        "Now, I will modify the existing `analyze_progress` function to build and return an HTML string instead of printing directly to the console. This involves collecting all output into a list of HTML snippets and joining them at the end. I'm taking into consideration the styling and structural changes mentioned previously.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f32b13f"
      },
      "source": [
        "import json\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Redefining helper functions needed by the main functions, as they are not globally available in this execution context.\n",
        "# Ideally, these would be in a separate utility file or defined earlier in the notebook.\n",
        "\n",
        "def load_progress_data(user_id, exercise_type):\n",
        "    \"\"\"\n",
        "    Load user's progress data\n",
        "    \"\"\"\n",
        "    progress_file = f'/content/progress_data/{user_id}_{exercise_type}_progress.json'\n",
        "\n",
        "    if not os.path.exists(progress_file):\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with open(progress_file, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except json.JSONDecodeError:\n",
        "        return None\n",
        "\n",
        "\n",
        "def analyze_progress(user_id, exercise_type, time_period='all'):\n",
        "    \"\"\"\n",
        "    Analyze user's progress over specified time period and return a JSON string.\n",
        "    \"\"\"\n",
        "    analysis_results = {\"status\": \"error\", \"message\": \"No session data available for analysis.\"}\n",
        "\n",
        "    data = load_progress_data(user_id, exercise_type)\n",
        "\n",
        "    if not data or not data['sessions']:\n",
        "        return json.dumps(analysis_results, indent=2)\n",
        "\n",
        "    sessions = data['sessions']\n",
        "    df = pd.DataFrame(sessions)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "    df = df.sort_values('date')\n",
        "\n",
        "    now = datetime.now()\n",
        "    if time_period == 'day':\n",
        "        cutoff_date = now - timedelta(days=1)\n",
        "        period_name = \"Last 24 Hours\"\n",
        "    elif time_period == 'week':\n",
        "        cutoff_date = now - timedelta(weeks=1)\n",
        "        period_name = \"Last 7 Days\"\n",
        "    elif time_period == '4weeks':\n",
        "        cutoff_date = now - timedelta(weeks=4)\n",
        "        period_name = \"Last 4 Weeks\"\n",
        "    elif time_period == 'month':\n",
        "        cutoff_date = now - timedelta(days=30)\n",
        "        period_name = \"Last 30 Days\"\n",
        "    else:\n",
        "        cutoff_date = df['date'].min()\n",
        "        period_name = \"All Time\"\n",
        "\n",
        "    df_filtered = df[df['date'] >= cutoff_date]\n",
        "\n",
        "    if len(df_filtered) == 0:\n",
        "        analysis_results[\"message\"] = f\"No sessions found in {period_name.lower()}.\"\n",
        "        return json.dumps(analysis_results, indent=2)\n",
        "\n",
        "    analysis_results = {\n",
        "        \"status\": \"success\",\n",
        "        \"exercise\": exercise_type.upper(),\n",
        "        \"period_name\": period_name,\n",
        "        \"total_sessions\": len(df_filtered),\n",
        "        \"date_range_start\": df_filtered['date'].min().strftime('%Y-%m-%d'),\n",
        "        \"date_range_end\": df_filtered['date'].max().strftime('%Y-%m-%d'),\n",
        "        \"form_quality\": {},\n",
        "        \"volume_intensity\": {},\n",
        "        \"weight_progression\": {},\n",
        "        \"training_frequency\": {},\n",
        "        \"most_common_issues\": [],\n",
        "        \"personal_records\": {}\n",
        "    }\n",
        "\n",
        "    # Form Quality\n",
        "    analysis_results[\"form_quality\"] = {\n",
        "        \"current_accuracy\": round(float(df_filtered.iloc[-1]['accuracy']), 1),\n",
        "        \"starting_accuracy\": round(float(df_filtered.iloc[0]['accuracy']), 1),\n",
        "        \"improvement\": round(float(df_filtered.iloc[-1]['accuracy'] - df_filtered.iloc[0]['accuracy']), 1),\n",
        "        \"average_accuracy\": round(float(df_filtered['accuracy'].mean()), 1),\n",
        "        \"best_session_accuracy\": round(float(df_filtered['accuracy'].max()), 1)\n",
        "    }\n",
        "\n",
        "    # Volume & Intensity\n",
        "    total_reps = int(df_filtered['reps'].sum())\n",
        "    analysis_results[\"volume_intensity\"] = {\n",
        "        \"total_reps\": total_reps,\n",
        "        \"average_reps_per_session\": round(float(df_filtered['reps'].mean()), 1),\n",
        "        \"max_reps_single_session\": int(df_filtered['reps'].max())\n",
        "    }\n",
        "\n",
        "    # Weight Progression\n",
        "    if 'weight_lbs' in df_filtered.columns and df_filtered['weight_lbs'].max() > 0:\n",
        "        max_weight = float(df_filtered['weight_lbs'].max())\n",
        "        current_weight = float(df_filtered.iloc[-1]['weight_lbs'])\n",
        "        starting_weight = float(df_filtered.iloc[0]['weight_lbs'])\n",
        "        df_filtered['volume'] = df_filtered['reps'] * df_filtered['weight_lbs']\n",
        "        total_volume = int(df_filtered['volume'].sum())\n",
        "\n",
        "        analysis_results[\"weight_progression\"] = {\n",
        "            \"current_weight_lbs\": current_weight,\n",
        "            \"starting_weight_lbs\": starting_weight,\n",
        "            \"max_weight_used_lbs\": max_weight,\n",
        "            \"weight_increase_lbs\": round(current_weight - starting_weight, 1),\n",
        "            \"total_volume_lbs\": total_volume\n",
        "        }\n",
        "\n",
        "    # Training Frequency\n",
        "    days_span = (df_filtered['date'].max() - df_filtered['date'].min()).days + 1\n",
        "    sessions_per_week = (len(df_filtered) / days_span) * 7 if days_span > 0 else 0\n",
        "    days_since_last_session = (now - df_filtered['date'].max()).days\n",
        "\n",
        "    df_filtered['date_only'] = df_filtered['date'].dt.date\n",
        "    unique_dates = sorted(df_filtered['date_only'].unique(), reverse=True)\n",
        "    current_streak = 0\n",
        "    if unique_dates:\n",
        "        for i, date in enumerate(unique_dates):\n",
        "            if i == 0:\n",
        "                days_diff = (datetime.now().date() - date).days\n",
        "                if days_diff <= 1:\n",
        "                    current_streak = 1\n",
        "                else:\n",
        "                    break\n",
        "            else:\n",
        "                days_diff = (unique_dates[i-1] - date).days\n",
        "                if days_diff == 1:\n",
        "                    current_streak += 1\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "    analysis_results[\"training_frequency\"] = {\n",
        "        \"sessions_per_week\": round(sessions_per_week, 1),\n",
        "        \"days_since_last_session\": days_since_last_session,\n",
        "        \"current_streak_days\": current_streak\n",
        "    }\n",
        "\n",
        "    # Trend analysis\n",
        "    if len(df_filtered) >= 3:\n",
        "        recent_avg = df_filtered.tail(3)['accuracy'].mean()\n",
        "        early_avg = df_filtered.head(3)['accuracy'].mean()\n",
        "        if recent_avg > early_avg + 2:\n",
        "            trend = \"Improving\"\n",
        "        elif recent_avg < early_avg - 2:\n",
        "            trend = \"Declining\"\n",
        "        else:\n",
        "            trend = \"Stable\"\n",
        "        analysis_results[\"trend\"] = trend\n",
        "\n",
        "    # Most common issues\n",
        "    all_issues = {}\n",
        "    for session in df_filtered.to_dict('records'):\n",
        "        if 'issues' in session and isinstance(session['issues'], list):\n",
        "            for issue in session['issues']:\n",
        "                joint = issue['joint']\n",
        "                all_issues[joint] = all_issues.get(joint, 0) + issue['count']\n",
        "\n",
        "    if all_issues:\n",
        "        sorted_issues = sorted(all_issues.items(), key=lambda x: x[1], reverse=True)\n",
        "        analysis_results[\"most_common_issues\"] = [\n",
        "            {\"joint\": joint.replace('_', ' ').title(), \"occurrences\": count}\n",
        "            for joint, count in sorted_issues[:3]\n",
        "        ]\n",
        "\n",
        "    # Personal Records\n",
        "    pr_accuracy = df_filtered.loc[df_filtered['accuracy'].idxmax()]\n",
        "    pr_reps = df_filtered.loc[df_filtered['reps'].idxmax()]\n",
        "\n",
        "    analysis_results[\"personal_records\"] = {\n",
        "        \"best_accuracy\": {\n",
        "            \"value\": round(float(pr_accuracy['accuracy']), 1),\n",
        "            \"date\": pr_accuracy['date'].strftime('%Y-%m-%d')\n",
        "        },\n",
        "        \"most_reps\": {\n",
        "            \"value\": int(pr_reps['reps']),\n",
        "            \"date\": pr_reps['date'].strftime('%Y-%m-%d')\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if 'weight_lbs' in df_filtered.columns and df_filtered['weight_lbs'].max() > 0:\n",
        "        pr_weight = df_filtered.loc[df_filtered['weight_lbs'].idxmax()]\n",
        "        analysis_results[\"personal_records\"][\"heaviest_weight\"] = {\n",
        "            \"value\": float(pr_weight['weight_lbs']),\n",
        "            \"date\": pr_weight['date'].strftime('%Y-%m-%d')\n",
        "        }\n",
        "\n",
        "    return json.dumps(analysis_results, indent=2)\n",
        "\n",
        "def visualize_progress(user_id, exercise_type, time_period='month'):\n",
        "    \"\"\"\n",
        "    Create comprehensive visualization of user's progress and return an HTML string with base64 image.\n",
        "    \"\"\"\n",
        "    data = load_progress_data(user_id, exercise_type)\n",
        "\n",
        "    if not data or not data['sessions']:\n",
        "        return \"<p>No session data available for visualization.</p>\"\n",
        "\n",
        "    sessions = data['sessions']\n",
        "    df = pd.DataFrame(sessions)\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.sort_values('date')\n",
        "\n",
        "    now = datetime.now()\n",
        "    if time_period == 'week':\n",
        "        cutoff_date = now - timedelta(weeks=1)\n",
        "        period_name = \"Last 7 Days\"\n",
        "    elif time_period == '4weeks':\n",
        "        cutoff_date = now - timedelta(weeks=4)\n",
        "        period_name = \"Last 4 Weeks\"\n",
        "    elif time_period == 'month':\n",
        "        cutoff_date = now - timedelta(days=30)\n",
        "        period_name = \"Last 30 Days\"\n",
        "    elif time_period == '3months':\n",
        "        cutoff_date = now - timedelta(days=90)\n",
        "        period_name = \"Last 3 Months\"\n",
        "    elif time_period == '6months':\n",
        "        cutoff_date = now - timedelta(days=180)\n",
        "        period_name = \"Last 6 Months\"\n",
        "    else:\n",
        "        cutoff_date = df['date'].min()\n",
        "        period_name = \"All Time\"\n",
        "\n",
        "    df_filtered = df[df['date'] >= cutoff_date]\n",
        "\n",
        "    if len(df_filtered) == 0:\n",
        "        return f\"<p>No sessions found in {period_name.lower()}.</p>\"\n",
        "\n",
        "    fig = plt.figure(figsize=(20, 12))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    fig.suptitle(f'{exercise_type.upper()} Progress - {period_name}',\n",
        "                 fontsize=20, fontweight='bold', y=0.98)\n",
        "\n",
        "    ax1 = fig.add_subplot(gs[0, :2])\n",
        "    ax1.plot(df_filtered['date'], df_filtered['accuracy'],\n",
        "             marker='o', linewidth=2.5, markersize=8, color='#2E86AB', label='Accuracy')\n",
        "    ax1.axhline(y=85, color='g', linestyle='--', linewidth=2, label='Target (85%)')\n",
        "\n",
        "    if len(df_filtered) > 1:\n",
        "        z = np.polyfit(range(len(df_filtered)), df_filtered['accuracy'], 1)\n",
        "        p = np.poly1d(z)\n",
        "        ax1.plot(df_filtered['date'], p(range(len(df_filtered))),\n",
        "                \"r--\", alpha=0.5, linewidth=2, label='Trend')\n",
        "\n",
        "    ax1.set_xlabel('Date', fontsize=12)\n",
        "    ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    ax1.set_title('Form Accuracy Over Time', fontsize=14, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    ax2 = fig.add_subplot(gs[0, 2])\n",
        "    colors = plt.cm.viridis(np.linspace(0, 1, len(df_filtered)))\n",
        "    bars = ax2.bar(range(len(df_filtered)), df_filtered['reps'], color=colors)\n",
        "    ax2.set_xlabel('Session Number', fontsize=11)\n",
        "    ax2.set_ylabel('Reps', fontsize=11)\n",
        "    ax2.set_title('Reps Per Session', fontsize=13, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    ax3 = fig.add_subplot(gs[1, 0])\n",
        "    if 'weight_lbs' in df_filtered.columns:\n",
        "        ax3.plot(df_filtered['date'], df_filtered['weight_lbs'],\n",
        "                marker='s', linewidth=2.5, markersize=8, color='#A23B72')\n",
        "        ax3.fill_between(df_filtered['date'], 0, df_filtered['weight_lbs'],\n",
        "                        alpha=0.3, color='#A23B72')\n",
        "        ax3.set_xlabel('Date', fontsize=11)\n",
        "        ax3.set_ylabel('Weight (lbs)', fontsize=11)\n",
        "        ax3.set_title('Weight Progression', fontsize=13, fontweight='bold')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "        ax3.tick_params(axis='x', rotation=45)\n",
        "    else:\n",
        "        ax3.text(0.5, 0.5, 'No Weight Data', ha='center', va='center',\n",
        "                fontsize=14, transform=ax3.transAxes)\n",
        "        ax3.set_title('Weight Progression', fontsize=13, fontweight='bold')\n",
        "\n",
        "    ax4 = fig.add_subplot(gs[1, 1])\n",
        "    if 'weight_lbs' in df_filtered.columns:\n",
        "        df_filtered['volume'] = df_filtered['reps'] * df_filtered['weight_lbs']\n",
        "        ax4.bar(df_filtered['date'], df_filtered['volume'],\n",
        "               color='#F18F01', alpha=0.7)\n",
        "        ax4.set_xlabel('Date', fontsize=11)\n",
        "        ax4.set_ylabel('Volume (lbs)', fontsize=11)\n",
        "        ax4.set_title('Training Volume (Reps √ó Weight)', fontsize=13, fontweight='bold')\n",
        "        ax4.grid(True, alpha=0.3, axis='y')\n",
        "        ax4.tick_params(axis='x', rotation=45)\n",
        "    else:\n",
        "        ax4.text(0.5, 0.5, 'No Volume Data', ha='center', va='center',\n",
        "                fontsize=14, transform=ax4.transAxes)\n",
        "        ax4.set_title('Training Volume', fontsize=13, fontweight='bold')\n",
        "\n",
        "    ax5 = fig.add_subplot(gs[1, 2])\n",
        "    ax5.plot(df_filtered['date'], df_filtered['avg_difference'],\n",
        "            marker='D', linewidth=2, markersize=7, color='#C73E1D')\n",
        "    ax5.set_xlabel('Date', fontsize=11)\n",
        "    ax5.set_ylabel('Avg Angle Difference (¬∞)', fontsize=11)\n",
        "    ax5.set_title('Average Form Deviation', fontsize=13, fontweight='bold')\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    ax5.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    ax6 = fig.add_subplot(gs[2, 0])\n",
        "    all_issues = {}\n",
        "    for session in df_filtered.to_dict('records'):\n",
        "        if 'issues' in session and isinstance(session['issues'], list):\n",
        "            for issue in session['issues']:\n",
        "                joint = issue['joint']\n",
        "                all_issues[joint] = all_issues.get(joint, 0) + issue['count']\n",
        "\n",
        "    if all_issues:\n",
        "        sorted_issues = sorted(all_issues.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "        joints, counts = zip(*sorted_issues)\n",
        "        joints = [j.replace('_', ' ').title() for j in joints]\n",
        "        ax6.barh(joints, counts, color='#E63946')\n",
        "        ax6.set_xlabel('Frequency', fontsize=11)\n",
        "        ax6.set_title('Most Common Form Issues', fontsize=13, fontweight='bold')\n",
        "        ax6.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "    ax7 = fig.add_subplot(gs[2, 1])\n",
        "    df_filtered['date_only'] = df_filtered['date'].dt.date\n",
        "    session_counts = df_filtered.groupby('date_only').size()\n",
        "\n",
        "    dates = pd.date_range(df_filtered['date'].min(), df_filtered['date'].max(), freq='D')\n",
        "    session_matrix = [session_counts.get(d.date(), 0) for d in dates]\n",
        "\n",
        "    ax7.plot(dates, session_matrix, marker='o', linewidth=2, markersize=6, color='#06A77D')\n",
        "    ax7.fill_between(dates, 0, session_matrix, alpha=0.3, color='#06A77D')\n",
        "    ax7.set_xlabel('Date', fontsize=11)\n",
        "    ax7.set_ylabel('Sessions', fontsize=11)\n",
        "    ax7.set_title('Training Frequency', fontsize=13, fontweight='bold')\n",
        "    ax7.grid(True, alpha=0.3)\n",
        "    ax7.tick_params(axis='x', rotation=45)\n",
        "\n",
        "    ax8 = fig.add_subplot(gs[2, 2])\n",
        "    ax8.axis('off')\n",
        "\n",
        "    pr_text = \"üèÜ PERSONAL RECORDS\\n\\n\"\n",
        "    pr_text += f\"Best Accuracy:\\n{df_filtered['accuracy'].max():.1f}%\\n\\n\"\n",
        "    pr_text += f\"Most Reps:\\n{df_filtered['reps'].max()}\\n\\n\"\n",
        "    if 'weight_lbs' in df_filtered.columns and df_filtered['weight_lbs'].max() > 0:\n",
        "        pr_text += f\"Max Weight:\\n{df_filtered['weight_lbs'].max()} lbs\\n\\n\"\n",
        "    pr_text += f\"Total Sessions:\\n{len(df_filtered)}\\n\\n\"\n",
        "    pr_text += f\"Total Reps:\\n{df_filtered['reps'].sum()}\"\n",
        "\n",
        "    ax8.text(0.1, 0.9, pr_text, fontsize=12, verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    buffer = io.BytesIO()\n",
        "    plt.savefig(buffer, format='png', bbox_inches='tight')\n",
        "    buffer.seek(0)\n",
        "    image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
        "    plt.close(fig)\n",
        "\n",
        "    return f\"<img src='data:image/png;base64,{image_base64}' style='max-width:100%; height:auto;'/>\"\n",
        "\n",
        "\n",
        "def compare_time_periods(user_id, exercise_type):\n",
        "    \"\"\"\n",
        "    Compare performance across different time periods and return an HTML string.\n",
        "    \"\"\"\n",
        "    html_output = []\n",
        "    html_output.append(f\"<h3>üìä COMPARATIVE ANALYSIS - {exercise_type.upper()}</h3>\")\n",
        "\n",
        "    periods = {\n",
        "        'day': 'Last 24 Hours',\n",
        "        'week': 'Last 7 Days',\n",
        "        'month': 'Last 30 Days',\n",
        "        '4weeks': 'Last 4 Weeks'\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for period_key, period_name in periods.items():\n",
        "        # Call analyze_progress to get JSON data for each period\n",
        "        json_data = analyze_progress(user_id, exercise_type, time_period=period_key)\n",
        "        period_analysis = json.loads(json_data)\n",
        "\n",
        "        if period_analysis[\"status\"] == \"success\" and period_analysis[\"total_sessions\"] > 0:\n",
        "            results[period_name] = {\n",
        "                'sessions': period_analysis[\"total_sessions\"],\n",
        "                'avg_accuracy': period_analysis[\"form_quality\"][\"average_accuracy\"],\n",
        "                'total_reps': period_analysis[\"volume_intensity\"][\"total_reps\"],\n",
        "                'max_weight': period_analysis[\"weight_progression\"][\"max_weight_used_lbs\"] if \"weight_progression\" in period_analysis else 0\n",
        "            }\n",
        "        else:\n",
        "            html_output.append(f\"<p>No session data available for {period_name}.</p>\")\n",
        "\n",
        "    if results:\n",
        "        html_output.append(\"<h4>üìà SUMMARY COMPARISON:</h4>\")\n",
        "        html_output.append(\"<table border='1' style='width:100%; border-collapse: collapse;'>\")\n",
        "        html_output.append(\"<thead><tr><th>Period</th><th>Sessions</th><th>Avg Accuracy</th><th>Total Reps</th><th>Max Weight</th></tr></thead>\")\n",
        "        html_output.append(\"<tbody>\")\n",
        "        for period, stats in results.items():\n",
        "            html_output.append(f\"<tr>\"\n",
        "                               f\"<td>{period}</td>\"\n",
        "                               f\"<td>{stats['sessions']}</td>\"\n",
        "                               f\"<td>{stats['avg_accuracy']:.1f}%</td>\"\n",
        "                               f\"<td>{stats['total_reps']}</td>\"\n",
        "                               f\"<td>{stats['max_weight']} lbs</td>\"\n",
        "                               f\"</tr>\")\n",
        "        html_output.append(\"</tbody></table>\")\n",
        "    else:\n",
        "        html_output.append(\"<p>No comparative data available.</p>\")\n",
        "\n",
        "    return \"\".join(html_output)\n",
        "\n",
        "print(\"‚úì Progress analysis functions modified for HTML output.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75792717"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the HTML dashboard implementation and explain how users can interact with it to view progress data and potential next steps for making it fully interactive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0000020"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "**How is the HTML dashboard implemented, and how can users interact with it to view progress data?**\n",
        "The HTML dashboard is implemented by generating a static HTML string within a Python cell using `IPython.display.HTML`. This string defines the dashboard's layout, including input fields for User ID and Exercise Type, a dropdown for Analysis Period, radio buttons for Output Type (Detailed Report or Visual Chart), a button to trigger analysis, and a designated display area for results.\n",
        "\n",
        "Users can interact with it by:\n",
        "1.  **Inputting Data**: Typing a `USER_ID` (e.g., \"demo\\_user\") and an `EXERCISE` (e.g., \"squat\") into the respective text fields.\n",
        "2.  **Selecting Analysis Period**: Choosing a time frame (e.g., \"Last 7 Days\", \"Last 30 Days\", \"All Time\") from the dropdown menu.\n",
        "3.  **Selecting Output Type**: Choosing between a \"Detailed Progress Report\" or a \"Visual Chart\" using radio buttons.\n",
        "4.  **Initiating Analysis**: Clicking the \"Analyze Progress\" button.\n",
        "\n",
        "Currently, this implementation is static; the user interactions (inputs and button clicks) do not yet dynamically trigger the Python analysis functions.\n",
        "\n",
        "**What are the potential next steps for making the dashboard fully interactive?**\n",
        "The next critical step is to integrate JavaScript into the HTML to handle user events (like button clicks) and establish communication with the Python backend. This will involve:\n",
        "1.  **Event Handling**: Adding JavaScript event listeners to the \"Analyze Progress\" button to capture user inputs from the form fields.\n",
        "2.  **Calling Python Backend**: Using mechanisms like `google.colab.output.register_callback` to expose Python functions (`analyze_progress`, `visualize_progress`, `compare_time_periods`) to JavaScript.\n",
        "3.  **Dynamic Display**: Writing JavaScript to call the appropriate Python function with the user's selected parameters and then dynamically injecting the HTML output (reports or base64-encoded images) into the `results_display_area`.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Basic Dashboard Structure Established**: A foundational HTML dashboard was successfully created, featuring input fields for User ID and Exercise Type, a dropdown for Analysis Period, radio buttons for Report/Chart selection, an \"Analyze Progress\" button, and a dedicated results display area.\n",
        "*   **Enhanced Visuals and Layout**: Comprehensive CSS styling was applied to the HTML structure, significantly improving the dashboard's visual appeal, layout, and user experience with elements like `box-shadow`, `border-radius`, and `hover` effects for buttons.\n",
        "*   **Python Functions Adapted for HTML Output**:\n",
        "    *   The `analyze_progress` and `compare_time_periods` Python functions were refactored to return their analysis as structured HTML strings, suitable for direct insertion into the dashboard.\n",
        "    *   The `visualize_progress` function was modified to capture Matplotlib plots into an in-memory buffer, encode them as base64 strings, and embed them within HTML `<img>` tags, enabling dynamic chart display.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The dashboard currently serves as a well-styled static template. The immediate next step is to implement JavaScript to bridge the user interface with the Python analysis backend, enabling dynamic data processing and display.\n",
        "*   Consider using `google.colab.output.register_callback` to expose the Python analysis functions to JavaScript, allowing the HTML button to trigger data processing and update the display area dynamically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb4c110c"
      },
      "source": [
        "# Task\n",
        "Create a new HTML template for a live video analysis dashboard, including sections for video input (file upload or URL), a video player, an area to display annotated video frames, and a dedicated space for real-time textual feedback or metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8b05a6f"
      },
      "source": [
        "## Design Live Analysis Dashboard Layout\n",
        "\n",
        "### Subtask:\n",
        "Create a new HTML template for a dashboard specifically designed for live video analysis. This template will include sections for video input (e.g., file upload or URL), a video player, an area to display the annotated video frames, and a dedicated space for real-time textual feedback or metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eff0cd27"
      },
      "source": [
        "**Reasoning**:\n",
        "To create the new HTML template for the live video analysis dashboard, I will generate a Python code block that defines the HTML structure including video input, video player, annotated frame display, and real-time feedback sections, along with basic CSS for layout and styling, then display it using IPython.display.HTML.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fa6a50a"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "html_template_live = \"\"\"\n",
        "<div class=\"live-dashboard-container\">\n",
        "    <style>\n",
        "        .live-dashboard-container {\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            padding: 25px;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            border-radius: 10px;\n",
        "            background-color: #fcfcfc;\n",
        "            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);\n",
        "            max-width: 1200px;\n",
        "            margin: 20px auto;\n",
        "            display: flex;\n",
        "            flex-wrap: wrap;\n",
        "            gap: 20px;\n",
        "        }\n",
        "        h2 {\n",
        "            width: 100%;\n",
        "            color: #2c3e50;\n",
        "            text-align: center;\n",
        "            margin-bottom: 25px;\n",
        "            font-size: 2.2em;\n",
        "        }\n",
        "        .section {\n",
        "            background-color: #ffffff;\n",
        "            border: 1px solid #e9ecef;\n",
        "            border-radius: 8px;\n",
        "            padding: 20px;\n",
        "            box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
        "        }\n",
        "        .video-input-section {\n",
        "            flex: 1 1 300px;\n",
        "            min-width: 300px;\n",
        "        }\n",
        "        .video-display-section {\n",
        "            flex: 2 1 600px;\n",
        "            min-width: 600px;\n",
        "        }\n",
        "        .feedback-section {\n",
        "            flex: 1 1 300px;\n",
        "            min-width: 300px;\n",
        "        }\n",
        "        .form-group {\n",
        "            margin-bottom: 15px;\n",
        "        }\n",
        "        label {\n",
        "            font-weight: bold;\n",
        "            color: #34495e;\n",
        "            display: block;\n",
        "            margin-bottom: 5px;\n",
        "        }\n",
        "        input[type=\"file\"], input[type=\"text\"] {\n",
        "            width: calc(100% - 22px);\n",
        "            padding: 10px;\n",
        "            border: 1px solid #bdc3c7;\n",
        "            border-radius: 6px;\n",
        "            font-size: 1em;\n",
        "            box-sizing: border-box;\n",
        "            transition: border-color 0.2s, box-shadow 0.2s;\n",
        "        }\n",
        "        input[type=\"text\"]:focus {\n",
        "            border-color: #3498db;\n",
        "            box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.2);\n",
        "            outline: none;\n",
        "        }\n",
        "        button {\n",
        "            padding: 10px 15px;\n",
        "            background-color: #2ecc71;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 6px;\n",
        "            cursor: pointer;\n",
        "            font-size: 1em;\n",
        "            font-weight: bold;\n",
        "            transition: background-color 0.3s ease, transform 0.1s ease;\n",
        "            margin-top: 10px;\n",
        "        }\n",
        "        button:hover {\n",
        "            background-color: #27ae60;\n",
        "            transform: translateY(-1px);\n",
        "        }\n",
        "        video {\n",
        "            width: 100%;\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 8px;\n",
        "            background-color: #000;\n",
        "            display: block; /* Ensure it doesn't take less than 100% width due to baseline */\n",
        "        }\n",
        "        .annotated-frame-display {\n",
        "            width: 100%;\n",
        "            height: auto; /* Adjust height based on content */\n",
        "            min-height: 360px; /* Minimum height for visual */\n",
        "            background-color: #e9ecef;\n",
        "            border: 1px dashed #ced4da;\n",
        "            border-radius: 8px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            justify-content: center;\n",
        "            color: #6c757d;\n",
        "            font-style: italic;\n",
        "            text-align: center;\n",
        "            overflow: hidden; /* Hide overflow if image too large */\n",
        "        }\n",
        "        .annotated-frame-display img {\n",
        "            max-width: 100%;\n",
        "            max-height: 100%;\n",
        "            object-fit: contain;\n",
        "        }\n",
        "        .realtime-feedback {\n",
        "            min-height: 200px;\n",
        "            max-height: 400px; /* Limit height to prevent excessive scrolling */\n",
        "            overflow-y: auto;\n",
        "            background-color: #e9ecef;\n",
        "            border: 1px dashed #ced4da;\n",
        "            border-radius: 8px;\n",
        "            padding: 15px;\n",
        "            font-size: 0.95em;\n",
        "            line-height: 1.5;\n",
        "            color: #343a40;\n",
        "        }\n",
        "        @media (max-width: 900px) {\n",
        "            .live-dashboard-container {\n",
        "                flex-direction: column;\n",
        "            }\n",
        "            .video-input-section, .video-display-section, .feedback-section {\n",
        "                flex: 1 1 100%;\n",
        "                min-width: unset;\n",
        "            }\n",
        "        }\n",
        "    </style>\n",
        "\n",
        "    <h2>Live Video Analysis Dashboard</h2>\n",
        "\n",
        "    <div class=\"section video-input-section\">\n",
        "        <h3>Video Input</h3>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"video_file\">Upload Video File:</label>\n",
        "            <input type=\"file\" id=\"video_file\" accept=\"video/*\">\n",
        "        </div>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"video_url\">Video URL:</label>\n",
        "            <input type=\"text\" id=\"video_url\" placeholder=\"Enter video URL (e.g., .mp4, .mov)\">\n",
        "        </div>\n",
        "        <button id=\"load_video_button\">Load Video</button>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section video-display-section\">\n",
        "        <h3>Video Player</h3>\n",
        "        <video id=\"video_player\" controls autoplay muted>\n",
        "            <source src=\"\" type=\"video/mp4\">\n",
        "            Your browser does not support the video tag.\n",
        "        </video>\n",
        "        <h3 style=\"margin-top: 20px;\">Annotated Frames</h3>\n",
        "        <div id=\"annotated_frame_display\" class=\"annotated-frame-display\">\n",
        "            <p>Annotated frames will appear here.</p>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section feedback-section\">\n",
        "        <h3>Real-time Feedback & Metrics</h3>\n",
        "        <div id=\"realtime_feedback_area\" class=\"realtime-feedback\">\n",
        "            <p>Live analysis feedback will be displayed here.</p>\n",
        "        </div>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_template_live))\n",
        "print(\"‚úì New HTML template for Live Video Analysis Dashboard displayed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bf9f877"
      },
      "source": [
        "## Create Python Functions for Real-Time Frame Processing\n",
        "\n",
        "### Subtask:\n",
        "Develop or adapt Python functions to efficiently process a single video frame for real-time analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fa975a8"
      },
      "source": [
        "**Reasoning**:\n",
        "To develop the `process_frame_for_live_analysis` function, I need to define it with the specified arguments and implement the logic for decoding the frame, running pose estimation, calculating angles, generating feedback, overlaying annotations and text, and re-encoding the frame to base64.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb2e9da7"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import base64\n",
        "\n",
        "def process_frame_for_live_analysis(base64_frame_string, exercise_type, reference_angles):\n",
        "    \"\"\"\n",
        "    Processes a single base64 encoded video frame for real-time analysis.\n",
        "\n",
        "    Args:\n",
        "        base64_frame_string (str): Base64 encoded string of a video frame.\n",
        "        exercise_type (str): Type of exercise (e.g., 'squat').\n",
        "        reference_angles (dict): Dictionary containing ideal joint angles for the exercise type.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (base64_annotated_frame, feedback_messages)\n",
        "    \"\"\"\n",
        "    # 1. Decode base64 string to OpenCV image\n",
        "    nparr = np.frombuffer(base64.b64decode(base64_frame_string), np.uint8)\n",
        "    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
        "\n",
        "    if frame is None:\n",
        "        return None, [\"Error: Could not decode frame.\"]\n",
        "\n",
        "    # 2. Run YOLO pose estimation\n",
        "    results = model(frame, verbose=False)\n",
        "\n",
        "    feedback_messages = []\n",
        "    annotated_frame = frame.copy()\n",
        "    user_angles = {}\n",
        "    user_keypoints = None\n",
        "\n",
        "    if len(results[0].keypoints) > 0 and results[0].keypoints.xy.shape[0] > 0:\n",
        "        # Assuming only one person is detected for simplicity in live analysis\n",
        "        user_keypoints = results[0].keypoints.xy[0].cpu().numpy()\n",
        "\n",
        "        # 3. Extract keypoints and calculate joint angles\n",
        "        user_angles = get_joint_angles(user_keypoints)\n",
        "\n",
        "        # 4. Generate real-time textual feedback\n",
        "        feedback_messages, _ = compare_form_exercise_specific(\n",
        "            reference_angles, user_angles, exercise_type, threshold=15\n",
        "        )\n",
        "\n",
        "        # 5. Overlay pose estimation\n",
        "        annotated_frame = results[0].plot(\n",
        "            boxes=False, masks=False, probs=False, conf=False, kpt_line=True, labels=False\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        feedback_messages.append(\"No person detected.\")\n",
        "\n",
        "    # 6. Add feedback messages onto the annotated frame\n",
        "    y_offset = 30\n",
        "    for i, msg in enumerate(feedback_messages):\n",
        "        cv2.putText(annotated_frame, msg, (10, y_offset + i * 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "    # 7. Encode the annotated frame back into a base64 encoded JPEG string\n",
        "    _, buffer = cv2.imencode('.jpg', annotated_frame)\n",
        "    base64_annotated_frame = base64.b64encode(buffer).decode('utf-8')\n",
        "\n",
        "    return base64_annotated_frame, feedback_messages\n",
        "\n",
        "print(\"‚úì `process_frame_for_live_analysis` function developed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41e26471"
      },
      "source": [
        "## Implement JavaScript for Video Stream and Python Integration\n",
        "\n",
        "### Subtask:\n",
        "Write JavaScript code within the HTML dashboard to handle user video input, capture frames, send them to the Python backend for analysis, and display the annotated frames and real-time feedback.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8deb9909"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I need to define the `get_sample_reference_angles` Python function, which will provide a set of ideal joint angles for an exercise, as required by the subtask. This function is essential for the `process_frame_for_live_analysis` function to compare user form against a reference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "213de339"
      },
      "source": [
        "def get_sample_reference_angles(exercise_type):\n",
        "    \"\"\"\n",
        "    Returns a dictionary of sample ideal joint angles for a given exercise type.\n",
        "    These are illustrative and would typically come from a trained model or expert data.\n",
        "    \"\"\"\n",
        "    if exercise_type == 'squat':\n",
        "        return {\n",
        "            'left_knee': 90.0, 'right_knee': 90.0,\n",
        "            'left_hip': 90.0, 'right_hip': 90.0,\n",
        "            'left_elbow': 160.0, 'right_elbow': 160.0\n",
        "        }\n",
        "    elif exercise_type == 'pushup':\n",
        "        return {\n",
        "            'left_elbow': 90.0, 'right_elbow': 90.0, # At bottom of pushup\n",
        "            'left_hip': 170.0, 'right_hip': 170.0 # Maintain straight body\n",
        "        }\n",
        "    # Add more exercise types as needed\n",
        "    return {\n",
        "        'left_knee': 180.0, 'right_knee': 180.0,\n",
        "        'left_hip': 180.0, 'right_hip': 180.0,\n",
        "        'left_elbow': 180.0, 'right_elbow': 180.0\n",
        "    }\n",
        "\n",
        "print(\"‚úì `get_sample_reference_angles` function defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7263059d"
      },
      "source": [
        "**Reasoning**:\n",
        "To bridge the Python backend with the HTML frontend, I need to register the `process_frame_for_live_analysis` and `get_sample_reference_angles` functions as Colab output callbacks so that they can be invoked from JavaScript. Then, I will embed JavaScript code within the HTML template to implement the video loading, frame capture, and communication with these registered Python callbacks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69e4ca8f"
      },
      "source": [
        "from google.colab import output\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Register Python functions as callbacks\n",
        "output.register_callback('process_frame_js', process_frame_for_live_analysis)\n",
        "output.register_callback('get_ref_angles_js', get_sample_reference_angles)\n",
        "\n",
        "html_template_live = f\"\"\"\n",
        "<div class=\"live-dashboard-container\">\n",
        "    <style>\n",
        "        .live-dashboard-container {\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            padding: 25px;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            border-radius: 10px;\n",
        "            background-color: #fcfcfc;\n",
        "            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);\n",
        "            max-width: 1200px;\n",
        "            margin: 20px auto;\n",
        "            display: flex;\n",
        "            flex-wrap: wrap;\n",
        "            gap: 20px;\n",
        "        }\n",
        "        h2 {\n",
        "            width: 100%;\n",
        "            color: #2c3e50;\n",
        "            text-align: center;\n",
        "            margin-bottom: 25px;\n",
        "            font-size: 2.2em;\n",
        "        }\n",
        "        .section {\n",
        "            background-color: #ffffff;\n",
        "            border: 1px solid #e9ecef;\n",
        "            border-radius: 8px;\n",
        "            padding: 20px;\n",
        "            box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
        "        }\n",
        "        .video-input-section {\n",
        "            flex: 1 1 300px;\n",
        "            min-width: 300px;\n",
        "        }\n",
        "        .video-display-section {\n",
        "            flex: 2 1 600px;\n",
        "            min-width: 600px;\n",
        "        }\n",
        "        .feedback-section {\n",
        "            flex: 1 1 300px;\n",
        "            min-width: 300px;\n",
        "        }\n",
        "        .form-group {\n",
        "            margin-bottom: 15px;\n",
        "        }\n",
        "        label {\n",
        "            font-weight: bold;\n",
        "            color: #34495e;\n",
        "            display: block;\n",
        "            margin-bottom: 5px;\n",
        "        }\n",
        "        input[type=\"file\"], input[type=\"text\"] {\n",
        "            width: calc(100% - 22px);\n",
        "            padding: 10px;\n",
        "            border: 1px solid #bdc3c7;\n",
        "            border-radius: 6px;\n",
        "            font-size: 1em;\n",
        "            box-sizing: border-box;\n",
        "            transition: border-color 0.2s, box-shadow 0.2s;\n",
        "        }\n",
        "        input[type=\"text\"]:focus {\n",
        "            border-color: #3498db;\n",
        "            box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.2);\n",
        "            outline: none;\n",
        "        }\n",
        "        button {\n",
        "            padding: 10px 15px;\n",
        "            background-color: #2ecc71;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 6px;\n",
        "            cursor: pointer;\n",
        "            font-size: 1em;\n",
        "            font-weight: bold;\n",
        "            transition: background-color 0.3s ease, transform 0.1s ease;\n",
        "            margin-top: 10px;\n",
        "        }\n",
        "        button:hover {\n",
        "            background-color: #27ae60;\n",
        "            transform: translateY(-1px);\n",
        "        }\n",
        "        video {\n",
        "            width: 100%;\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 8px;\n",
        "            background-color: #000;\n",
        "            display: block; /* Ensure it doesn't take less than 100% width due to baseline */\n",
        "        }\n",
        "        .annotated-frame-display {\n",
        "            width: 100%;\n",
        "            height: auto; /* Adjust height based on content */\n",
        "            min-height: 360px; /* Minimum height for visual */\n",
        "            background-color: #e9ecef;\n",
        "            border: 1px dashed #ced4da;\n",
        "            border-radius: 8px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            justify-content: center;\n",
        "            color: #6c757d;\n",
        "            font-style: italic;\n",
        "            text-align: center;\n",
        "            overflow: hidden; /* Hide overflow if image too large */\n",
        "        }\n",
        "        .annotated-frame-display img {\n",
        "            max-width: 100%;\n",
        "            max-height: 100%;\n",
        "            object-fit: contain;\n",
        "        }\n",
        "        .realtime-feedback {\n",
        "            min-height: 200px;\n",
        "            max-height: 400px; /* Limit height to prevent excessive scrolling */\n",
        "            overflow-y: auto;\n",
        "            background-color: #e9ecef;\n",
        "            border: 1px dashed #ced4da;\n",
        "            border-radius: 8px;\n",
        "            padding: 15px;\n",
        "            font-size: 0.95em;\n",
        "            line-height: 1.5;\n",
        "            color: #343a40;\n",
        "        }\n",
        "        @media (max-width: 900px) {\n",
        "            .live-dashboard-container {\n",
        "                flex-direction: column;\n",
        "            }\n",
        "            .video-input-section, .video-display-section, .feedback-section {\n",
        "                flex: 1 1 100%;\n",
        "                min-width: unset;\n",
        "            }\n",
        "        }\n",
        "    </style>\n",
        "\n",
        "    <h2>Live Video Analysis Dashboard</h2>\n",
        "\n",
        "    <div class=\"section video-input-section\">\n",
        "        <h3>Video Input</h3>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"video_file\">Upload Video File:</label>\n",
        "            <input type=\"file\" id=\"video_file\" accept=\"video/*\">\n",
        "        </div>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"video_url\">Video URL:</label>\n",
        "            <input type=\"text\" id=\"video_url\" placeholder=\"Enter video URL (e.g., .mp4, .mov)\">\n",
        "        </div>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"exercise_select\">Exercise Type:</label>\n",
        "            <select id=\"exercise_select\" style=\"width: calc(100% - 22px); padding: 10px; border: 1px solid #bdc3c7; border-radius: 6px; font-size: 1em; box-sizing: border-box;\">\n",
        "                <option value=\"squat\">Squat</option>\n",
        "                <option value=\"pushup\">Pushup</option>\n",
        "                <option value=\"unknown\">Other/Unknown</option>\n",
        "            </select>\n",
        "        </div>\n",
        "        <button id=\"load_video_button\">Load Video</button>\n",
        "        <button id=\"start_analysis_button\" style=\"background-color: #3498db; margin-left: 10px;\" disabled>Start Analysis</button>\n",
        "        <button id=\"stop_analysis_button\" style=\"background-color: #e74c3c; margin-left: 10px;\" disabled>Stop Analysis</button>\n",
        "\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section video-display-section\">\n",
        "        <h3>Video Player</h3>\n",
        "        <video id=\"video_player\" controls muted preload=\"auto\">\n",
        "            Your browser does not support the video tag.\n",
        "        </video>\n",
        "        <h3 style=\"margin-top: 20px;\">Annotated Frames</h3>\n",
        "        <div id=\"annotated_frame_display\" class=\"annotated-frame-display\">\n",
        "            <p>Annotated frames will appear here.</p>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section feedback-section\">\n",
        "        <h3>Real-time Feedback & Metrics</h3>\n",
        "        <div id=\"realtime_feedback_area\" class=\"realtime-feedback\">\n",
        "            <p>Live analysis feedback will be displayed here.</p>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <canvas id=\"frame_canvas\" style=\"display:none;\"></canvas>\n",
        "\n",
        "    <script>\n",
        "        const videoPlayer = document.getElementById('video_player');\n",
        "        const videoFile = document.getElementById('video_file');\n",
        "        const videoUrl = document.getElementById('video_url');\n",
        "        const exerciseSelect = document.getElementById('exercise_select');\n",
        "        const loadVideoButton = document.getElementById('load_video_button');\n",
        "        const startAnalysisButton = document.getElementById('start_analysis_button');\n",
        "        const stopAnalysisButton = document.getElementById('stop_analysis_button');\n",
        "        const annotatedFrameDisplay = document.getElementById('annotated_frame_display');\n",
        "        const realtimeFeedbackArea = document.getElementById('realtime_feedback_area');\n",
        "        const frameCanvas = document.getElementById('frame_canvas');\n",
        "        const canvasCtx = frameCanvas.getContext('2d');\n",
        "\n",
        "        let animationFrameId = null;\n",
        "        let referenceAngles = null;\n",
        "        let currentExerciseType = 'squat';\n",
        "\n",
        "        // Set up callback functions to be called from Python\n",
        "        async function processFramePython(base64Frame, exerciseType, refAngles) {\n",
        "            const result = await google.colab.output.getData({\n",
        "                name: 'process_frame_js',\n",
        "                args: [base64Frame, exerciseType, refAngles]\n",
        "            });\n",
        "            return result.data;\n",
        "        }\n",
        "\n",
        "        async function getReferenceAnglesPython(exerciseType) {\n",
        "            const result = await google.colab.output.getData({\n",
        "                name: 'get_ref_angles_js',\n",
        "                args: [exerciseType]\n",
        "            });\n",
        "            return result.data;\n",
        "        }\n",
        "\n",
        "        function logFeedback(message, type = 'info') {\n",
        "            const p = document.createElement('p');\n",
        "            p.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;\n",
        "            if (type === 'error') p.style.color = 'red';\n",
        "            else if (type === 'warning') p.style.color = 'orange';\n",
        "            realtimeFeedbackArea.appendChild(p);\n",
        "            realtimeFeedbackArea.scrollTop = realtimeFeedbackArea.scrollHeight;\n",
        "        }\n",
        "\n",
        "        loadVideoButton.addEventListener('click', async () => {\n",
        "            logFeedback('Loading video...');\n",
        "            startAnalysisButton.disabled = true;\n",
        "            stopAnalysisButton.disabled = true;\n",
        "            videoPlayer.pause();\n",
        "            annotatedFrameDisplay.innerHTML = '<p>Annotated frames will appear here.</p>';\n",
        "            realtimeFeedbackArea.innerHTML = '<p>Live analysis feedback will be displayed here.</p>';\n",
        "\n",
        "            currentExerciseType = exerciseSelect.value;\n",
        "            referenceAngles = await getReferenceAnglesPython(currentExerciseType);\n",
        "            logFeedback(`Reference angles loaded for ${currentExerciseType}.`);\n",
        "\n",
        "            if (videoFile.files.length > 0) {\n",
        "                const file = videoFile.files[0];\n",
        "                videoPlayer.src = URL.createObjectURL(file);\n",
        "                videoPlayer.load();\n",
        "            } else if (videoUrl.value) {\n",
        "                videoPlayer.src = videoUrl.value;\n",
        "                videoPlayer.load();\n",
        "            } else {\n",
        "                logFeedback('Please select a video file or enter a URL.', 'error');\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            videoPlayer.onloadeddata = () => {\n",
        "                logFeedback('Video loaded successfully.');\n",
        "                startAnalysisButton.disabled = false;\n",
        "                videoPlayer.play(); // Autoplay once loaded\n",
        "            };\n",
        "            videoPlayer.onerror = () => {\n",
        "                logFeedback('Error loading video. Check URL or file format.', 'error');\n",
        "            };\n",
        "        });\n",
        "\n",
        "        startAnalysisButton.addEventListener('click', () => {\n",
        "            if (!videoPlayer.src) {\n",
        "                logFeedback('No video loaded. Please load a video first.', 'warning');\n",
        "                return;\n",
        "            }\n",
        "            if (!referenceAngles) {\n",
        "                logFeedback('Reference angles not loaded. Please load video again.', 'error');\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            logFeedback('Starting live analysis...');\n",
        "            startAnalysisButton.disabled = true;\n",
        "            stopAnalysisButton.disabled = false;\n",
        "            videoPlayer.play();\n",
        "            processVideoFrames();\n",
        "        });\n",
        "\n",
        "        stopAnalysisButton.addEventListener('click', () => {\n",
        "            logFeedback('Stopping live analysis...');\n",
        "            if (animationFrameId) {\n",
        "                cancelAnimationFrame(animationFrameId);\n",
        "                animationFrameId = null;\n",
        "            }\n",
        "            videoPlayer.pause();\n",
        "            startAnalysisButton.disabled = false;\n",
        "            stopAnalysisButton.disabled = true;\n",
        "        });\n",
        "\n",
        "        videoPlayer.addEventListener('play', () => {\n",
        "             if (startAnalysisButton.disabled && !stopAnalysisButton.disabled) { // If analysis was already started\n",
        "                 processVideoFrames();\n",
        "             }\n",
        "        });\n",
        "\n",
        "        videoPlayer.addEventListener('pause', () => {\n",
        "            if (animationFrameId) {\n",
        "                cancelAnimationFrame(animationFrameId);\n",
        "                animationFrameId = null;\n",
        "            }\n",
        "        });\n",
        "\n",
        "        videoPlayer.addEventListener('ended', () => {\n",
        "            logFeedback('Video ended. Analysis stopped.', 'info');\n",
        "            if (animationFrameId) {\n",
        "                cancelAnimationFrame(animationFrameId);\n",
        "                animationFrameId = null;\n",
        "            }\n",
        "            startAnalysisButton.disabled = false;\n",
        "            stopAnalysisButton.disabled = true;\n",
        "        });\n",
        "\n",
        "        function processVideoFrames() {\n",
        "            if (videoPlayer.paused || videoPlayer.ended) {\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            frameCanvas.width = videoPlayer.videoWidth;\n",
        "            frameCanvas.height = videoPlayer.videoHeight;\n",
        "            canvasCtx.drawImage(videoPlayer, 0, 0, frameCanvas.width, frameCanvas.height);\n",
        "            const base64Frame = frameCanvas.toDataURL('image/jpeg', 0.8).split(',')[1];\n",
        "\n",
        "            processFramePython(base64Frame, currentExerciseType, referenceAngles)\n",
        "                .then(response => {\n",
        "                    const [annotatedFrameBase64, feedbackMessages] = response;\n",
        "                    if (annotatedFrameBase64) {\n",
        "                        annotatedFrameDisplay.innerHTML = `<img src='data:image/jpeg;base64,${annotatedFrameBase64}' alt='Annotated Frame'/>`;\n",
        "                    }\n",
        "                    realtimeFeedbackArea.innerHTML = ''; // Clear previous feedback\n",
        "                    if (feedbackMessages && feedbackMessages.length > 0) {\n",
        "                        feedbackMessages.forEach(msg => logFeedback(msg));\n",
        "                    } else {\n",
        "                         logFeedback('No specific issues detected.', 'info');\n",
        "                    }\n",
        "                })\n",
        "                .catch(error => {\n",
        "                    logFeedback(`Python analysis error: ${error}`, 'error');\n",
        "                });\n",
        "\n",
        "            animationFrameId = requestAnimationFrame(processVideoFrames);\n",
        "        }\n",
        "    </script>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_template_live))\n",
        "print(\"‚úì Live Video Analysis Dashboard with JavaScript interactivity displayed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa79dca0"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt failed because f-strings in Python interpret single curly braces `{}` as placeholders for variables. To include literal curly braces within an f-string, they must be escaped by doubling them (`{{` and `}}`). I need to go through the CSS portion of the `html_template_live` and escape all literal curly braces to fix this `SyntaxError`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73bb47a6"
      },
      "source": [
        "from google.colab import output\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Register Python functions as callbacks\n",
        "output.register_callback('process_frame_js', process_frame_for_live_analysis)\n",
        "output.register_callback('get_ref_angles_js', get_sample_reference_angles)\n",
        "\n",
        "html_template_live = f\"\"\"\n",
        "<div class=\"live-dashboard-container\">\n",
        "    <style>\n",
        "        .live-dashboard-container {{\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            padding: 25px;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            border-radius: 10px;\n",
        "            background-color: #fcfcfc;\n",
        "            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);\n",
        "            max-width: 1200px;\n",
        "            margin: 20px auto;\n",
        "            display: flex;\n",
        "            flex-wrap: wrap;\n",
        "            gap: 20px;\n",
        "        }}\n",
        "        h2 {{\n",
        "            width: 100%;\n",
        "            color: #2c3e50;\n",
        "            text-align: center;\n",
        "            margin-bottom: 25px;\n",
        "            font-size: 2.2em;\n",
        "        }}\n",
        "        .section {{\n",
        "            background-color: #ffffff;\n",
        "            border: 1px solid #e9ecef;\n",
        "            border-radius: 8px;\n",
        "            padding: 20px;\n",
        "            box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
        "        }}\n",
        "        .video-input-section {{\n",
        "            flex: 1 1 300px;\n",
        "            min-width: 300px;\n",
        "        }}\n",
        "        .video-display-section {{\n",
        "            flex: 2 1 600px;\n",
        "            min-width: 600px;\n",
        "        }}\n",
        "        .feedback-section {{\n",
        "            flex: 1 1 300px;\n",
        "            min-width: 300px;\n",
        "        }}\n",
        "        .form-group {{\n",
        "            margin-bottom: 15px;\n",
        "        }}\n",
        "        label {{\n",
        "            font-weight: bold;\n",
        "            color: #34495e;\n",
        "            display: block;\n",
        "            margin-bottom: 5px;\n",
        "        }}\n",
        "        input[type=\"file\"], input[type=\"text\"] {{\n",
        "            width: calc(100% - 22px);\n",
        "            padding: 10px;\n",
        "            border: 1px solid #bdc3c7;\n",
        "            border-radius: 6px;\n",
        "            font-size: 1em;\n",
        "            box-sizing: border-box;\n",
        "            transition: border-color 0.2s, box-shadow 0.2s;\n",
        "        }}\n",
        "        input[type=\"text\"]:focus {{\n",
        "            border-color: #3498db;\n",
        "            box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.2);\n",
        "            outline: none;\n",
        "        }}\n",
        "        button {{\n",
        "            padding: 10px 15px;\n",
        "            background-color: #2ecc71;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 6px;\n",
        "            cursor: pointer;\n",
        "            font-size: 1em;\n",
        "            font-weight: bold;\n",
        "            transition: background-color 0.3s ease, transform 0.1s ease;\n",
        "            margin-top: 10px;\n",
        "        }}\n",
        "        button:hover {{\n",
        "            background-color: #27ae60;\n",
        "            transform: translateY(-1px);\n",
        "        }}\n",
        "        video {{\n",
        "            width: 100%;\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 8px;\n",
        "            background-color: #000;\n",
        "            display: block; /* Ensure it doesn't take less than 100% width due to baseline */\n",
        "        }}\n",
        "        .annotated-frame-display {{\n",
        "            width: 100%;\n",
        "            height: auto; /* Adjust height based on content */\n",
        "            min-height: 360px; /* Minimum height for visual */\n",
        "            background-color: #e9ecef;\n",
        "            border: 1px dashed #ced4da;\n",
        "            border-radius: 8px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            justify-content: center;\n",
        "            color: #6c757d;\n",
        "            font-style: italic;\n",
        "            text-align: center;\n",
        "            overflow: hidden; /* Hide overflow if image too large */\n",
        "        }}\n",
        "        .annotated-frame-display img {{\n",
        "            max-width: 100%;\n",
        "            max-height: 100%;\n",
        "            object-fit: contain;\n",
        "        }}\n",
        "        .realtime-feedback {{\n",
        "            min-height: 200px;\n",
        "            max-height: 400px; /* Limit height to prevent excessive scrolling */\n",
        "            overflow-y: auto;\n",
        "            background-color: #e9ecef;\n",
        "            border: 1px dashed #ced4da;\n",
        "            border-radius: 8px;\n",
        "            padding: 15px;\n",
        "            font-size: 0.95em;\n",
        "            line-height: 1.5;\n",
        "            color: #343a40;\n",
        "        }}\n",
        "        @media (max-width: 900px) {{\n",
        "            .live-dashboard-container {{\n",
        "                flex-direction: column;\n",
        "            }}\n",
        "            .video-input-section, .video-display-section, .feedback-section {{\n",
        "                flex: 1 1 100%;\n",
        "                min-width: unset;\n",
        "            }}\n",
        "        }}\n",
        "    </style>\n",
        "\n",
        "    <h2>Live Video Analysis Dashboard</h2>\n",
        "\n",
        "    <div class=\"section video-input-section\">\n",
        "        <h3>Video Input</h3>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"video_file\">Upload Video File:</label>\n",
        "            <input type=\"file\" id=\"video_file\" accept=\"video/*\">\n",
        "        </div>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"video_url\">Video URL:</label>\n",
        "            <input type=\"text\" id=\"video_url\" placeholder=\"Enter video URL (e.g., .mp4, .mov)\">\n",
        "        </div>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"exercise_select\">Exercise Type:</label>\n",
        "            <select id=\"exercise_select\" style=\"width: calc(100% - 22px); padding: 10px; border: 1px solid #bdc3c7; border-radius: 6px; font-size: 1em; box-sizing: border-box;\">\n",
        "                <option value=\"squat\">Squat</option>\n",
        "                <option value=\"pushup\">Pushup</option>\n",
        "                <option value=\"unknown\">Other/Unknown</option>\n",
        "            </select>\n",
        "        </div>\n",
        "        <button id=\"load_video_button\">Load Video</button>\n",
        "        <button id=\"start_analysis_button\" style=\"background-color: #3498db; margin-left: 10px;\" disabled>Start Analysis</button>\n",
        "        <button id=\"stop_analysis_button\" style=\"background-color: #e74c3c; margin-left: 10px;\" disabled>Stop Analysis</button>\n",
        "\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section video-display-section\">\n",
        "        <h3>Video Player</h3>\n",
        "        <video id=\"video_player\" controls muted preload=\"auto\">\n",
        "            Your browser does not support the video tag.\n",
        "        </video>\n",
        "        <h3 style=\"margin-top: 20px;\">Annotated Frames</h3>\n",
        "        <div id=\"annotated_frame_display\" class=\"annotated-frame-display\">\n",
        "            <p>Annotated frames will appear here.</p>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section feedback-section\">\n",
        "        <h3>Real-time Feedback & Metrics</h3>\n",
        "        <div id=\"realtime_feedback_area\" class=\"realtime-feedback\">\n",
        "            <p>Live analysis feedback will be displayed here.</p>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <canvas id=\"frame_canvas\" style=\"display:none;\"></canvas>\n",
        "\n",
        "    <script>\n",
        "        const videoPlayer = document.getElementById('video_player');\n",
        "        const videoFile = document.getElementById('video_file');\n",
        "        const videoUrl = document.getElementById('video_url');\n",
        "        const exerciseSelect = document.getElementById('exercise_select');\n",
        "        const loadVideoButton = document.getElementById('load_video_button');\n",
        "        const startAnalysisButton = document.getElementById('start_analysis_button');\n",
        "        const stopAnalysisButton = document.getElementById('stop_analysis_button');\n",
        "        const annotatedFrameDisplay = document.getElementById('annotated_frame_display');\n",
        "        const realtimeFeedbackArea = document.getElementById('realtime_feedback_area');\n",
        "        const frameCanvas = document.getElementById('frame_canvas');\n",
        "        const canvasCtx = frameCanvas.getContext('2d');\n",
        "\n",
        "        let animationFrameId = null;\n",
        "        let referenceAngles = null;\n",
        "        let currentExerciseType = 'squat';\n",
        "\n",
        "        // Set up callback functions to be called from Python\n",
        "        async function processFramePython(base64Frame, exerciseType, refAngles) {\n",
        "            const result = await google.colab.output.getData({\n",
        "                name: 'process_frame_js',\n",
        "                args: [base64Frame, exerciseType, refAngles]\n",
        "            });\n",
        "            return result.data;\n",
        "        }\n",
        "\n",
        "        async function getReferenceAnglesPython(exerciseType) {\n",
        "            const result = await google.colab.output.getData({\n",
        "                name: 'get_ref_angles_js',\n",
        "                args: [exerciseType]\n",
        "            });\n",
        "            return result.data;\n",
        "        }\n",
        "\n",
        "        function logFeedback(message, type = 'info') {\n",
        "            const p = document.createElement('p');\n",
        "            p.textContent = `[${new Date().toLocaleTimeString()}] ${message}`;\n",
        "            if (type === 'error') p.style.color = 'red';\n",
        "            else if (type === 'warning') p.style.color = 'orange';\n",
        "            realtimeFeedbackArea.appendChild(p);\n",
        "            realtimeFeedbackArea.scrollTop = realtimeFeedbackArea.scrollHeight;\n",
        "        }\n",
        "\n",
        "        loadVideoButton.addEventListener('click', async () => {\n",
        "            logFeedback('Loading video...');\n",
        "            startAnalysisButton.disabled = true;\n",
        "            stopAnalysisButton.disabled = true;\n",
        "            videoPlayer.pause();\n",
        "            annotatedFrameDisplay.innerHTML = '<p>Annotated frames will appear here.</p>';\n",
        "            realtimeFeedbackArea.innerHTML = '<p>Live analysis feedback will be displayed here.</p>';\n",
        "\n",
        "            currentExerciseType = exerciseSelect.value;\n",
        "            referenceAngles = await getReferenceAnglesPython(currentExerciseType);\n",
        "            logFeedback(`Reference angles loaded for ${currentExerciseType}.`);\n",
        "\n",
        "            if (videoFile.files.length > 0) {\n",
        "                const file = videoFile.files[0];\n",
        "                videoPlayer.src = URL.createObjectURL(file);\n",
        "                videoPlayer.load();\n",
        "            } else if (videoUrl.value) {\n",
        "                videoPlayer.src = videoUrl.value;\n",
        "                videoPlayer.load();\n",
        "            } else {\n",
        "                logFeedback('Please select a video file or enter a URL.', 'error');\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            videoPlayer.onloadeddata = () => {\n",
        "                logFeedback('Video loaded successfully.');\n",
        "                startAnalysisButton.disabled = false;\n",
        "                videoPlayer.play(); // Autoplay once loaded\n",
        "            };\n",
        "            videoPlayer.onerror = () => {\n",
        "                logFeedback('Error loading video. Check URL or file format.', 'error');\n",
        "            };\n",
        "        });\n",
        "\n",
        "        startAnalysisButton.addEventListener('click', () => {\n",
        "            if (!videoPlayer.src) {\n",
        "                logFeedback('No video loaded. Please load a video first.', 'warning');\n",
        "                return;\n",
        "            }\n",
        "            if (!referenceAngles) {\n",
        "                logFeedback('Reference angles not loaded. Please load video again.', 'error');\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            logFeedback('Starting live analysis...');\n",
        "            startAnalysisButton.disabled = true;\n",
        "            stopAnalysisButton.disabled = false;\n",
        "            videoPlayer.play();\n",
        "            processVideoFrames();\n",
        "        });\n",
        "\n",
        "        stopAnalysisButton.addEventListener('click', () => {\n",
        "            logFeedback('Stopping live analysis...');\n",
        "            if (animationFrameId) {\n",
        "                cancelAnimationFrame(animationFrameId);\n",
        "                animationFrameId = null;\n",
        "            }\n",
        "            videoPlayer.pause();\n",
        "            startAnalysisButton.disabled = false;\n",
        "            stopAnalysisButton.disabled = true;\n",
        "        });\n",
        "\n",
        "        videoPlayer.addEventListener('play', () => {\n",
        "             if (startAnalysisButton.disabled && !stopAnalysisButton.disabled) { // If analysis was already started\n",
        "                 processVideoFrames();\n",
        "             }\n",
        "        });\n",
        "\n",
        "        videoPlayer.addEventListener('pause', () => {\n",
        "            if (animationFrameId) {\n",
        "                cancelAnimationFrame(animationFrameId);\n",
        "                animationFrameId = null;\n",
        "            }\n",
        "        });\n",
        "\n",
        "        videoPlayer.addEventListener('ended', () => {\n",
        "            logFeedback('Video ended. Analysis stopped.', 'info');\n",
        "            if (animationFrameId) {\n",
        "                cancelAnimationFrame(animationFrameId);\n",
        "                animationFrameId = null;\n",
        "            }\n",
        "            startAnalysisButton.disabled = false;\n",
        "            stopAnalysisButton.disabled = true;\n",
        "        });\n",
        "\n",
        "        function processVideoFrames() {\n",
        "            if (videoPlayer.paused || videoPlayer.ended) {\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            frameCanvas.width = videoPlayer.videoWidth;\n",
        "            frameCanvas.height = videoPlayer.videoHeight;\n",
        "            canvasCtx.drawImage(videoPlayer, 0, 0, frameCanvas.width, frameCanvas.height);\n",
        "            const base64Frame = frameCanvas.toDataURL('image/jpeg', 0.8).split(',')[1];\n",
        "\n",
        "            processFramePython(base64Frame, currentExerciseType, referenceAngles)\n",
        "                .then(response => {\n",
        "                    const [annotatedFrameBase64, feedbackMessages] = response;\n",
        "                    if (annotatedFrameBase64) {\n",
        "                        annotatedFrameDisplay.innerHTML = `<img src='data:image/jpeg;base64,${annotatedFrameBase64}' alt='Annotated Frame'/>`;\n",
        "                    }\n",
        "                    realtimeFeedbackArea.innerHTML = ''; // Clear previous feedback\n",
        "                    if (feedbackMessages && feedbackMessages.length > 0) {\n",
        "                        feedbackMessages.forEach(msg => logFeedback(msg));\n",
        "                    } else {\n",
        "                         logFeedback('No specific issues detected.', 'info');\n",
        "                    }\n",
        "                })\n",
        "                .catch(error => {\n",
        "                    logFeedback(`Python analysis error: ${error}`, 'error');\n",
        "                });\n",
        "\n",
        "            animationFrameId = requestAnimationFrame(processVideoFrames);\n",
        "        }\n",
        "    </script>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_template_live))\n",
        "print(\"‚úì Live Video Analysis Dashboard with JavaScript interactivity displayed.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eae647da"
      },
      "source": [
        "**Reasoning**:\n",
        "The `SyntaxError` persists because the curly braces within the JavaScript code block were not properly escaped when embedded inside the Python f-string. I need to go through the JavaScript section of the `html_template_live` and escape all literal curly braces (`{` and `}`) by doubling them (`{{` and `}}`) to ensure Python interprets them as literal characters rather than f-string placeholders.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57e4279f"
      },
      "source": [
        "from google.colab import output\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Register Python functions as callbacks\n",
        "output.register_callback('process_frame_js', process_frame_for_live_analysis)\n",
        "output.register_callback('get_ref_angles_js', get_sample_reference_angles)\n",
        "\n",
        "html_template_live = f\"\"\"\n",
        "<div class=\"live-dashboard-container\">\n",
        "    <style>\n",
        "        .live-dashboard-container {{\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            padding: 25px;\n",
        "            border: 1px solid #e0e0e0;\n",
        "            border-radius: 10px;\n",
        "            background-color: #fcfcfc;\n",
        "            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.08);\n",
        "            max-width: 1200px;\n",
        "            margin: 20px auto;\n",
        "            display: flex;\n",
        "            flex-wrap: wrap;\n",
        "            gap: 20px;\n",
        "        }}\n",
        "        h2 {{\n",
        "            width: 100%;\n",
        "            color: #2c3e50;\n",
        "            text-align: center;\n",
        "            margin-bottom: 25px;\n",
        "            font-size: 2.2em;\n",
        "        }}\n",
        "        .section {{\n",
        "            background-color: #ffffff;\n",
        "            border: 1px solid #e9ecef;\n",
        "            border-radius: 8px;\n",
        "            padding: 20px;\n",
        "            box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
        "        }}\n",
        "        .video-input-section {{\n",
        "            flex: 1 1 300px;\n",
        "            min-width: 300px;\n",
        "        }}\n",
        "        .video-display-section {{\n",
        "            flex: 2 1 600px;\n",
        "            min-width: 600px;\n",
        "        }}\n",
        "        .feedback-section {{\n",
        "            flex: 1 1 300px;\n",
        "            min-width: 300px;\n",
        "        }}\n",
        "        .form-group {{\n",
        "            margin-bottom: 15px;\n",
        "        }}\n",
        "        label {{\n",
        "            font-weight: bold;\n",
        "            color: #34495e;\n",
        "            display: block;\n",
        "            margin-bottom: 5px;\n",
        "        }}\n",
        "        input[type=\"file\"], input[type=\"text\"] {{\n",
        "            width: calc(100% - 22px);\n",
        "            padding: 10px;\n",
        "            border: 1px solid #bdc3c7;\n",
        "            border-radius: 6px;\n",
        "            font-size: 1em;\n",
        "            box-sizing: border-box;\n",
        "            transition: border-color 0.2s, box-shadow 0.2s;\n",
        "        }}\n",
        "        input[type=\"text\"]:focus {{\n",
        "            border-color: #3498db;\n",
        "            box-shadow: 0 0 0 3px rgba(52, 152, 219, 0.2);\n",
        "            outline: none;\n",
        "        }}\n",
        "        button {{\n",
        "            padding: 10px 15px;\n",
        "            background-color: #2ecc71;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 6px;\n",
        "            cursor: pointer;\n",
        "            font-size: 1em;\n",
        "            font-weight: bold;\n",
        "            transition: background-color 0.3s ease, transform 0.1s ease;\n",
        "            margin-top: 10px;\n",
        "        }}\n",
        "        button:hover {{\n",
        "            background-color: #27ae60;\n",
        "            transform: translateY(-1px);\n",
        "        }}\n",
        "        video {{\n",
        "            width: 100%;\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 8px;\n",
        "            background-color: #000;\n",
        "            display: block; /* Ensure it doesn't take less than 100% width due to baseline */\n",
        "        }}\n",
        "        .annotated-frame-display {{\n",
        "            width: 100%;\n",
        "            height: auto; /* Adjust height based on content */\n",
        "            min-height: 360px; /* Minimum height for visual */\n",
        "            background-color: #e9ecef;\n",
        "            border: 1px dashed #ced4da;\n",
        "            border-radius: 8px;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            justify-content: center;\n",
        "            color: #6c757d;\n",
        "            font-style: italic;\n",
        "            text-align: center;\n",
        "            overflow: hidden; /* Hide overflow if image too large */\n",
        "        }}\n",
        "        .annotated-frame-display img {{\n",
        "            max-width: 100%;\n",
        "            max-height: 100%;\n",
        "            object-fit: contain;\n",
        "        }}\n",
        "        .realtime-feedback {{\n",
        "            min-height: 200px;\n",
        "            max-height: 400px; /* Limit height to prevent excessive scrolling */\n",
        "            overflow-y: auto;\n",
        "            background-color: #e9ecef;\n",
        "            border: 1px dashed #ced4da;\n",
        "            border-radius: 8px;\n",
        "            padding: 15px;\n",
        "            font-size: 0.95em;\n",
        "            line-height: 1.5;\n",
        "            color: #343a40;\n",
        "        }}\n",
        "        @media (max-width: 900px) {{\n",
        "            .live-dashboard-container {{\n",
        "                flex-direction: column;\n",
        "            }}\n",
        "            .video-input-section, .video-display-section, .feedback-section {{\n",
        "                flex: 1 1 100%;\n",
        "                min-width: unset;\n",
        "            }}\n",
        "        }}\n",
        "    </style>\n",
        "\n",
        "    <h2>Live Video Analysis Dashboard</h2>\n",
        "\n",
        "    <div class=\"section video-input-section\">\n",
        "        <h3>Video Input</h3>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"video_file\">Upload Video File:</label>\n",
        "            <input type=\"file\" id=\"video_file\" accept=\"video/*\">\n",
        "        </div>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"video_url\">Video URL:</label>\n",
        "            <input type=\"text\" id=\"video_url\" placeholder=\"Enter video URL (e.g., .mp4, .mov)\">\n",
        "        </div>\n",
        "        <div class=\"form-group\">\n",
        "            <label for=\"exercise_select\">Exercise Type:</label>\n",
        "            <select id=\"exercise_select\" style=\"width: calc(100% - 22px); padding: 10px; border: 1px solid #bdc3c7; border-radius: 6px; font-size: 1em; box-sizing: border-box;\">\n",
        "                <option value=\"squat\">Squat</option>\n",
        "                <option value=\"pushup\">Pushup</option>\n",
        "                <option value=\"unknown\">Other/Unknown</option>\n",
        "            </select>\n",
        "        </div>\n",
        "        <button id=\"load_video_button\">Load Video</button>\n",
        "        <button id=\"start_analysis_button\" style=\"background-color: #3498db; margin-left: 10px;\" disabled>Start Analysis</button>\n",
        "        <button id=\"stop_analysis_button\" style=\"background-color: #e74c3c; margin-left: 10px;\" disabled>Stop Analysis</button>\n",
        "\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section video-display-section\">\n",
        "        <h3>Video Player</h3>\n",
        "        <video id=\"video_player\" controls muted preload=\"auto\">\n",
        "            Your browser does not support the video tag.\n",
        "        </video>\n",
        "        <h3 style=\"margin-top: 20px;\">Annotated Frames</h3>\n",
        "        <div id=\"annotated_frame_display\" class=\"annotated-frame-display\">\n",
        "            <p>Annotated frames will appear here.</p>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"section feedback-section\">\n",
        "        <h3>Real-time Feedback & Metrics</h3>\n",
        "        <div id=\"realtime_feedback_area\" class=\"realtime-feedback\">\n",
        "            <p>Live analysis feedback will be displayed here.</p>\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <canvas id=\"frame_canvas\" style=\"display:none;\"></canvas>\n",
        "\n",
        "    <script>\n",
        "        const videoPlayer = document.getElementById('video_player');\n",
        "        const videoFile = document.getElementById('video_file');\n",
        "        const videoUrl = document.getElementById('video_url');\n",
        "        const exerciseSelect = document.getElementById('exercise_select');\n",
        "        const loadVideoButton = document.getElementById('load_video_button');\n",
        "        const startAnalysisButton = document.getElementById('start_analysis_button');\n",
        "        const stopAnalysisButton = document.getElementById('stop_analysis_button');\n",
        "        const annotatedFrameDisplay = document.getElementById('annotated_frame_display');\n",
        "        const realtimeFeedbackArea = document.getElementById('realtime_feedback_area');\n",
        "        const frameCanvas = document.getElementById('frame_canvas');\n",
        "        const canvasCtx = frameCanvas.getContext('2d');\n",
        "\n",
        "        let animationFrameId = null;\n",
        "        let referenceAngles = null;\n",
        "        let currentExerciseType = 'squat';\n",
        "\n",
        "        // Set up callback functions to be called from Python\n",
        "        async function processFramePython(base64Frame, exerciseType, refAngles) {{\n",
        "            const result = await google.colab.output.getData({{\n",
        "                name: 'process_frame_js',\n",
        "                args: [base64Frame, exerciseType, refAngles]\n",
        "            }});\n",
        "            return result.data;\n",
        "        }}\n",
        "\n",
        "        async function getReferenceAnglesPython(exerciseType) {{\n",
        "            const result = await google.colab.output.getData({{\n",
        "                name: 'get_ref_angles_js',\n",
        "                args: [exerciseType]\n",
        "            }});\n",
        "            return result.data;\n",
        "        }}\n",
        "\n",
        "        function logFeedback(message, type = 'info') {{\n",
        "            const p = document.createElement('p');\n",
        "            p.textContent = `[${{new Date().toLocaleTimeString()}}] ${{message}}`;\n",
        "            if (type === 'error') p.style.color = 'red';\n",
        "            else if (type === 'warning') p.style.color = 'orange';\n",
        "            realtimeFeedbackArea.appendChild(p);\n",
        "            realtimeFeedbackArea.scrollTop = realtimeFeedbackArea.scrollHeight;\n",
        "        }}\n",
        "\n",
        "        loadVideoButton.addEventListener('click', async () => {{\n",
        "            logFeedback('Loading video...');\n",
        "            startAnalysisButton.disabled = true;\n",
        "            stopAnalysisButton.disabled = true;\n",
        "            videoPlayer.pause();\n",
        "            annotatedFrameDisplay.innerHTML = '<p>Annotated frames will appear here.</p>';\n",
        "            realtimeFeedbackArea.innerHTML = '<p>Live analysis feedback will be displayed here.</p>';\n",
        "\n",
        "            currentExerciseType = exerciseSelect.value;\n",
        "            referenceAngles = await getReferenceAnglesPython(currentExerciseType);\n",
        "            logFeedback(`Reference angles loaded for ${{currentExerciseType}}. `);\n",
        "\n",
        "            if (videoFile.files.length > 0) {{\n",
        "                const file = videoFile.files[0];\n",
        "                videoPlayer.src = URL.createObjectURL(file);\n",
        "                videoPlayer.load();\n",
        "            }} else if (videoUrl.value) {{\n",
        "                videoPlayer.src = videoUrl.value;\n",
        "                videoPlayer.load();\n",
        "            }} else {{\n",
        "                logFeedback('Please select a video file or enter a URL.', 'error');\n",
        "                return;\n",
        "            }}\n",
        "\n",
        "            videoPlayer.onloadeddata = () => {{\n",
        "                logFeedback('Video loaded successfully.');\n",
        "                startAnalysisButton.disabled = false;\n",
        "                videoPlayer.play(); // Autoplay once loaded\n",
        "            }};\n",
        "            videoPlayer.onerror = () => {{\n",
        "                logFeedback('Error loading video. Check URL or file format.', 'error');\n",
        "            }};\n",
        "        }});\n",
        "\n",
        "        startAnalysisButton.addEventListener('click', () => {{\n",
        "            if (!videoPlayer.src) {{\n",
        "                logFeedback('No video loaded. Please load a video first.', 'warning');\n",
        "                return;\n",
        "            }}\n",
        "            if (!referenceAngles) {{\n",
        "                logFeedback('Reference angles not loaded. Please load video again.', 'error');\n",
        "                return;\n",
        "            }}\n",
        "\n",
        "            logFeedback('Starting live analysis...');\n",
        "            startAnalysisButton.disabled = true;\n",
        "            stopAnalysisButton.disabled = false;\n",
        "            videoPlayer.play();\n",
        "            processVideoFrames();\n",
        "        }});\n",
        "\n",
        "        stopAnalysisButton.addEventListener('click', () => {{\n",
        "            logFeedback('Stopping live analysis...');\n",
        "            if (animationFrameId) {{\n",
        "                cancelAnimationFrame(animationFrameId);\n",
        "                animationFrameId = null;\n",
        "            }}\n",
        "            videoPlayer.pause();\n",
        "            startAnalysisButton.disabled = false;\n",
        "            stopAnalysisButton.disabled = true;\n",
        "        }});\n",
        "\n",
        "        videoPlayer.addEventListener('play', () => {{\n",
        "             if (startAnalysisButton.disabled && !stopAnalysisButton.disabled) {{ // If analysis was already started\n",
        "                 processVideoFrames();\n",
        "             }}\n",
        "        }});\n",
        "\n",
        "        videoPlayer.addEventListener('pause', () => {{\n",
        "            if (animationFrameId) {{\n",
        "                cancelAnimationFrame(animationFrameId);\n",
        "                animationFrameId = null;\n",
        "            }}\n",
        "        }});\n",
        "\n",
        "        videoPlayer.addEventListener('ended', () => {{\n",
        "            logFeedback('Video ended. Analysis stopped.', 'info');\n",
        "            if (animationFrameId) {{\n",
        "                cancelAnimationFrame(animationFrameId);\n",
        "                animationFrameId = null;\n",
        "            }}\n",
        "            startAnalysisButton.disabled = false;\n",
        "            stopAnalysisButton.disabled = true;\n",
        "        }});\n",
        "\n",
        "        function processVideoFrames() {{\n",
        "            if (videoPlayer.paused || videoPlayer.ended) {{\n",
        "                return;\n",
        "            }}\n",
        "\n",
        "            frameCanvas.width = videoPlayer.videoWidth;\n",
        "            frameCanvas.height = videoPlayer.videoHeight;\n",
        "            canvasCtx.drawImage(videoPlayer, 0, 0, frameCanvas.width, frameCanvas.height);\n",
        "            const base64Frame = frameCanvas.toDataURL('image/jpeg', 0.8).split(',')[1];\n",
        "\n",
        "            processFramePython(base64Frame, currentExerciseType, referenceAngles)\n",
        "                .then(response => {{\n",
        "                    const [annotatedFrameBase64, feedbackMessages] = response;\n",
        "                    if (annotatedFrameBase64) {{\n",
        "                        annotatedFrameDisplay.innerHTML = `<img src='data:image/jpeg;base64,${{annotatedFrameBase64}}' alt='Annotated Frame'/>`;\n",
        "                    }}\n",
        "                    realtimeFeedbackArea.innerHTML = ''; // Clear previous feedback\n",
        "                    if (feedbackMessages && feedbackMessages.length > 0) {{\n",
        "                        feedbackMessages.forEach(msg => logFeedback(msg));\n",
        "                    }} else {{\n",
        "                         logFeedback('No specific issues detected.', 'info');\n",
        "                    }}\n",
        "                }})\n",
        "                .catch(error => {{\n",
        "                    logFeedback(`Python analysis error: ${{error}}`, 'error');\n",
        "                }});\n",
        "\n",
        "            animationFrameId = requestAnimationFrame(processVideoFrames);\n",
        "        }}\n",
        "    </script>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(html_template_live))\n",
        "print(\"‚úì Live Video Analysis Dashboard with JavaScript interactivity displayed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6545ef11"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### How to Use the Live Video Analysis Dashboard\n",
        "\n",
        "This interactive dashboard allows users to perform live pose estimation and form analysis on video input. Here's how to use it:\n",
        "\n",
        "1.  **Load Video**: In the \"Video Input\" section, you can either:\n",
        "    *   **Upload a local file**: Click \"Choose File\" and select a video from your computer.\n",
        "    *   **Provide a video URL**: Enter a direct link to a video file (e.g., an `.mp4` or `.mov` file) in the \"Video URL\" field.\n",
        "2.  **Select Exercise Type**: Choose the exercise being performed in the video from the \"Exercise Type\" dropdown (e.g., 'Squat', 'Pushup'). This selection determines the reference angles used for form comparison.\n",
        "3.  **Click 'Load Video'**: After selecting your video source and exercise type, click the \"Load Video\" button. The video will appear in the \"Video Player\" section, and a message confirming the reference angles loaded will appear in the \"Real-time Feedback & Metrics\" area.\n",
        "4.  **Click 'Start Analysis'**: Once the video is loaded (and may start playing automatically), click \"Start Analysis\". The dashboard will begin processing frames in real-time:\n",
        "    *   **Annotated Frames**: The \"Annotated Frames\" section will display a live stream of the video frames with pose keypoints and skeletal lines overlaid.\n",
        "    *   **Real-time Feedback**: The \"Real-time Feedback & Metrics\" area will update with textual feedback messages, indicating form issues detected in real-time.\n",
        "5.  **Click 'Stop Analysis'**: To pause the analysis at any time, click the \"Stop Analysis\" button. You can resume by clicking \"Start Analysis\" again, or load a new video.\n",
        "\n",
        "### Key Findings from Implementation\n",
        "\n",
        "*   **Interactive HTML Structure**: A robust HTML template was created with dedicated sections for video input, a video player, an annotated frame display, and a real-time feedback area. CSS styling was applied to ensure a clean, responsive, and user-friendly interface.\n",
        "*   **Python Backend Integration**: Two Python functions, `process_frame_for_live_analysis` (for single-frame processing) and `get_sample_reference_angles` (for providing exercise-specific ideal angles), were adapted and registered as Colab callbacks using `google.colab.output.register_callback`. This allows JavaScript in the frontend to invoke these Python functions asynchronously.\n",
        "*   **JavaScript-Python Bridge**: The embedded JavaScript code effectively manages the client-side logic:\n",
        "    *   It handles video loading from both file uploads and URLs.\n",
        "    *   It retrieves exercise-specific reference angles from Python upon video load.\n",
        "    *   It continuously captures frames from the playing video using an offscreen `<canvas>` and `requestAnimationFrame`.\n",
        "    *   Each frame is converted to a base64 string and sent to the Python `process_frame_for_live_analysis` callback.\n",
        "    *   The annotated frames and textual feedback received from Python are dynamically updated in the respective HTML elements.\n",
        "*   **Real-time Feedback Mechanism**: The `logFeedback` JavaScript function provides a clear, time-stamped log of events and analysis results in the feedback area, enhancing the user experience.\n",
        "\n",
        "### Next Steps and Potential Enhancements\n",
        "\n",
        "1.  **Dynamic Reference Angle Generation**: Instead of hardcoded sample reference angles, integrate a mechanism to load reference angles from pre-recorded \"good form\" videos or a database, allowing for more accurate and personalized analysis.\n",
        "2.  **Performance Optimization**: For truly high-frame-rate real-time analysis, explore optimizations such as:\n",
        "    *   Processing frames at a lower rate (e.g., every 2nd or 3rd frame) if performance is a bottleneck.\n",
        "    *   Using Web Workers in JavaScript to offload frame capture and base64 conversion.\n",
        "    *   Quantizing the base64 frames to reduce payload size sent to Python.\n",
        "3.  **Advanced Metrics and Visualization**: Implement more advanced real-time metrics (e.g., rep counting, average angle deviations over a set) and consider small, embedded charts or gauges within the feedback section for immediate visual cues.\n",
        "4.  **Error Handling and User Guidance**: Improve error handling for video loading failures, Python processing errors, and provide more explicit user guidance within the dashboard itself.\n",
        "5.  **Stop/Start Analysis Buttons**: The 'Start Analysis' and 'Stop Analysis' buttons are implemented but could be refined to handle edge cases more robustly (e.g., preventing multiple analysis loops).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23dd0834"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### How to Use the Live Video Analysis Dashboard\n",
        "\n",
        "This interactive dashboard allows users to perform live pose estimation and form analysis on video input. Here's how to use it:\n",
        "\n",
        "1.  **Load Video**: In the \"Video Input\" section, you can either:\n",
        "    *   **Upload a local file**: Click \"Choose File\" and select a video from your computer.\n",
        "    *   **Provide a video URL**: Enter a direct link to a video file (e.g., an `.mp4` or `.mov` file) in the \"Video URL\" field.\n",
        "2.  **Select Exercise Type**: Choose the exercise being performed in the video from the \"Exercise Type\" dropdown (e.g., 'Squat', 'Pushup'). This selection determines the reference angles used for form comparison.\n",
        "3.  **Click 'Load Video'**: After selecting your video source and exercise type, click the \"Load Video\" button. The video will appear in the \"Video Player\" section, and a message confirming the reference angles loaded will appear in the \"Real-time Feedback & Metrics\" area.\n",
        "4.  **Click 'Start Analysis'**: Once the video is loaded (and may start playing automatically), click \"Start Analysis\". The dashboard will begin processing frames in real-time:\n",
        "    *   **Annotated Frames**: The \"Annotated Frames\" section will display a live stream of the video frames with pose keypoints and skeletal lines overlaid.\n",
        "    *   **Real-time Feedback**: The \"Real-time Feedback & Metrics\" area will update with textual feedback messages, indicating form issues detected in real-time.\n",
        "5.  **Click 'Stop Analysis'**: To pause the analysis at any time, click the \"Stop Analysis\" button. You can resume by clicking \"Start Analysis\" again, or load a new video.\n",
        "\n",
        "### Key Findings from Implementation\n",
        "\n",
        "*   **Interactive HTML Structure**: A robust HTML template was created with dedicated sections for video input, a video player, an annotated frame display, and a real-time feedback area. CSS styling was applied to ensure a clean, responsive, and user-friendly interface.\n",
        "*   **Python Backend Integration**: Two Python functions, `process_frame_for_live_analysis` (for single-frame processing) and `get_sample_reference_angles` (for providing exercise-specific ideal angles), were adapted and registered as Colab callbacks using `google.colab.output.register_callback`. This allows JavaScript in the frontend to invoke these Python functions asynchronously.\n",
        "*   **JavaScript-Python Bridge**: The embedded JavaScript code effectively manages the client-side logic:\n",
        "    *   It handles video loading from both file uploads and URLs.\n",
        "    *   It retrieves exercise-specific reference angles from Python upon video load.\n",
        "    *   It continuously captures frames from the playing video using an offscreen `<canvas>` and `requestAnimationFrame`.\n",
        "    *   Each frame is converted to a base64 string and sent to the Python `process_frame_for_live_analysis` callback.\n",
        "    *   The annotated frames and textual feedback received from Python are dynamically updated in the respective HTML elements.\n",
        "*   **Real-time Feedback Mechanism**: The `logFeedback` JavaScript function provides a clear, time-stamped log of events and analysis results in the feedback area, enhancing the user experience.\n",
        "\n",
        "### Next Steps and Potential Enhancements\n",
        "\n",
        "1.  **Dynamic Reference Angle Generation**: Instead of hardcoded sample reference angles, integrate a mechanism to load reference angles from pre-recorded \"good form\" videos or a database, allowing for more accurate and personalized analysis.\n",
        "2.  **Performance Optimization**: For truly high-frame-rate real-time analysis, explore optimizations such as:\n",
        "    *   Processing frames at a lower rate (e.g., every 2nd or 3rd frame) if performance is a bottleneck.\n",
        "    *   Using Web Workers in JavaScript to offload frame capture and base64 conversion.\n",
        "    *   Quantizing the base64 frames to reduce payload size sent to Python.\n",
        "3.  **Advanced Metrics and Visualization**: Implement more advanced real-time metrics (e.g., rep counting, average angle deviations over a set) and consider small, embedded charts or gauges within the feedback section for immediate visual cues.\n",
        "4.  **Error Handling and User Guidance**: Improve error handling for video loading failures, Python processing errors, and provide more explicit user guidance within the dashboard itself.\n",
        "5.  **Stop/Start Analysis Buttons**: The 'Start Analysis' and 'Stop Analysis' buttons are implemented but could be refined to handle edge cases more robustly (e.g., preventing multiple analysis loops).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06359ea9"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the implemented live video analysis dashboard, explain how users can interact with it, and discuss any limitations or potential next steps for further enhancements, such as webcam integration or cloud-based real-time processing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e6c7f30"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "\n",
        "**How can users interact with the implemented live video analysis dashboard?**\n",
        "Users can interact with the dashboard by:\n",
        "1.  **Loading a video**: They can either upload a local video file or provide a direct video URL (e.g., .mp4, .mov).\n",
        "2.  **Selecting an exercise type**: A dropdown allows users to choose the exercise (e.g., 'Squat', 'Pushup'), which determines the reference angles for form analysis.\n",
        "3.  **Initiating analysis**: Clicking the \"Start Analysis\" button begins real-time processing of video frames.\n",
        "4.  **Stopping analysis**: The \"Stop Analysis\" button pauses the real-time frame processing.\n",
        "Once analysis starts, the dashboard displays annotated video frames with pose estimations and provides real-time textual feedback on form in a dedicated feedback area.\n",
        "\n",
        "**What are the limitations or potential next steps for further enhancements, such as webcam integration or cloud-based real-time processing?**\n",
        "The current implementation has the following limitations and potential enhancements:\n",
        "*   **Reference Angle Generation**: Currently uses hardcoded sample reference angles. Future enhancements should include dynamic generation of reference angles from pre-recorded \"good form\" videos or a database.\n",
        "*   **Performance Optimization**: For high-frame-rate analysis, optimizations are needed, such as processing frames at a lower rate, using Web Workers in JavaScript for offloading tasks, or quantizing base64 frames to reduce payload size.\n",
        "*   **Advanced Metrics and Visualization**: Implement more advanced real-time metrics (e.g., rep counting, average angle deviations) and consider adding small, embedded charts or gauges for immediate visual feedback.\n",
        "*   **Error Handling and User Guidance**: Improve error handling for various failures (video loading, Python processing) and provide more explicit guidance within the dashboard.\n",
        "*   **Webcam Integration**: Although not explicitly implemented, the structure lays the groundwork for integrating webcam streams, which would involve adapting the frame capture mechanism to use `navigator.mediaDevices.getUserMedia()` to get a webcam stream instead of a video file/URL.\n",
        "*   **Cloud-based Real-time Processing**: For heavy computational loads, the Python backend could be hosted on a cloud platform (e.g., Google Cloud Functions, AWS Lambda), and the JavaScript frontend would send frames to and receive results from this cloud endpoint.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   A responsive HTML template for a live video analysis dashboard was successfully created, featuring dedicated sections for video input, a video player, an annotated frame display, and a real-time feedback area, all styled with embedded CSS.\n",
        "*   A Python function, `process_frame_for_live_analysis`, was developed to handle single video frames: it decodes base64 frames, performs YOLO pose estimation, calculates joint angles, generates textual form feedback, overlays annotations, and re-encodes the frame to base64.\n",
        "*   A helper Python function, `get_sample_reference_angles`, was defined to provide exercise-specific ideal joint angles (e.g., for squat, pushup) to be used as a reference during form analysis.\n",
        "*   Both Python backend functions (`process_frame_for_live_analysis` and `get_sample_reference_angles`) were successfully registered as Colab callbacks (`google.colab.output.register_callback`), enabling seamless asynchronous communication between the JavaScript frontend and the Python backend.\n",
        "*   The embedded JavaScript code effectively manages the client-side interactivity, including loading videos from local files or URLs, capturing frames from the video player using an offscreen canvas and `requestAnimationFrame`, converting frames to base64, invoking the Python analysis functions, and dynamically updating the dashboard's UI with annotated frames and real-time feedback.\n",
        "*   The final implemented dashboard supports loading videos, selecting an exercise type, and starting/stopping a real-time analysis loop that continuously sends frames to Python for processing and displays the results back to the user.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Enhance Reference Angle Management**: Develop a more sophisticated system for managing and generating reference angles, possibly using a database of expert-validated movements or on-the-fly learning from \"good form\" examples, rather than static hardcoded values.\n",
        "*   **Improve Real-time Performance and Scalability**: Implement performance optimizations such as asynchronous processing in the JavaScript frontend (e.g., Web Workers), intelligent frame skipping, and consider migrating the computationally intensive Python backend to a dedicated cloud service for more robust, scalable real-time analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UI/UX**\n",
        "Randall"
      ],
      "metadata": {
        "id": "DWA5X0o6TjUX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OPivaMARUtpw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "043f5a2fe7a84d3f9ba17253ac42cd6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "GridBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "GridBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "GridBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f68738d6ed8c48d4b66820185aceef99",
              "IPY_MODEL_e03cc7d87a5e421189d57cefef9bb61d",
              "IPY_MODEL_0e58daee331e4e12ab7a6bcad51ec901",
              "IPY_MODEL_3fc1c7c07230482793640612ef673ad4"
            ],
            "layout": "IPY_MODEL_27e2835f986b4a79a2bc4a954cec6b1b"
          }
        },
        "f68738d6ed8c48d4b66820185aceef99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "google/gemini-2.0-flash",
              "google/gemini-2.0-flash-lite",
              "google/gemini-2.5-flash",
              "google/gemini-2.5-flash-lite",
              "google/gemini-2.5-pro",
              "google/gemini-3-pro-preview",
              "google/gemma-3-12b",
              "google/gemma-3-1b",
              "google/gemma-3-27b",
              "google/gemma-3-4b"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_89d0ab4a2eb84f49a7471e78ca99aeaa",
            "style": "IPY_MODEL_44b14417b3944a4aa39d97180d8bf816"
          }
        },
        "e03cc7d87a5e421189d57cefef9bb61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_deecc1373b694bf5be8d55f046295b2b",
            "placeholder": "Ask me anything....",
            "rows": null,
            "style": "IPY_MODEL_dab3addc95bc4a79bf276987115c243d",
            "value": ""
          }
        },
        "0e58daee331e4e12ab7a6bcad51ec901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit Text",
            "disabled": false,
            "icon": "check",
            "layout": "IPY_MODEL_9c063cb2db01490a88d4ae21153fd470",
            "style": "IPY_MODEL_eeedd30a00174deabfce6e00a9cc339d",
            "tooltip": "Click to submit the text"
          }
        },
        "3fc1c7c07230482793640612ef673ad4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_40d0741456af4d1c8e20ab70d70a34dc",
            "msg_id": "",
            "outputs": []
          }
        },
        "27e2835f986b4a79a2bc4a954cec6b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89d0ab4a2eb84f49a7471e78ca99aeaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "44b14417b3944a4aa39d97180d8bf816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deecc1373b694bf5be8d55f046295b2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "100px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "dab3addc95bc4a79bf276987115c243d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c063cb2db01490a88d4ae21153fd470": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeedd30a00174deabfce6e00a9cc339d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "40d0741456af4d1c8e20ab70d70a34dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": "300px",
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": "scroll",
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}